# cpu是如何执行程序的
### 冯诺依曼模型
五个部分**运算器、控制器、储存器、输入设备、输出设备**。
运算器、控制器在中央处理器中，储存器就是常见的内存，输入输出设备是计算机外接的设备。储存单元和输入输出设备要与中央处理器打交道，离不开总线
#### 内存
储存的区域是线性的，储存数据的基本单位是**字节***byte*，一字节等于八位（8bit），每一个字节对应一个内存地址，从0开始
#### 中央处理器
32位cpu一次可以处理4个字节，64位一次可以处理8个字节，32位和64位代表CPU的位宽，位宽越大，可以计算的数值就越大。
cpu内部还有一些组件，常见的有**寄存器、控制单元、逻辑运算单元**。其中控制单元负责控制CPU工作，逻辑单元负责计算，寄存器又可以分为多种类，每种功能不同，紧挨着控制单位和逻辑运算单元
**常见寄存器种类**
* *通用寄存器*，用来存放需要运算的数据
- *程序计数器*，储存cpu要执行的下一条指令**所在的内存地址**
- *指令寄存器*，用来存放正在执行的指令
#### 总线
用于cpu和内存和其他设备之间的通信，可分为三种
- **地址总线**，用于指定CPU将要操作的内存地址
- **数据总线**，用于读写内存数据
- **控制总线**，用于发送和接收信号
CPU读写内存时，依次经过**地址总线-控制总线-数据总线**
### 程序执行的基本过程
CPU根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器中执行，然后指令长度自增，开始顺序读取下一条指令，这个循环过程叫**CPU的指令周期**
### a = 1 + 2执行过程
- 编译器先将数据1和数据2放到**数据段**中
- 编译器将 a=1+2编译为四个指令
  > load指令将地址1中的数据1装入寄存器R0
  > load指令将地址2中的数据2装入寄存器R1
  > add将R0 R1数据相加放入寄存器R2
  > store指令将R2数据存回数据a对应的地址中
- 编译完后，运行程序时程序计数器将地址设置为0x100地址，然后依次执行这4条指令
#### 指令
MIPS指令是32位的整数，高6位代表着操作码，剩下26位不同指令类型所表示内容也不同，主要有R、I、J三种
- **R指令**，用在算数和逻辑操作，有读取和写入数据的内存地址
- **I指令**，用在数据传输、条件分支等
- **J指令**，用在跳转，高6位之外的26位都是一个跳转后的地址
CPU构造指令流水线通常被分为四个阶段
1. Fetch，CPU通过程序计数器读取对应内存地址的指令
2. Decode，CPU对指令进行解码
3. Execution，CPU执行指令
4. Store，CPU将计算结果存回寄存器或将寄存器值存入内存
#### 指令类型
- 数据传输类型的指令
- 运算类型的指令
- 跳转类型的指令
- 信号类型的指令
- 闲置类型的指令
# 磁盘比内存慢几万倍？
### 储存器的层次结构
- 寄存器
- CPU Cache
  >1. L1 cache
  >2. L2 cache
  >3. L3 cache
- 内存
- SSD/HDD硬盘
#### 寄存器
最靠近CPU控制单元和逻辑单元的储存器，32位CPU中大多数寄存器可以储存**4个字节**，64位大多数可以储存**8个字节**
#### CPU Cache
SRAM静态随机储存器
**L1高速缓存**：通常缓存**指令缓存和数据缓存**
**L2高速缓存**：离核心更远，访问速度10-20时钟周期
**L3高速缓存**：多个CPU公用，访问速度20-60时钟周期
#### 内存
DRAM动态随机存取储存器，访问速度200~300时钟周期
#### SSD/HDD
内存读写速度是SSD的10-1000倍，HDD的10w倍
### 储存器的层次关系
# 如何写出让CPU跑得更快的代码
### CPU Cache的数据结构和读取过程是什么
CPU Cache的数据是从内存中读过来的，一小块一小块的**Cache Line**，CPU会顺序Cache Line中的数据。
CPU读取数据的时候，无论数据是否在Cache中，都是先访问Cache，没有数据时再去访问内存，加载到cache中
内存的访问地址，包括**组标记、CPU Cache Line、偏移量**组成，CPU通过这些信息，就能在CPU Cache中找到缓存的数据。对于CPU Cache中的数据结构，**则是引索+有效位+组标记+数据块**组成
### 如何写出让CPU跑的更快的代码
数据在CPU Cache中，意味着**缓存命中**，缓存命中率越高，代码性能就会更好
L1通常分为**数据缓存、指令缓存**，分开来看这两个的缓存命中率
#### 如何提升数据缓存的命中率
遇到遍历数组情况时，按照内存布局顺序访问，可以有效的利用CPU Cache带来的好处，提升代码性能
#### 如何提升指令缓存的命中率
**CPU分支预测器**可以分支预测接下来需要执行的的if/else里的数据，可以提前将指令放在指令缓存里，这样CPU可以直接从Cache读取到指令，执行速度就很快
#### 如何提升多核CPU的缓存命中率
如果一个线程在多个核心中切换，各个核心的命中率就会受到影响，如果线程都在一个核心上执行，其数据的L1和L2的缓存击中率就可以有效提高。当多个同时执行计算密集型的线程，可以把线程绑定在一个CPU核心上
# CPU缓存一致性
### CPU Cache的数据写入
#### 写直达
把数据同时写入Cache和内存中，很大影响性能
如果数据**已经**在Cache中，则先更新到Cache里，再写入内存；**没有**在Cache中，则直接把数据更新到内存里
#### 写回
当发生写操作时，新数据只写入Cache Block中，当修改过的Cache Block被替换时才写入内存
**先修改Cache中的数据**，然后通过脏位判断是否被修改过；若修改过写回主存，没修改过不必写回
CPU----->Cache------>主存
#### 缓存一致性问题
多个核心的L1，L2是独有的，一个核心操作了变量在L1中而没有写入内存，其他核心就会读取到错误的变量
- 当某个核心Cache的数据更新时，必须传播到其他Cache，被称为**写传播**
- 某个核心对数据的操作顺序，必须在其他核心看起来顺序一样，称为**事务串行化**
要实现事务串行化，要做到两点
- cpu核心对于cached数据的操作，必须同步给其他核心
- 要引入*锁*的概念，如果两个CPU核心有相同数据的cache，对于这个cache数据的更新，只有拿到了锁，才能进行对应的数据更新
### 总线嗅探
写传播的原则就是当某个CPU核心更新了cache的数据，要把该事件广播到其他核心，最常用的方法是**总线嗅探**
当核心A修改了L1中的数据，通过总线将这个时间广播给其他核心，其他核心都监听总线上的广播，检测并更新已有数据。CPU需要每时每刻监听总线上的一切活动，回加重总线负担
总线嗅探只保证了某个核心的cache更新这个事件被其他核心知道，不能保证事务串行化
### MESI协议
- Modified 已修改
- Exclusive 独占
- Shared 共享
- Invalidated 已失效
这四个状态标记cache line的四个不同的状态
**已修改**就是脏标记，代表该cache block中的数据已经被修改过了，但还没有写入内存；**已失效**代表该cache block中的数据已经失效，不可再读取
**独占、共享**状态都标识cache block中的数据是干净的，即内存和cache数据一致；**独占**状态数据只储存在一个核心的cache中，其他核心cache没有数据，该核心可以任意修改数据，当独占状态下的数据，如果有其他核心cache从内存中读取到，则会变为**共享**；共享状态下不能直接修改数据，而是要先向其他核心广播一个请求，将其他cache的cache line修改为*无效*状态，然后再更新数据
# CPU是如何执行任务的
### CPU如何读写数据
Cache<-Memory<-SSD/HHD
CPU Cache Line是CPU从内存读数据到Cache的，连续读取的一块一块的数据
#### 分析伪共享
多个线程同时读写一个Cache Line的不同变量时，导致CPU Cache失效的现象称之为**伪共享*false sharing***
#### 避免伪共享的方法
对于多个线程共享的热点数据，应当避免这些数据在同一个cache line中
Linux内核中存在`__cacheline_aligned_in_smp`宏定义，用于解决伪共享问题
- 多核系统中，该宏定义为cache line的大小
- 单核系统该宏定义是空的
为了防止伪共享现象，可以使用上面的宏定义让变量在cache line中对齐，使用空间换时间方法提升性能
或前置、后置填充cache line，使得整个cache line怎么加载都没有发生更新操作的数据，只要数据被频繁的读取访问，就没有数据被换出cache line，也不会产生伪共享的问题
### CPU如何选择线程的
linux内核中，进程和线程都是用`task_struct`结构体表示的，进程的task_struct里部分资源是共享了进程已创建的资源，比如内存空间地址、代码段等。没有创建线程的进程，只有单个执行流，被称为主线程，可以创建多个线程分别处理不同事情，对应到内核中都是`task_struct`
linux中任务分为两种，优先级数值越小，优先度越高
- 实时任务，对于系统响应时间要求很高，0-99
- 普通任务，响应时间没有很高的要求，100-139
#### 调度类
Deadline Deadline调度器 SCHED_DEADLINE dl_rq
Realtime RT调度器 SCHED_FIFO SCHED_RR rt_rq
Fair CFS调度器 SCHED_NORMAL SCHED_BATCH cfs_rq
Deadline和Realtime这两个调度类，都是应用于实时任务，共有三个调度策略
- SCHED_DEADLINE 按照deadline调度，距离当前时间点最近的deadline的任务会被优先执行
- SCHED_FIFO 对于相同优先级任务，按照FIFO原则，但是优先级更高的任务可以抢占低优先级的任务
- SCHED_RR 对于相同优先级的任务轮流运行，每个人物都有一定时间片，用完时间片的任务会被放到队列尾部，保证公平性，但是高优先级的任务可以抢占
Fair调度类用于普通任务，由CFS调度器管理
- SCHED_NORMAL 普通任务的调度策略
- SCHED_BATCH 后台任务的调度策略，不和终端进行交互，不影响其他需要交互的任务，可以适当降低优先级
#### 完全公平调度
给每个任务分配**vruntime**，CFS算法调度时，优先选择vruntime少的任务，一个任务运行时vruntime会增加
nice级别越低，任务权重值越大，高权重任务的vruntime少，CFS优先执行
#### CPU运行队列
每个cpu都有自己的运行队列RunQueue，用于描述此CPU上所运行的所有进程。
CFS运行队列cfs_rq是按照红黑树描述，按vruntime大小来描述的
调度类优先级Deadline>Realtime>Fair，Linux选择下一个任务执行的时候，先从dl_rq，然后rt_rq，最后cfs_rq，实时任务总是比普通任务先执行
#### 调整优先级
启动任务时没有指定调整优先级的话，默认都是普通任务Fair由CFS调度器管理，如果想要某个任务有更多执行时间，可以调整nice值，让优先值高的任务执行久一点
nice值是优先级的修正指数，priority(new) = priority(old) + nice，内核中nice范围值0-139，普通任务0-99，优先任务是100-139
不管怎么修改nice值，都是普通任务，可以修改任务优先级和调度策略，使得变成实时任务
# 什么是软中断
### 中断是什么
系统收到硬件的中断请求，会打断正在执行的过程，调用内核中的中断处理程序来响应请求。中断是一种异步的事件处理机制，可以提高系统的并发处理机制
中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度的影响
中断处理程序在响应中断时，还可能会临时关闭中断，意味着如果当前中断程序中没有执行完之前，系统中其他的中断请求都无法被响应，中断有可能会丢失
### 什么是软中断
Linux为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是**上半部和下半部**
- 上半部用来处理快速中断，一般会暂时关闭中断请求，主要负责处理和硬件相关或时间敏感的事情
- 下半部用来延迟处理上半部未完成的工作，一般为内核线程的方式运行
中断处理程序的上部分和下部分可以理解为
- 上半部直接处理硬件请求，硬中断，负责耗时短的工作，特点是快速执行
- 下半部分由内核触发，软中断，负责上半部未完成的工作，耗时较长，特点延迟执行
硬中断是打断CPU执行的任务，然后立刻执行中断处理程序，而软中断是由内核线程的方式执行的，每个CPU都有一个软中断内核线程
# 为什么0.1+0.2 ！= 0.3？
### 为什么负数要用补码表示
十进制转二进制采用除2取余法
补码就是把正数的二进制全部取反再+1
如果负数不是补码形式表示，那么再作基本加减法运算时候还需要判断是否为负数再反转，采用了补码则和正数加减法操作一致
### 十进制小数和二进制的转换
乘二取整法
使用二进制无法精确表示0.1，只能用近似值，就会造成精度损失
### 计算机是怎么存小数的
浮点数
- 符号位：表示数字正负，0正1负
- 指数位：指定小数点在数据中位置，指数可以为正数也可以为负数，指数位越长数据表示范围就越大
- 尾数位：小数点右侧数字，位数长度决定了数的精度
### 0.1 + 0.2 = 0.3吗
不等于
0.1和0.2是两个无限循环小数，计算机只能表示近似值，相加并不等于完整的二进制的0.3
# Linux内核 vs Windows内核
### 内核
内核作为应用链接硬件的桥梁，应用只需关系与内核交互，不用关心硬件的细节
内核有哪些能力
- 管理线程、进程，决定哪个线程、进程使用CPU，**进程调度**
- 管理内存，决定内存的分配和回收，**内存管理**
- 管理硬件，为进程和硬件之间提供通信能力，**硬件通信**
- 提供系统调用，程序和操作系统之间的接口
内核是怎么工作
- 内核空间，只有内核程序可以访问
- 用户空间，专门给应用程序使用
当程序使用用户空间时，常说该程序在**用户态**执行，使用内核空间时，程序则在**内核态**执行
### Linux的设计
Linux设计内核理念主要有几点
- Multitask 多任务
- SMP 对称多处理
- ELF 可执行文件连接格式
- Monolithic kernal 宏内核
#### Multitask
代表Linux是个多任务的操作系统
- 对于单核CPU，可以让每个任务执行一小段时间，时间到了就切换到另一个任务，宏观角度看这是一段时间内执行了多个任务，称之为并发
- 对于多核CPU，多个任务可以被不同核心CPU同时执行，称之为并行
#### SMP
对称多处理，代表每个CPU的地位、对资源使用权限相同，多个CPU共享一个内存，每个CPU都可以访问完整的内存和硬件资源
#### ELF
可执行文件连接格式
ELF将文件分成一个个分段，每个段都有自己的作用
ELF文件通过 编译器->汇编器->连接器 形成执行文件ELF
通过 装载器 将ELF装载到内存中
#### Monolithic Kernal
Linux的内核是个完整的可执行程序，有最高权限，宏内核特征是系统内核的所有模块，比如内存管理、进程调度、文件系统都运行在内核态
与宏内核相反的是微内核，只保留最基本的能力，比如进程调度、虚拟机内存等，将一些应用放到了用户空间。这样服务和服务之间是隔离的，提高了系统的稳定性可靠性
### Windows设计
windows内核是混合型内核，Windows的可执行文件叫PE，**可移植执行文件**
# 为什么要有虚拟内存
### 虚拟内存
进程把使用的地址隔离开来，让操作系统为每个进程分配一套独立的虚拟地址。操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来
- 程序使用的内存地址叫**虚拟内存地址**
- 实际存放在硬件里面的地址叫物理内存地址
操作系统通过MMU映射关系将虚拟地址转换为物理地址，通过**内存分段**和**内存分页**来管理虚拟地址和物理地址
### 内存分段
分段机制下虚拟地址由**段选择因子**和**段内偏移量**构成
- 段选择因子就保存在段寄存器里，段寄存器里最重要的是**段号**，用作段表的引索。**段表**里保存的是这个**段的基地址、段的界限和特权等级等**
- **段内偏移量**应当处于0和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理物理内存地址
内存分段存在不足之处
- 内存碎片
- 内存交换效率低
#### 内存分段会出现内存碎片吗
内存分段管理可以做到根据实际需求分配内存，**不会出现内部内存碎片**，但是每个段长度不固定，会出现**外部内存碎片**，通过内存交换解决（linux的swap）
#### 为什么分段会导致内存交换效率低
多进程系统分段产生大量外部内存碎片，需要内存交换的时候，要把大片连续内存写进硬盘，而硬盘读访问速度慢得多，如果内存交换的时候是交换的是占内存空间很大的程序，这样整个机器就会显得卡顿
### 内存分页
分页是把整个虚拟内存和物理内存切成一段段固定尺寸的大小。这样一个连续且尺寸固定的内存空间，叫做页
虚拟地址和物理地址之间通过页表来映射，页表保存在内存里，当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后返回用户空间，恢复进程的运行
#### 分页是怎么解决分段的外部内存和内存交换效率低的问题
内存分页采用预分配空间，页与页之间紧密排列没有内存空隙，**但是分页最小单位是一页，会造成内部内存碎片**
如果内存空间不够，会将最近没有使用的内存页面换出（swap out 写入硬盘），需要时再写入（swap in），一次写入磁盘的也只有少数几个页，提高了交换效率
分页使得加载程序时不用一次全部加载进物理内存，完全可以在进行虚拟内存映射后，只有在程序运行中需要用到对应虚拟内存里的指令和数据时，再加载到物理内存中
#### 分页机制下，虚拟地址和物理地址是怎么映射的
虚拟地址地址分为**页号**和**页偏移**，页号作为页表的引索，页表包含物理页每页所在的物理内存的及地址，基地址和页内偏移的组合就形成了物理内存地址
#### 简单分页有什么缺陷吗
页表空间占用大，运行进程越多，占用越大
#### 多级页表 
对于32位系统，将页表的单机页表再分页，将页表（一级页表）分为1024个页表（二级页表），每个页表中包含1024个页表项，形成二级分页
使用了二级分页，一级页表就可以覆盖整个4GB虚拟内存空间，但如果某个一级页表的页表项没有被用到，也就不需要创建二级页表了
对于64位系统，分为四级目录
- 全局页目录项PGD
- 上层页目录项PUD
- 中间页目录项PMD
- 页表项PTE
#### TLB
在CPU中放入一个专门存放最常访问的页表项的Cache，这个Cache就是TLB，通常被称为页表缓存、转址旁路缓存、快表等
### 段页式内存管理
内存分段和内存分页组合起来使用就称之为段页式内存管理
- 先将程序划分为多个有逻辑意义的段
- 再把每个段分为多个页
这样地址结构就由**段号、段内页和页内偏移**三个部分组成
### Linux内存布局
Linux主要采用了分页管理，但是无法避免分段管理，Linux把所有段基地址设为0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），段只用于访问控制和内存保护
Linux中虚拟空间分为**用户态**和**内核态**，用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区
# malloc是如何分配内存的
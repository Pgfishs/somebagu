# cpu是如何执行程序的
### 冯诺依曼模型
五个部分**运算器、控制器、储存器、输入设备、输出设备**。
运算器、控制器在中央处理器中，储存器就是常见的内存，输入输出设备是计算机外接的设备。储存单元和输入输出设备要与中央处理器打交道，离不开总线
#### 内存
储存的区域是线性的，储存数据的基本单位是**字节***byte*，一字节等于八位（8bit），每一个字节对应一个内存地址，从0开始
#### 中央处理器
32位cpu一次可以处理4个字节，64位一次可以处理8个字节，32位和64位代表CPU的位宽，位宽越大，可以计算的数值就越大。
cpu内部还有一些组件，常见的有**寄存器、控制单元、逻辑运算单元**。其中控制单元负责控制CPU工作，逻辑单元负责计算，寄存器又可以分为多种类，每种功能不同，紧挨着控制单位和逻辑运算单元
**常见寄存器种类**
* *通用寄存器*，用来存放需要运算的数据
- *程序计数器*，储存cpu要执行的下一条指令**所在的内存地址**
- *指令寄存器*，用来存放正在执行的指令
#### 总线
用于cpu和内存和其他设备之间的通信，可分为三种
- **地址总线**，用于指定CPU将要操作的内存地址
- **数据总线**，用于读写内存数据
- **控制总线**，用于发送和接收信号
CPU读写内存时，依次经过**地址总线-控制总线-数据总线**
### 程序执行的基本过程
CPU根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器中执行，然后指令长度自增，开始顺序读取下一条指令，这个循环过程叫**CPU的指令周期**
### a = 1 + 2执行过程
- 编译器先将数据1和数据2放到**数据段**中
- 编译器将 a=1+2编译为四个指令
  > load指令将地址1中的数据1装入寄存器R0
  > load指令将地址2中的数据2装入寄存器R1
  > add将R0 R1数据相加放入寄存器R2
  > store指令将R2数据存回数据a对应的地址中
- 编译完后，运行程序时程序计数器将地址设置为0x100地址，然后依次执行这4条指令
#### 指令
MIPS指令是32位的整数，高6位代表着操作码，剩下26位不同指令类型所表示内容也不同，主要有R、I、J三种
- **R指令**，用在算数和逻辑操作，有读取和写入数据的内存地址
- **I指令**，用在数据传输、条件分支等
- **J指令**，用在跳转，高6位之外的26位都是一个跳转后的地址
CPU构造指令流水线通常被分为四个阶段
1. Fetch，CPU通过程序计数器读取对应内存地址的指令
2. Decode，CPU对指令进行解码
3. Execution，CPU执行指令
4. Store，CPU将计算结果存回寄存器或将寄存器值存入内存
#### 指令类型
- 数据传输类型的指令
- 运算类型的指令
- 跳转类型的指令
- 信号类型的指令
- 闲置类型的指令
# 磁盘比内存慢几万倍？
### 储存器的层次结构
- 寄存器
- CPU Cache
  >1. L1 cache
  >2. L2 cache
  >3. L3 cache
- 内存
- SSD/HDD硬盘
#### 寄存器
最靠近CPU控制单元和逻辑单元的储存器，32位CPU中大多数寄存器可以储存**4个字节**，64位大多数可以储存**8个字节**
#### CPU Cache
SRAM静态随机储存器
**L1高速缓存**：通常缓存**指令缓存和数据缓存**
**L2高速缓存**：离核心更远，访问速度10-20时钟周期
**L3高速缓存**：多个CPU公用，访问速度20-60时钟周期
#### 内存
DRAM动态随机存取储存器，访问速度200~300时钟周期
#### SSD/HDD
内存读写速度是SSD的10-1000倍，HDD的10w倍
### 储存器的层次关系
# 如何写出让CPU跑得更快的代码
### CPU Cache的数据结构和读取过程是什么
CPU Cache的数据是从内存中读过来的，一小块一小块的**Cache Line**，CPU会顺序Cache Line中的数据。
CPU读取数据的时候，无论数据是否在Cache中，都是先访问Cache，没有数据时再去访问内存，加载到cache中
内存的访问地址，包括**组标记、CPU Cache Line、偏移量**组成，CPU通过这些信息，就能在CPU Cache中找到缓存的数据。对于CPU Cache中的数据结构，**则是引索+有效位+组标记+数据块**组成
### 如何写出让CPU跑的更快的代码
数据在CPU Cache中，意味着**缓存命中**，缓存命中率越高，代码性能就会更好
L1通常分为**数据缓存、指令缓存**，分开来看这两个的缓存命中率
#### 如何提升数据缓存的命中率
遇到遍历数组情况时，按照内存布局顺序访问，可以有效的利用CPU Cache带来的好处，提升代码性能
#### 如何提升指令缓存的命中率
**CPU分支预测器**可以分支预测接下来需要执行的的if/else里的数据，可以提前将指令放在指令缓存里，这样CPU可以直接从Cache读取到指令，执行速度就很快
#### 如何提升多核CPU的缓存命中率
如果一个线程在多个核心中切换，各个核心的命中率就会受到影响，如果线程都在一个核心上执行，其数据的L1和L2的缓存击中率就可以有效提高。当多个同时执行计算密集型的线程，可以把线程绑定在一个CPU核心上
# CPU缓存一致性
### CPU Cache的数据写入
#### 写直达
把数据同时写入Cache和内存中，很大影响性能
如果数据**已经**在Cache中，则先更新到Cache里，再写入内存；**没有**在Cache中，则直接把数据更新到内存里
#### 写回
当发生写操作时，新数据只写入Cache Block中，当修改过的Cache Block被替换时才写入内存
**先修改Cache中的数据**，然后通过脏位判断是否被修改过；若修改过写回主存，没修改过不必写回
CPU----->Cache------>主存
#### 缓存一致性问题
多个核心的L1，L2是独有的，一个核心操作了变量在L1中而没有写入内存，其他核心就会读取到错误的变量
- 当某个核心Cache的数据更新时，必须传播到其他Cache，被称为**写传播**
- 某个核心对数据的操作顺序，必须在其他核心看起来顺序一样，称为**事务串行化**
要实现事务串行化，要做到两点
- cpu核心对于cached数据的操作，必须同步给其他核心
- 要引入*锁*的概念，如果两个CPU核心有相同数据的cache，对于这个cache数据的更新，只有拿到了锁，才能进行对应的数据更新
### 总线嗅探
写传播的原则就是当某个CPU核心更新了cache的数据，要把该事件广播到其他核心，最常用的方法是**总线嗅探**
当核心A修改了L1中的数据，通过总线将这个时间广播给其他核心，其他核心都监听总线上的广播，检测并更新已有数据。CPU需要每时每刻监听总线上的一切活动，回加重总线负担
总线嗅探只保证了某个核心的cache更新这个事件被其他核心知道，不能保证事务串行化
### MESI协议
- Modified 已修改
- Exclusive 独占
- Shared 共享
- Invalidated 已失效
这四个状态标记cache line的四个不同的状态
**已修改**就是脏标记，代表该cache block中的数据已经被修改过了，但还没有写入内存；**已失效**代表该cache block中的数据已经失效，不可再读取
**独占、共享**状态都标识cache block中的数据是干净的，即内存和cache数据一致；**独占**状态数据只储存在一个核心的cache中，其他核心cache没有数据，该核心可以任意修改数据，当独占状态下的数据，如果有其他核心cache从内存中读取到，则会变为**共享**；共享状态下不能直接修改数据，而是要先向其他核心广播一个请求，将其他cache的cache line修改为*无效*状态，然后再更新数据
# CPU是如何执行任务的
### CPU如何读写数据
Cache<-Memory<-SSD/HHD
CPU Cache Line是CPU从内存读数据到Cache的，连续读取的一块一块的数据
#### 分析伪共享
多个线程同时读写一个Cache Line的不同变量时，导致CPU Cache失效的现象称之为**伪共享*false sharing***
#### 避免伪共享的方法
对于多个线程共享的热点数据，应当避免这些数据在同一个cache line中
Linux内核中存在`__cacheline_aligned_in_smp`宏定义，用于解决伪共享问题
- 多核系统中，该宏定义为cache line的大小
- 单核系统该宏定义是空的
为了防止伪共享现象，可以使用上面的宏定义让变量在cache line中对齐，使用空间换时间方法提升性能
或前置、后置填充cache line，使得整个cache line怎么加载都没有发生更新操作的数据，只要数据被频繁的读取访问，就没有数据被换出cache line，也不会产生伪共享的问题
### CPU如何选择线程的
linux内核中，进程和线程都是用`task_struct`结构体表示的，进程的task_struct里部分资源是共享了进程已创建的资源，比如内存空间地址、代码段等。没有创建线程的进程，只有单个执行流，被称为主线程，可以创建多个线程分别处理不同事情，对应到内核中都是`task_struct`
linux中任务分为两种，优先级数值越小，优先度越高
- 实时任务，对于系统响应时间要求很高，0-99
- 普通任务，响应时间没有很高的要求，100-139
#### 调度类
Deadline Deadline调度器 SCHED_DEADLINE dl_rq
Realtime RT调度器 SCHED_FIFO SCHED_RR rt_rq
Fair CFS调度器 SCHED_NORMAL SCHED_BATCH cfs_rq
Deadline和Realtime这两个调度类，都是应用于实时任务，共有三个调度策略
- SCHED_DEADLINE 按照deadline调度，距离当前时间点最近的deadline的任务会被优先执行
- SCHED_FIFO 对于相同优先级任务，按照FIFO原则，但是优先级更高的任务可以抢占低优先级的任务
- SCHED_RR 对于相同优先级的任务轮流运行，每个人物都有一定时间片，用完时间片的任务会被放到队列尾部，保证公平性，但是高优先级的任务可以抢占
Fair调度类用于普通任务，由CFS调度器管理
- SCHED_NORMAL 普通任务的调度策略
- SCHED_BATCH 后台任务的调度策略，不和终端进行交互，不影响其他需要交互的任务，可以适当降低优先级
#### 完全公平调度
给每个任务分配**vruntime**，CFS算法调度时，优先选择vruntime少的任务，一个任务运行时vruntime会增加
nice级别越低，任务权重值越大，高权重任务的vruntime少，CFS优先执行
#### CPU运行队列
每个cpu都有自己的运行队列RunQueue，用于描述此CPU上所运行的所有进程。
CFS运行队列cfs_rq是按照红黑树描述，按vruntime大小来描述的
调度类优先级Deadline>Realtime>Fair，Linux选择下一个任务执行的时候，先从dl_rq，然后rt_rq，最后cfs_rq，实时任务总是比普通任务先执行
#### 调整优先级
启动任务时没有指定调整优先级的话，默认都是普通任务Fair由CFS调度器管理，如果想要某个任务有更多执行时间，可以调整nice值，让优先值高的任务执行久一点
nice值是优先级的修正指数，priority(new) = priority(old) + nice，内核中nice范围值0-139，普通任务0-99，优先任务是100-139
不管怎么修改nice值，都是普通任务，可以修改任务优先级和调度策略，使得变成实时任务
# 什么是软中断
### 中断是什么
系统收到硬件的中断请求，会打断正在执行的过程，调用内核中的中断处理程序来响应请求。中断是一种异步的事件处理机制，可以提高系统的并发处理机制
中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度的影响
中断处理程序在响应中断时，还可能会临时关闭中断，意味着如果当前中断程序中没有执行完之前，系统中其他的中断请求都无法被响应，中断有可能会丢失
### 什么是软中断
Linux为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是**上半部和下半部**
- 上半部用来处理快速中断，一般会暂时关闭中断请求，主要负责处理和硬件相关或时间敏感的事情
- 下半部用来延迟处理上半部未完成的工作，一般为内核线程的方式运行
中断处理程序的上部分和下部分可以理解为
- 上半部直接处理硬件请求，硬中断，负责耗时短的工作，特点是快速执行
- 下半部分由内核触发，软中断，负责上半部未完成的工作，耗时较长，特点延迟执行
硬中断是打断CPU执行的任务，然后立刻执行中断处理程序，而软中断是由内核线程的方式执行的，每个CPU都有一个软中断内核线程
# 为什么0.1+0.2 ！= 0.3？
### 为什么负数要用补码表示
十进制转二进制采用除2取余法
补码就是把正数的二进制全部取反再+1
如果负数不是补码形式表示，那么再作基本加减法运算时候还需要判断是否为负数再反转，采用了补码则和正数加减法操作一致
### 十进制小数和二进制的转换
乘二取整法
使用二进制无法精确表示0.1，只能用近似值，就会造成精度损失
### 计算机是怎么存小数的
浮点数
- 符号位：表示数字正负，0正1负
- 指数位：指定小数点在数据中位置，指数可以为正数也可以为负数，指数位越长数据表示范围就越大
- 尾数位：小数点右侧数字，位数长度决定了数的精度
### 0.1 + 0.2 = 0.3吗
不等于
0.1和0.2是两个无限循环小数，计算机只能表示近似值，相加并不等于完整的二进制的0.3
#
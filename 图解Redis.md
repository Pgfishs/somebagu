# Redis
### 什么是redis
基于内存的数据库，对数据的读写都是在内存中完成的，读写速度非常快，用于缓存、消息队列、分布式锁登场景
redis提供了多种数据类型，String、Hash、List、Set、Zset、Bitmaps、HyperLogLog、GEO、Stream，对数据类型的操作都是原子性的，因为**执行命令由单线程负责**，不存在并发竞争的问题
redis还支持事务、持久化、lua脚本、多种集群方案、发布/订阅模式、内存淘汰机制、过期删除机制等
### 和memcached异同
1. 都是基于内存的数据库，当做缓存使用
2. 都有过期策略
3. 高性能
区别
- redis数据更丰富，memcached只支持k-v数据结构
- redis支持持久化，保存在磁盘中，memcached挂掉后数据就没了
- redis原生支持集群模式，memcached需要依赖客户端实现往集群中分片写入数据
- redis支持订阅发布模型、lua脚本、事务等功能
### 为什么用redis作为mysql缓存
1. redis具备高性能。将访问数据缓存在redis中，下次访问时直接从缓存中读取，mysql数据改变后同步改变redis中数据即可，会有双写一致性问题
2. redis具备高并发。redis的qps可以破10w，而mysql很难破1w
# Redis数据结构
- String：缓存对象、常规计数、分布式锁、共享session等
- List：消息队列（生产者需要自行实现全局唯一ID，不能以消费组形式消费数据）
- Hash：缓存对象、购物车等
- Set：聚合计算（并集、交集等），比如点赞、共同关注等
- Zset：排序场景，比如排行榜、电话和姓名排序
以上是五种常见数据类型
----------
- BitMap：二值状态统计，比如签到、判断登陆状态、签到用户数等
- HyperLogLog：海量数据基数统计场景，比如百万级网页UV计数
- GEO：储存地理位置信息，比如嘀嘀打车
- Stream：消息队列（实现List没有的两个特性）
### 五种常见数据类型的实现
#### String
基于SDS简单动态字符串
- SDS可以保存二进制数据。使用len而非空字符判断是否结束，SDS所有API会处理二进制方式处理SDS存放在buf数组的数据，所以SDS还可以保存图片、音频、视频这样二进制数据
- SDS获取字符串长度的时间复杂度是O(1)
- SDS API是安全的，拼接字符串不会导致缓冲区溢出
#### List
双向链表或压缩列表
- 列表元素小于512个且每个元素值小于64，使用压缩列表
- 不满足上面使用双向链表
在3.2版本后，只用quicklist实现，代替了双向链表和压缩列表
#### Hash
压缩列表或哈希表
- 列表元素小于512个且每个元素值小于64，使用压缩列表
- 不满足上面使用哈希表
在7.0中压缩列表被listpack实现
#### Set
哈希表或整数集合
- 元素都是整数且个数小于512，使用整数集合
- 否则使用哈希表
#### Zset
压缩列表或跳表
- 元素小于128个且值小于64字节，使用压缩列表
- 否则使用跳表
7.0中由listpack实现压缩列表
# Redis线程模型
### Redis是单线程吗
redis单线程是指**接受请求->解析请求->读写操作->发送数据**这个过程是由主线程完成的，redis程序并不是单线程的，会**启动后台线程**BIO
- 2.6版本会启动两个后台线程，分别处理关闭文件、AOF刷盘
- 4.0以后新增线程，异步释放Redis内存，即lazyfree线程。删除线程会交给后台线程执行，不会造成主线程卡顿，删除大key时用unlink异步删除大key
redis创建单独线程处理耗时任务，避免造成主线程卡顿，后台线程相当于消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）轮询队列
关闭文件、AOF刷盘、释放内存三个任务有各自任务队列
### Redis单线程模式
redis首先初始化，创建socket并监听、注册连接事件处理函数，初始化结束后进入**事件循环函数**：
- 调用**处理发送队列函数**，发送队列中存在的任务，即通过write将客户端发送缓存区中数据发送，没发送完则注册写事件处理函数，等待epoll_wait发现可写后在处理
- 调用epoll_wait函数
	- 链接事件则调用**连接事件处理函数**，调用accept获取已连接socket->调用epoll_ctl将socket加入epoll->注册读事件处理函数
	- 读事件则调用读事件处理函数，调用read获取发送的数据->解析->处理->添加客户端对象至发送队列->写入执行结果到发送等待区等待发送
	- 写事件调用写事件处理函数，通过write发送客户端发送缓存区数据，没发送完则注册写事件处理函数，等待epoll_wait发现可写后在处理
### Redis单线程高QPS原因
- 大部分操作在内存中完成，采用了高效数据结构，瓶颈可能是内存或网络带宽
- 单线程避免了多线程竞争，省去了多线程切换带来的开销也避免了死锁
- 采用I/O多路复用机制处理客户端Socket请求
### redis6.0之前为什么使用单线程
CPU不是制约redis性能的瓶颈，多线程模型会带来并发读写的问题，增加系统复杂度，存在线程切换，甚至加锁解锁，死锁造成的性能损耗
### 6.0之后为什么引入了多线程
采用了多个IO线程处理网络请求，对于命令的执行仍然使用单线程
6.0以后启动redis时会创建额外6个线程，三个后台线程和三个IO线程
# Redis持久化
### redis如何实现数据不丢失
- AOF快照：每执行一条写操作命令，就把该命令以追加形式写入一个文件
- RDB快照：将某一时刻内存数据以二进制写入磁盘
- 混合持久化方式：集成AOF和RBD
### AOF日志的实现
执行完写操作后，将命令以追加方式写入文件，当Redis重启时会读取该文件记录的命令，逐一执行命令进行数据恢复
#### 为什么先执行命令再写入日志
- 避免额外检查开销。如果先写入日志，则需要进行语法检查造成额外开销，避免读取时出错
- 不会阻塞当前写操作命令的执行，当写成功后，才会记录到AOF日志
- **数据可能会丢失**。这两个操作不是一个原子操作，当没来得及将命令写入硬盘时服务器宕机，则会丢失数据
- **可能阻塞其他操作**。写成功后才记录到AOF日志，不会阻塞当前命令执行，但写入AOF的操作也是在主线程中执行，可能会阻塞后续操作
#### AOF写回策略
redis执行完写操作后将命令追加server.aof_buf缓冲区->write()系统调用，将缓冲区数据写入AOF文件，拷贝内核缓冲区pagecache等待内核写入硬盘->*内核决定何时写入硬盘*
redis三种写回策略，控制第三步过程
- Always：每次写命令执行完后同步AOF写回硬盘，可靠性高，但是性能开销大
- Everysec：写命令执行完后写入AOF文件内核缓冲区，每隔一秒写回硬盘，性能始终，宕机时会丢失1s内数据
- No：写命令执行完后写入AOF缓冲区，由操作系统决定何时写入硬盘
#### AOF日志过大触发机制
AOF重写机制，当文件大小超过阈值后触发，压缩AOF文件
再重写时，读取当前数据库中所有键值对，对每个键值对用命令写入到新AOF文件中，写完全部记录后用新AOF文件代替现有AOF文件
#### 重写AOF日志过程
后台子进程bgwriteaof完成
- 子进程重写AOF，避免阻塞主进程
- 子进程带有主进程数据副本，不使用线程避免修改共享内存，若使用线程需要加锁导致性能降低；而进程共享内存数据且只读，保证数据安全
重写过程中，主进程依然可以正常处理命令，redis设置AOF重写缓冲区避免主进程修改k-v导致和子进程数据不一致，缓冲区在创建后台子进程后建立。在重写AOF期间，redis主线程执行完命令后会写入AOF缓冲区和AOF重写缓冲区
子进程完成重写后，异步发送信号给主线程，主线程调用函数：
- 将AOF重写缓冲区中内容追加到新AOF文件中，使新旧AOF文件保存数据库状态一致
- 新AOF进行改名，覆盖现有AOF文件
### RDB快照实现
RDB快照记录某个瞬间内存数据，是实际数据，AOF保存命令操作日志。RDB恢复数据效率比AOF高
#### RDB快照会阻塞线程吗
通过save和bgsave生成RDB文件，区别在于是否在主线程中执行
- save在主线程中生成RDB文件，写入RDB时间太长会阻塞主线程
- bgsave创建子进程生成RDB文件，可以避免主线程阻塞，可通过配置文件实现自动执行bgsave
redis快照是**全量快照**，保存内存中所有数据到磁盘中，过于频繁的快照会对性能产生影响
#### RDB执行快照时可以修改数据吗
写时复制计数COW，可以继续处理操作命令
fork创建子进程，复制父进程页表，指向物理内存是同一个，如果主线程读操作，则主线程和bgsave进程互不影响；如果是写操作，修改的数据会创建副本，bgsave进程写入RDB文件，这个过程中主线程仍可以修改原来数据
#### 混合持久化
使用了混合持久化，AOF文件的前半部分是RDB格式的全量数据，后半部分是AOF格式增量数据，加载时速度会快
- 结合RDB和AOF优点，加快启动速度，降低大量数据丢失风险
- AOF文件添加了RDB格式内容，可读性变差
- 兼容性差，不能用在4.0之前版本
# Redis集群
### redis服务高可用
#### 主从复制
一主多从模式，主从服务器之间采用读写分离方式。主服务器进行读写操作，写操作时主服务器同步给从服务器，从服务器一般是只读，接收主服务器命令并执行
所有数据修改只在主服务器进行，然后将新数据同步给从服务器，主从之间命令复制是异步进行的
主服务器不会等待从服务器执行完写命令再返回服务器，而是本地执行完后就返回结果，从服务器如果没有及时执行命令就会导致主从之间数据不一致
#### 哨兵模式
哨兵模式可以监控主从服务器，提供主从节点故障转移的功能
#### 切片集群模式
Redis Cluster采用哈希槽处理数据和节点之间的关系，一个集群有16384个哈希槽，哈希槽类似数据分区，每个k-v值根据key映射到哈希槽中
- 根据键值对的key按照CRC16计算一个16bit值
- 值对16384取模，模数对应相应编号哈希槽
哈希槽有两种分配模式
- 平均分配：redis自动把哈希槽平均到节点上
- 手动分配：cluster meet命令手动建立节点，再addslots指定哈希槽个数
### 集群脑裂
#### 脑裂
redis主从架构中，一般都是一主多从，主节点提供写操作，从节点提供读操作，如果主节点与从节点失联，但主节点和客户端链接正常，客户端并不知道redis内部发生问题，还在写数据，都被缓存到旧主节点缓冲区中，无法同步给从节点
从节点也发现主节点失联，于是重新选举主节点，此时集群两个主节点就产生了**脑裂**；网络好了后，旧主节点会被降级成从节点，然后回向新主节点全量同步（清楚本地数据），导致先前写入的客户端数据丢失
**解决方案**
当主节点发现从节点下线或通信超时总数量小于阈值时，禁止主节点写操作，返回客户端错误；通过redis参数调节
- min-slaves-to-write x，主节点必须有x从节点链接，否则禁止写数据
- min-slaves-max-lag x，主从数据复制和同步延迟不能超过x秒，否则禁止写数据
即使原主库加固在，也会被限制写入，只有新主库上线时，新主库才能接受数据和处理请求，新数据会直接写入新主库中，从主库会被哨兵降级为从库
# Redis过期删除和内存淘汰
### 过期删除策略
对key设置过期时间时，redis会把该key带上过期时间存到一个**过期字典**中，当查询一个key是，首先检测是否存在过期字典中，不在则正常读取；存在则判定过期时间并对比
redis采用的过期删除策略是**惰性删除+定期删除**搭配使用
##### 惰性删除
不主动删除过期键，每次从数据库访问key时，检测是否过期，过期则删除key
- 优点：每次访问时才检测key是否过期，只会占用很少系统资源，对CPU时间最友好
- 缺点：key已经过期而又存在数据库中，只要这个过期key一直不被访问，占用的内存就不会释放，造成内存空间浪费，对内存不友好
##### 定期删除
每隔一段时间*随机*从数据库中取出一定的key检查并删除过期key
- 从过期字典中选择20个key
- 检查是否过期并删除
- 如果本轮检查已过期数量超过25%则重复检查，如果小于25%则停止检查等待下一轮检查时间到
- 优点：通过限制删除操作执行的时长和频率，减少操作对CPU的影响，也能减少一部分空间无效占用
- 缺点：难以确定删除操作执行时长和频率。太平凡则对CPU不友好，太少又对内存不友好
### 持久化对过期键处理
**RDB**：
- 生成阶段：过期间不会被保存到新RDB文件中
- 加载阶段：
	- 主服务器：载入RDB文件时，会对文件中保存的key进行检查，过期键不会被载入数据库中
	- 从服务器：载入时无论是否过期都会被载入数据库，但主从同步时，从服务器数据会被删除，所以不会造成影响
**AOF**：
- 写入阶段：如果某个过期key没被删除，AOF会保留该key，当过期键被删除后，会追加一条DEL命令显式删除该键
- 重写阶段：重写时会检查redis中键值，已过期的键不会被保存到重写后AOF文件中
### 主从模式对过期键处理
从库不会进行过期扫描，对过期的处理是**被动的**；主库再key到期时，会在AOF文件中增加一条del指令，同步到所有的从库，从库再执行命令删除
### redis内存满了会怎么样
触发内存淘汰机制，配置项maxmemory
### redis过期淘汰策略
##### 不进行数据淘汰的策略
- noeviction（3.0后默认）：当运行内存超过最大设置内存时，不淘汰数据，而是不再提供服务直接返回错误
##### 进行数据淘汰的策略
在设置了过期时间的数据中淘汰
- volatile-random：随机淘汰设置了过期时间的任意键值
- volatile-ttl：优先淘汰更早过期的键值
- volatile-lru：淘汰所有设置了过期时间键值中最久未使用的键值
- volatile-lfu：最少被使用的键值
所有数据范围内进行淘汰
- allkeys-random：随机淘汰任意键值
- allkeys-lru：最久未使用
- allkeys-lfu：最少被使用
### LRU LFU
传统LRU基于链表实现，淘汰最近最少使用数据，存在额外空间开销和链表移动操作带来的耗时
redis使用**近似LRU**算法，实现方式时在redis对象结构体中添加一个额外字段，记录此数据最后一次访问时间，使用随机采样方式淘汰数据，但是无法解决缓存污染问题，通过了**LFU**解决
redis的lru算法多记录了数据访问频次信息，redis对象头中的lru字段，在LRU和LFU算法下使用方式不同
**LRU**算法中，lru字段用来记录key的访问时间戳，在lru模式下redis可根据字段的值比较最后一次key的访问时间
**LFU**算法中，24bit的lru字段分为两段来储存，高16bit存储key访问时间戳，低8bit储存访问频次
# Redis缓存设计
### 缓存雪崩
当大量缓存数据在同一时期过期，如果又有大量用户请求，都无法在redis处理，于是请求直接访问数据库导致压力骤增，严重时导致数据库宕机，形成连锁反应造成系统奔溃，这就是缓存雪崩
可以通过两种方式解决
- 打乱缓存失效时间：在原有失效时间上增加一个随机值，降低集体失效概率
- 设置缓存不过期：设置后台服务更新缓存数据，避免缓存雪崩
### 缓存击穿
缓存中某个**热点数据过期**，大量请求访问了这个热点数据，就无法从缓存中读取，直接访问数据库，导致数据库被高并发请求冲垮，这就是缓存击穿问题
- 互斥锁方案，保证同一时间只有一个业务线程请求缓存；未能获取锁的请求要么等待释放后重新获取缓存，要么返回空值
- 不给热点数据设置过期时间，后台异步更新缓存，或在要过期前，通知后台线程更新缓存和重新设置时间
### 缓存穿透
访问的数据**既不在缓存中，也不再数据库中**，导致请求访问缓存时，发现缓存缺失，而数据库中也没数据，服务后续请求，这样大量请求到来时，数据库压力骤增，这就是缓存穿透
发生缓存穿透两种情况
- 业务误操作，删除了缓存和数据库中数据
- 黑客攻击，恶意访问大量不存在数据的业务
三种解决方案
- 限制非法请求，在API入口处就判断参数是否合理
- 设置空值或默认值，后续请求读取时就读到空值或默认值，不会查询数据库
- 使用布隆过滤器判断数据是否存在，避免通过查询判断数据是否存在：业务线程确认缓存失效后，通过查询布隆过滤器判断数据是否存在，即使发生缓存穿透，请求也只会查询redis和过滤器
### 设计一个缓存策略缓存热点数据
总体思路：通过数据最新访问时间做排名，过滤掉不常访问的数据，只留下经常访问的数据
### 常见缓存更新策略
- Cache Aside旁路缓存
- Read/Write Through 读/写穿透策略
- Write Back写回策略
最常用的是**旁路缓存**策略，程序直接和数据库、缓存交互，负责对缓存的维护，又课细分为*读策略*和*写策略*
**写策略步骤**：
- 先更新数据库中数据，再删除缓存数据
**读策略步骤**：
- 如果读取数据命中缓存，则直接返回数据
- 没有命中缓存，则从数据库中读取数据并写入内存，返回给用户
为什么*先更新数据库再删除缓存*不会导致数据不一致：概率不高，缓存写入远快于数据库写入，很难出现一边更新了数据库/删除缓存后，另一边才更新完缓存
旁路缓存适合读多写少场景，写入频繁时缓存会被频繁清理，对命中率有影响，如果对命中率有要求，有两种解决方案
- 更新数据时也更新缓存，在更新缓存前先加一个分布式锁，避免并发，对写入性能有影响
- 给缓存加一个较短过期时间，即使出现缓存不一致，缓存的数据也很快会过期
**读穿/写穿策略**
应用程序只和缓存交互，不和数据库交互，由缓存和数据库交互
**Read Through**策略：
- 先查询缓存中是否存在数据，存在则直接返回，不存在则由缓存数据负责从数据库中查询数据并将结果写入缓存组件，最后由缓存组件返回数据
**Write Through**：
- 如果缓存数据已存在，则更新数据并由缓存组件同步更新到数据库中，然后缓存组件告诉程序更新完成
- 不存在则直接更新数据库，然后返回
**WriteBack写回策略**
只更新缓存，将缓存数据设置为脏，然后立刻返回，对于数据库采用批量异步更新方式
写回策略不能用到常用数据库和缓存中，redis不支持异步更新，是CPU缓存、OS文件系统常用策略
特别适合写多场景，但数据不是强一致的，且有丢失风险
# Redis实战
### 延迟队列
把当前做的事情，延迟一定时间再做，比如下单超时、取消订单等
通过Zset有序集合实现，有一个Score属性存放延迟执行时间，使用zadd生产消息，再利用zrangebyscore查询符合条件的待处理任务
### Redis大key处理
指key对应value很大，一般两种情况
- String值大于10KB
- Hash、List、Set、Zset元素个数超过5000
会带来四个影响
- 客户端超时阻塞：redis单线程操作大key费时，从客户端看就是没有响应
- 引发网络阻塞：每次获取大key产生流量较大
- 阻塞工作线程：del删除大key时会阻塞工作线程
- 内存分布不均：集群在slot分片均匀情况下会出现数据和查询倾斜情况，部分大key占用节点多，qps大
通过redis -cli --bigkeys/SCAN/RdbTools查找大key
通过分批次删除/异步删除来删除大key
### Redis管道
一次处理多个redis命令，可以解决多个命令执行时网络等待，要注意避免发送命令过大或数据太多造成管道阻塞
### redis事务支持回滚吗
没有提供回滚机制，DISCARD命令只支持放弃事务，清空暂存命令队列，无法回滚
### 使用redis实现分布式锁
SETNX，如果key存在则插入成功（加锁成功），不存在则插入失败（加锁失败）
对于加锁操作，要满足三个条件
- 加锁包括读取锁变量、检查、设置三个操作，但需要原子操作，所以使用SET+NX实现
- 锁变量需要设置过期时间，以免无法释放锁
- 锁变量值需要区分不同客户端加锁操作，避免误释放，通过SET设置变量时，每个客户端都是唯一值
redis实现分布式锁的优点
- 性能高
- 实现方便
- 避免单点故障
	缺点
- 超时时间不好设置。可通过设置守护线程判断锁状态续约
- 主从复制模式数据异步复制，导致分布式锁不可靠性
#### 如何解决分布式锁可靠性
让客户端和多个独立Redis节点依次请求申请加锁，如果客户端能和半数以上节点成功加锁，就认为成功获得分布式锁
加锁成功后，重新计算有效时间，避免锁失效；加锁失败则发起释放锁操作
# Redis常见数据类型
### String
基本k-v结构，不仅是字符串，还可以是整数或浮点数，最大数据长度是512M
#### 内部实现
int和SDS(简单动态字符串)
- SDS可以保存二进制数据（图片、音频等）
- SDS获取字符长度O(1)
- SDS API安全，拼接字符串不会缓冲区溢出
内部编码有三种：int、raw、embstr
字符串保存**整数值**，且可以用long表示时，会将整数值保存在字符串对象结构的ptr中，编码设置为int
字符串保存的是**字符串，且长度≤32字节**，会使用SDS保存，并设置编码为embstr；如果大于32字节，会使用SDS保存，且设置编码为raw
embstr&raw在不同版本边界不同，2+为32、3-4为39、5.0为40字节
embstr使用一次内存分配函数分配**连续内存空间**保存redisObject和SDS，而raw使用两次内存分配**两块内存空间**保存redisObject和SDS
embstr创建分配内存、释放内存的操作只要一次，且因为连续内存使得embstr可以更好利用CPU缓存；但缺点是字符串长度增加时需要重新分配内存，所以embstr编码是只读的，使用append增加时会先转为raw再修改
#### 应用场景
**缓存对象**：缓存整个对象JSON；将key分离为对象属性，采用MSET保存
**常规计数**：计算访问次数、点赞、转发、库存等情况
**分布式锁**：SETNX
**共享session信息**：分布式系统服务器获取用户session
### List
字符串链表，按照插入顺序排序。最大长度2^32 - 1
#### 内部实现
**双向链表**或**压缩列表**
- 元素个数小于512，且值小于64字节，使用压缩列表
- 否则使用双向链表
3.2之后使用quicklist代替双向链表和压缩链表
#### 应用场景
**消息队列**：必须满足**消息保序、处理重复消息和保证消息可靠性**，redis的List和Stream就可以满足这三个需求
##### 消息保序
通过LPUSH+RPOP实现消息队列
- 生产者通过LPUSH插入队列头部
- 消费者通过RPOP读取队伍消息
但是存在性能风险，即消费者不知道生产者是否写入新消息，需要重复调用RPOP读取队列，影响性能，通过BRPOP阻塞式读取解决，客户端没有读到数据时会阻塞，直到有新数据写入
##### 重复消息处理
List不会为每个消息生成ID号，需要自信为每个消息生产唯一全局ID
##### 消息可靠性
提供了BRPOPLPUSH命令留存消息，让消费者程序从一个LIST中读取消息，同时Redis会把这个消息再插入另一个List留存
#### 作消息队列缺陷
不支持多个消费者消费同一个消息，一个消费者拉取一条消息后，这条消息就从List中删除了，List并不支持消费组的实现
### Hash
#### 内部实现
由哈索列表或哈希表实现
- 如果哈希类型元素小于512个，所有值小于64，使用压缩列表
- 否则使用哈希表
7.0中压缩列表被listpack实现
#### 应用场景
**缓存对象**：将哈希的key、field、value和对象的id、属性、值对应。一般对象用String+Json储存，其中频繁变化的属性可以考虑用Hash储存
**购物车**
### Set
set是无需且唯一的键值集合，存储顺序不会按照插入先后顺序进行储存
Set和List区别
- List可以存重复元素，Set只能存非重复元素
- List有序，Set无序
#### 内部实现
- 元素都是整数且个数小于512，使用整数集合
- 否则哈希表i
#### 应用场景
适合存储的数据是无序且需要去重
**点赞**：Set可以保证用户只能点一个赞
**共同关注**、**抽奖活动**（去重，保证只有一个人中奖）
### Zset
有序集合，相比Set多了一个score排序属性，对于Zset每个元素由两个值组成，一个是有序集合的元素值，一个是排序值
#### 内部实现
压缩列表或跳表
- 集合元素个数小于128且元素值小于64字节，使用压缩列表
- 否则使用跳表
7.0中压缩列表被listpack代替
#### 应用场景
**排行榜**、**电话/姓名排序**
### BitMap
适合数据量大且使用**二值统计**
#### 内部实现
基于String，Redis将字节数组每个bit位表示元素的二值状态，可以把BitMap看作bit数组
#### 应用场景
**签到统计**：使用0 1标记签到情况，通过命令可以获取首次打卡日期
**判断用户登录态**
**连续签到用户总数**：把每天日期作为key，userid作为offset，若打卡则将offset的bit设置为1；共有N个Bitmap，对这N个Bitmap作与运算，当一个userid在N个Bitmap对应位置的bit = 1则说明该用户连续N天签到了
### HyperLogLog
提供不精确的去重计数，标准误差率是0.81%
#### 内部实现
？
#### 应用场景
百万级网页UV计数
### GEO
地理信息
#### 内部实现
使用了Sorted Set，对GeoHash编码实现了从经纬度到SortedSet元素权重分数的转换
#### 应用场景
嘀嘀打车
### Stream
专门为消息队列设计的数据场景，支持消息持久化、生成全局唯一ID、ack确认消息模式、消费组模式等
#### 应用场景
**消息队列**
##### 故障处理
使用内部队列保证消费者故障/宕机后处理未完成消息。内部队列存留消费组中每个消费者读取的消息，直到消费者使用XACK通知Stream消息已经处理完成，消费者可以使用XPENDING查看已读取但未完成消息
##### Stream对比专业的消息队列
***Stream消息会丢失吗***：
- 生产者会不会丢消息，取决于生产者对异常情况处理。消息被生产出来，交给MQ过程中，只要能收到ACK就表示发送成功，返回异常则消息重发，那么是不会出错的
- 消费者不会丢消息，因为Stream会自动使用内部队列留存消费组中每个读取的消息，未被读取的消息重启后也可以重新读取
- Redis消息中间件会不会丢消息？**会**
	- AOF持久化写盘异步操作时，Redis宕机会导致数据丢失
	- 主从复制异步，主从切换时也可能丢失数据
RabbitMQ Kafka这种专业消息队列中间件，使用集群部署，即使一个节点挂了，集群也能保证数据不丢失
***Stream消息可堆积吗***：
Stream通过指定队列最大长度，避免消息积压在内存中导致OOM
如果堆积消息长度超过最大值，还是可能丢失消息
但Kafka RabbitMQ这种专业消息队列都是存储在硬盘上，不会OOM KILL掉
所以Redis当MQ使用存在两个问题
- Redis本身可能丢数据
- 面对消息挤压，内存资源会紧张
如果业务简单、数据丢失不敏感、消息挤压概率小，那么Redis当MQ完全可以；其他还是用MQ吧
##### Redis的订阅/发布机制为什么不能当MQ使用
- 发布/订阅机制没有基于任何数据类型实现，所以不具备持久化功能，不会被写入RDB和AOF中，Redis宕机重启后，发布/订阅的数据也会全部丢失
- 发后即忘，如果有订阅者重连后不能消费之前的历史消息
- 消费端有一定消息挤压，消费者消费不过来时，如果超过32M或60s内持续保持在8M以上时，消费端会被强行断开
发布订阅机制只适合即时通讯场景，比如构建哨兵集群
# Redis数据结构
### 键值对数据库是怎么实现的
Redis使用哈希表保存所有键值对，哈希表就是一个数组，数组中的元素叫哈希桶；哈希桶存放指向键值对数据的指针，通过指针就能找到键值对数据，键值对的值可以存放字符串对象和集合数据类型的对象
- redisDb结构表示redis数据库的结构，结构体存放了指向dict的只在
- dict，存放两个哈希表，一般情况下用哈希表1，哈希表2只有在rehash时才用
- ditctht结构，存放了哈希表数组，每个元素都是指向一个哈希表节点结构（dictEntry）的指针
- dictEntry表示哈希表节点的结构，存放了 * void key 和void * value指针
### SDS
基于c语言封装了SDS，简单动态字符串，redis的String的底层数据结构是SDS
#### C字符串的缺陷
C采用`\0`字符作结尾标记，获取字符串长度的时间复杂是O(N)，如果字符串中存在`\0`操作这个字符串时就会提早结束，导致不能保存图片、视频、音频等二进制数据
同时操作字符串的函数是很不安全的，容易缓冲区溢出，操作效率不高
#### SDS结构设计
- len记录字符串长度，获取长度时返回这个变量值，保证二进制安全
- alloc分配给字符数组的空间长度，修改字符串时，通过alloc - len计算出剩余空间大小，不满足时则会自动将SDS空间拓展至所需大小，避免出现缓冲区溢出问题
- flags表示不同类型SDS，一共有五种类型，sdshdr5/8/16/32/64，区别在于数据结构中的len和alloc的数据类型不同，灵活保存不同大小字符串，有效节省内存空间
- buf[]字符数组，保存实际数据
redis除了设计不同结构体，还是用专门编译优化节省内存空间：告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐
### 链表
#### 链表节点结构设计
前置节点+后置节点+节点值，是一个双向链表
#### 链表结构设计
在listNode结构体基础上又封装了list这个数据结构，增加了头指针head、尾节点tail、节点数量len、以及可以自定义实现的dup、free、match函数
#### 链表的优势与缺陷
**优点**
- listNode结构里带有prev和next指针，获取某个节点前后节点只需要O(1)，这两个节点都可以指向NULL，是无环链表
- 提供了head和tail，所以获取链表的表头节点和表尾节点的时间复杂度只要O(1)
- list保存了len，获取节点数量只需要O(1)
- 可以保存类型不同的值
**缺点**
- 每个节点之间内存都是不连续的，无法很好利用CPU缓存
- 保存一个链表节点的值都需要一个链表节点结构头的分配，内存开销大
### 压缩列表
是一种内存紧凑型的数据结构，占用一块连续的内存空间，可以利用CPU缓存且会针对不同长度的数据进行相应编码，有效节省内存开销
但是也存在缺陷：
- 不能保存过多数据，否则查询效率变低
- 新增或修改元素时，压缩列表占用的内存空间需要重新分配，可能引发连锁更新的问题
#### 压缩列表结构设计
压缩列表在表头有三个字段
- zlbytes，记录整个压缩列表占用的字节内存数
- zltail，压缩列表尾部距离起始地址多少字节
- zllen，压缩列表包含节点数量
- zlend，压缩列表的结束点，固定值0xFF
压缩列表查找第一个/最后一个元素时为O(1)，其他都是O(N)，所以压缩列表不适合保存过多元素
压缩列表节点包含三部分
- prevlen，记录前一个节点长度，实现从后向前遍历
- encoding，几里路当前实际数据的类型和长度
- data，记录实际数据，类型和长度由encoding记录
prevlen和encoding根据数据的大小和类型进行不同的空间大小分配
- 前一个节点长度小于254字节，prevlen用1字节空间保存这个长度值
- 大于254字节，使用5字节空间保存这个长度值
encoding空间大小和数据是字符串还是整数，以及数据长度有关
- 当前节点是整数，encoding使用1字节空间进行编码
- 如果是字符串，根据字符串长度，使用1字节/2字节/5字节空间进行编码
#### 连锁更新
压缩链表新增或修改某个元素时，如果空间不够，占用的内存空间就需要重新分配，而新插入的元素较大时，可能会导致后续元素的prevlen占用空间发生变化，引起连锁更新问题，导致每个元素的空间都需要重新分配，造成访问压缩列表性能的下降
#### 压缩列表的缺陷
连锁更新一旦发生，就会导致压缩列表占用的内存空间需要多次重新分配，会影响压缩列表的访问性能
压缩列表只会用于保存节点数量不多的场景
### 哈希表
#### 结构设计
哈希表是一个数组（dictEntry ** table），每个元素是一个指向哈希表节点的指针（dictEntry）。dictEntry不仅包含指向键和值的指针，还包含指向下一个哈希表节点的指针，将多个哈希值相同的kv对连接起来，解决哈希冲突的问题，这就是链式哈希
dictEntry键值对中的值是一个*联合体v*定义的，可以是一个指向实际值的指针，或是一个无符号的64位整数等。这样好处是节约内存空间，把值的数据内嵌在dictEntry结构里，无需再用一个指针指向实际的值
#### 哈希冲突
哈希表实际上是一个数组，数组里每多一个元素就是一个哈希桶，kv对的键经过hash函数计算后得到哈希值，再将哈希值取模得到kv对应元素位置
哈希冲突就是两个*取模相同的不同值的key*放进一个哈希桶，就造成key的哈希冲突
#### 链式哈希
每个哈希表节点都有一个next指针，指向下一个哈希表节点，多个哈希表节点可以用next指针构成一个单项链表，被分配到一个哈希桶中的key通过单项链表连接起来，解决了哈希冲突
随着单项链表长度的增加，查询这一位置的耗时也会增加，通过rehash对哈希表大小进行拓展来解决这个问题
#### rehash
实际使用哈希表时，redis定义了一个dict结构体，其中有两个哈希表ht(2)，进行rehash的时候，需要用上两个哈希表了
正常服务阶段，数据都被插入哈希表1，数据增多则触发rehash
- 将哈希表2分配空间，一般比哈希表1大一倍
- 将哈希表1数据迁移到哈希表2中
- 释放哈希表1空间，把哈希表2设置为表1，在哈希表2新建一个空哈希表，为下次rehash做准备
如果表1数据量非常大，在迁移到表2时会涉及大量拷贝导致redis阻塞，无法服务其他请求
#### 渐进式rehash
- 给哈希表2分配空间
- rehash期间，每次哈希表元素增删改更新操作时，redis除了执行对应操作，还会顺序将表1索引位置上的所有kv迁移到哈希表2上
- 随着客户端发起哈希标请求增多，某个时间点会把哈希表1所有kv迁移到哈希表2上
渐进式rehash过程中，哈希表元素的删除、查找、更新等操作会在两个哈希表进行；在渐进式rehash过程中，新增一个kv时，会被保存到表2中，表1不再进行任何添加工作
#### rehash触发条件
和**负载因子**有关，负载因子 = 哈希表已保存节点数量/哈希表大小
- 当负载因子大于等于1，且redis没有进行bgsave或bgrewriteaof，也就是RDB快照和AOF重写时，会进行rehash操作
- 负载因子大于等于5，就是哈希冲突非常严重了，不管有没有在执行RDB快照或AOF重写，都会强制执行rehash操作
### 整数集合
是Set底层实现之一
#### 结构设计
本质上是一块连续内存空间，保存元素的容器是一个contents数组，被声明为int8类型，实际类型取决于intset中encoding的值
- ending值为INTSET_ENC_INT16，则就是一个int16_t类型数组
- 以此类推，INTSET_ENC_INT32就是int32_t
不同类型contents数组，意味着数组大小也会不同
#### 整数集合的升级操作
如果加入的新元素比集合中所有元素类型都长，整数集合先要进行升级，按新元素类型扩展contents数组空间大小，将原有元素的类型转换为新元素类型（int16->int32）并插入升级的集合中，再将新元素加入整数集合中，升级过程中也要维持整数集合的有序性
升级集合过程中不会分配新类型数组，而是在原本数组上扩展空间，再将每个元素按间隔类型大小分割，如果encoding属性值为int16，则每个元素间隔就是16位
- **使用整数集合升级的好处**
同时保存int16_t、int32_t、int64_t三种类型数据时，如果保存的数据都是int16_t而直接使用int64_t进行保存时，会造成内存浪费；而使用集合升级，集合底层一直都是int16_t进行保存，只有要添加int32_t或int64_t新元素时，才会对数组进行升级操作，节省内存资源
- **支持降级操作吗**
不支持
### 跳表
Zset底层实现用到了跳表，优势是支持O(logN)复杂度的节点查找
Zset中一个是跳表，一个是哈希表，好处是可以高效的范围查找，也可以高效的单点查询
Zset执行插入或更新时，会依次在跳表和哈希表中插入更新相应数据，保证数据一致；Zset通过跳表进行范围查询，通过哈希表实现常数复杂度获取元素权重
Zset使用哈希表+跳表组成struct zset，在讨论时候会说跳表是Zset底层结构，因为大部分操作是跳表实现的，哈希表只用于以O(N)获取元素权重
#### 跳表结构设计
在链表基础上改进，实现了**多层的有序链表**，好处是可以快速定位数据
Zset对象要同时保存元素和元素权重，对应到跳表结构就是sds类型的ele变量和double的score变量，每个跳表节点都有一个后向指针，指向前一个节点，便于倒序查找
跳表是一个带有层级关系的链表，每一层级包含多个节点，每个节点通过指针连接起来，通过zskiplistlevel的level数组；数组的每个元素代表跳表的一层，zskiplistlevel结构体定义了*指向下一个跳表节点的指针*和*跨度*，跨度用来记录两个节点间距离，实际上**计算这个节点在跳表中的排位**；计算某个节点排位时，从头结点到该节点查询路径上，将沿途访问过的所有层跨度累加起来得到目标节点在条表中的排位
跳表结构体zskiplist
- 跳表头尾节点，便于在O(1)访问头尾节点
- 跳表长度，便于O(1)获取跳表节点的数量
- 跳表最大层数，便于O(1)获取条表中层高最高节点的层数量
#### 跳表节点查询过程
从头节点最高层开始，逐一遍历每一层，遍历某一层节点时会用跳表节点中SDS类型的元素和元素权重进行判断
- 当前节点权重小于要查找权重时，跳表会访问该层上下一个节点
- 当前权重等于要查找权重，且当前节点SDS类型数据小于要查找数据时，跳表就会访问该层上下一个节点
两个条件都不满足，或下一个节点为空时，跳表就会使用目前遍历到节点的level数组的下一层指针，然后沿着下一层继续查找
#### 跳表节点层数设置
跳表相邻两层节点数量最理想比例是2：1，查找复杂度降低到O(logN)
*如何维持两层节点数量比例为2：1*
跳表创建节点时，随机生成每个节点的层数，没有严格维持相邻两层节点数为2：1；具体做法是，跳表在创建节点时生成范围 0-1的随机数，如果这个数小于0.25则层数增加一层，然后继续生成下一个随机数，直到随机数大小大于0.25结束，最终确定该节点层数。层高最大为64，**头节点直接创建为64层高**
#### 为什么用跳表不用平衡树
- 从内存占用上比较，跳表比平衡树更灵活
- Zset经常需要执行ZRANGE或ZREVRANGE，作为链表遍历跳表，缓存局部性至少和其他类型平衡树一样好，比平衡树操作简单
- 更易于实现、调试等，算法实现上更简单
### quicklist
时双向链表+压缩列表组合，一个quicklist就是一个双向链表，链表中的每个元素就是一个压缩列表
压缩列表有连锁更新风险，quicklist通过控制每个链表节点中的压缩列表大小或元素个数来规避连锁更新的问题（压缩列表元素越少/越小），连锁更新带来的影响就越小，从而提供了更好的访问性能
#### quicklist结构设计
和链表结构体类似，区别在于节点是quicklistnode
quicklistnode包含了前一个结点和下一个节点指针，每个quicklistnode形成双向链表，节点元素不再是单纯保存元素值，而是保存了压缩列表
### listpack
代替压缩列表，每个节点不再包含前一个节点的长度，避免连锁更新的隐患
#### listpack结构设计
采用了压缩列表很多设计，用连续内存紧凑保存数据，listpack采用不同编码方式保存不同大小的数据
listpack entry就是listpack节点，每个listpack entry主要保存
- encoding，该元素编码类型，会对不同长度的整数和字符串进行编码
- data，实际存放数据
- len，encoding+data实际长度
# AOF持久化的实现
# Redis
### 什么是redis
基于内存的数据库，对数据的读写都是在内存中完成的，读写速度非常快，用于缓存、消息队列、分布式锁登场景
redis提供了多种数据类型，String、Hash、List、Set、Zset、Bitmaps、HyperLogLog、GEO、Stream，对数据类型的操作都是原子性的，因为**执行命令由单线程负责**，不存在并发竞争的问题
redis还支持事务、持久化、lua脚本、多种集群方案、发布/订阅模式、内存淘汰机制、过期删除机制等
### 和memcached异同
1. 都是基于内存的数据库，当做缓存使用
2. 都有过期策略
3. 高性能
区别
- redis数据更丰富，memcached只支持k-v数据结构
- redis支持持久化，保存在磁盘中，memcached挂掉后数据就没了
- redis原生支持集群模式，memcached需要依赖客户端实现往集群中分片写入数据
- redis支持订阅发布模型、lua脚本、事务等功能
### 为什么用redis作为mysql缓存
1. redis具备高性能。将访问数据缓存在redis中，下次访问时直接从缓存中读取，mysql数据改变后同步改变redis中数据即可，会有双写一致性问题
2. redis具备高并发。redis的qps可以破10w，而mysql很难破1w
# Redis数据结构
- String：缓存对象、常规计数、分布式锁、共享session等
- List：消息队列（生产者需要自行实现全局唯一ID，不能以消费组形式消费数据）
- Hash：缓存对象、购物车等
- Set：聚合计算（并集、交集等），比如点赞、共同关注等
- Zset：排序场景，比如排行榜、电话和姓名排序
以上是五种常见数据类型
----------
- BitMap：二值状态统计，比如签到、判断登陆状态、签到用户数等
- HyperLogLog：海量数据基数统计场景，比如百万级网页UV计数
- GEO：储存地理位置信息，比如嘀嘀打车
- Stream：消息队列（实现List没有的两个特性）
### 五种常见数据类型的实现
#### String
基于SDS简单动态字符串
- SDS可以保存二进制数据。使用len而非空字符判断是否结束，SDS所有API会处理二进制方式处理SDS存放在buf数组的数据，所以SDS还可以保存图片、音频、视频这样二进制数据
- SDS获取字符串长度的时间复杂度是O(1)
- SDS API是安全的，拼接字符串不会导致缓冲区溢出
#### List
双向链表或压缩列表
- 列表元素小于512个且每个元素值小于64，使用压缩列表
- 不满足上面使用双向链表
在3.2版本后，只用quicklist实现，代替了双向链表和压缩列表
#### Hash
压缩列表或哈希表
- 列表元素小于512个且每个元素值小于64，使用压缩列表
- 不满足上面使用哈希表
在7.0中压缩列表被listpack实现
#### Set
哈希表或整数集合
- 元素都是整数且个数小于512，使用整数集合
- 否则使用哈希表
#### Zset
压缩列表或跳表
- 元素小于128个且值小于64字节，使用压缩列表
- 否则使用跳表
7.0中由listpack实现压缩列表
# Redis线程模型
### Redis是单线程吗
redis单线程是指**接受请求->解析请求->读写操作->发送数据**这个过程是由主线程完成的，redis程序并不是单线程的，会**启动后台线程**BIO
- 2.6版本会启动两个后台线程，分别处理关闭文件、AOF刷盘
- 4.0以后新增线程，异步释放Redis内存，即lazyfree线程。删除线程会交给后台线程执行，不会造成主线程卡顿，删除大key时用unlink异步删除大key
redis创建单独线程处理耗时任务，避免造成主线程卡顿，后台线程相当于消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）轮询队列
关闭文件、AOF刷盘、释放内存三个任务有各自任务队列
### Redis单线程模式
redis首先初始化，创建socket并监听、注册连接事件处理函数，初始化结束后进入**事件循环函数**：
- 调用**处理发送队列函数**，发送队列中存在的任务，即通过write将客户端发送缓存区中数据发送，没发送完则注册写事件处理函数，等待epoll_wait发现可写后在处理
- 调用epoll_wait函数
	- 链接事件则调用**连接事件处理函数**，调用accept获取已连接socket->调用epoll_ctl将socket加入epoll->注册读事件处理函数
	- 读事件则调用读事件处理函数，调用read获取发送的数据->解析->处理->添加客户端对象至发送队列->写入执行结果到发送等待区等待发送
	- 写事件调用写事件处理函数，通过write发送客户端发送缓存区数据，没发送完则注册写事件处理函数，等待epoll_wait发现可写后在处理
### Redis单线程高QPS原因
- 大部分操作在内存中完成，采用了高效数据结构，瓶颈可能是内存或网络带宽
- 单线程避免了多线程竞争，省去了多线程切换带来的开销也避免了死锁
- 采用I/O多路复用机制处理客户端Socket请求
### redis6.0之前为什么使用单线程
CPU不是制约redis性能的瓶颈，多线程模型会带来并发读写的问题，增加系统复杂度，存在线程切换，甚至加锁解锁，死锁造成的性能损耗
### 6.0之后为什么引入了多线程
采用了多个IO线程处理网络请求，对于命令的执行仍然使用单线程
6.0以后启动redis时会创建额外6个线程，三个后台线程和三个IO线程
# Redis持久化
### redis如何实现数据不丢失
- AOF快照：每执行一条写操作命令，就把该命令以追加形式写入一个文件
- RDB快照：将某一时刻内存数据以二进制写入磁盘
- 混合持久化方式：集成AOF和RBD
### AOF日志的实现
执行完写操作后，将命令以追加方式写入文件，当Redis重启时会读取该文件记录的命令，逐一执行命令进行数据恢复
#### 为什么先执行命令再写入日志
- 避免额外检查开销。如果先写入日志，则需要进行语法检查造成额外开销，避免读取时出错
- 不会阻塞当前写操作命令的执行，当写成功后，才会记录到AOF日志
- **数据可能会丢失**。这两个操作不是一个原子操作，当没来得及将命令写入硬盘时服务器宕机，则会丢失数据
- **可能阻塞其他操作**。写成功后才记录到AOF日志，不会阻塞当前命令执行，但写入AOF的操作也是在主线程中执行，可能会阻塞后续操作
#### AOF写回策略
redis执行完写操作后将命令追加server.aof_buf缓冲区->write()系统调用，将缓冲区数据写入AOF文件，拷贝内核缓冲区pagecache等待内核写入硬盘->*内核决定何时写入硬盘*
redis三种写回策略，控制第三步过程
- Always：每次写命令执行完后同步AOF写回硬盘，可靠性高，但是性能开销大
- Everysec：写命令执行完后写入AOF文件内核缓冲区，每隔一秒写回硬盘，性能始终，宕机时会丢失1s内数据
- No：写命令执行完后写入AOF缓冲区，由操作系统决定何时写入硬盘
#### AOF日志过大触发机制
AOF重写机制，当文件大小超过阈值后触发，压缩AOF文件
再重写时，读取当前数据库中所有键值对，对每个键值对用命令写入到新AOF文件中，写完全部记录后用新AOF文件代替现有AOF文件
#### 重写AOF日志过程
后台子进程bgwriteaof完成
- 子进程重写AOF，避免阻塞主进程
- 子进程带有主进程数据副本，不使用线程避免修改共享内存，若使用线程需要加锁导致性能降低；而进程共享内存数据且只读，保证数据安全
重写过程中，主进程依然可以正常处理命令，redis设置AOF重写缓冲区避免主进程修改k-v导致和子进程数据不一致，缓冲区在创建后台子进程后建立。在重写AOF期间，redis主线程执行完命令后会写入AOF缓冲区和AOF重写缓冲区
子进程完成重写后，异步发送信号给主线程，主线程调用函数：
- 将AOF重写缓冲区中内容追加到新AOF文件中，使新旧AOF文件保存数据库状态一致
- 新AOF进行改名，覆盖现有AOF文件
### RDB快照实现
RDB快照记录某个瞬间内存数据，是实际数据，AOF保存命令操作日志。RDB恢复数据效率比AOF高
#### RDB快照会阻塞线程吗
通过save和bgsave生成RDB文件，区别在于是否在主线程中执行
- save在主线程中生成RDB文件，写入RDB时间太长会阻塞主线程
- bgsave创建子进程生成RDB文件，可以避免主线程阻塞，可通过配置文件实现自动执行bgsave
redis快照是**全量快照**，保存内存中所有数据到磁盘中，过于频繁的快照会对性能产生影响
#### RDB执行快照时可以修改数据吗
写时复制计数COW，可以继续处理操作命令
fork创建子进程，复制父进程页表，指向物理内存是同一个，如果主线程读操作，则主线程和bgsave进程互不影响；如果是写操作，修改的数据会创建副本，bgsave进程写入RDB文件，这个过程中主线程仍可以修改原来数据
#### 混合持久化
使用了混合持久化，AOF文件的前半部分是RDB格式的全量数据，后半部分是AOF格式增量数据，加载时速度会快
- 结合RDB和AOF优点，加快启动速度，降低大量数据丢失风险
- AOF文件添加了RDB格式内容，可读性变差
- 兼容性差，不能用在4.0之前版本
# Redis集群
### redis服务高可用
#### 主从复制
一主多从模式，主从服务器之间采用读写分离方式。主服务器进行读写操作，写操作时主服务器同步给从服务器，从服务器一般是只读，接收主服务器命令并执行
所有数据修改只在主服务器进行，然后将新数据同步给从服务器，主从之间命令复制是异步进行的
主服务器不会等待从服务器执行完写命令再返回服务器，而是本地执行完后就返回结果，从服务器如果没有及时执行命令就会导致主从之间数据不一致
#### 哨兵模式
哨兵模式可以监控主从服务器，提供主从节点故障转移的功能
#### 切片集群模式
Redis Cluster采用哈希槽处理数据和节点之间的关系，一个集群有16384个哈希槽，哈希槽类似数据分区，每个k-v值根据key映射到哈希槽中
- 根据键值对的key按照CRC16计算一个16bit值
- 值对16384取模，模数对应相应编号哈希槽
哈希槽有两种分配模式
- 平均分配：redis自动把哈希槽平均到节点上
- 手动分配：cluster meet命令手动建立节点，再addslots指定哈希槽个数
### 集群脑裂
#### 脑裂
redis主从架构中，一般都是一主多从，主节点提供写操作，从节点提供读操作，如果主节点与从节点失联，但主节点和客户端链接正常，客户端并不知道redis内部发生问题，还在写数据，都被缓存到旧主节点缓冲区中，无法同步给从节点
从节点也发现主节点失联，于是重新选举主节点，此时集群两个主节点就产生了**脑裂**；网络好了后，旧主节点会被降级成从节点，然后回向新主节点全量同步（清楚本地数据），导致先前写入的客户端数据丢失
**解决方案**
当主节点发现从节点下线或通信超时总数量小于阈值时，禁止主节点写操作，返回客户端错误；通过redis参数调节
- min-slaves-to-write x，主节点必须有x从节点链接，否则禁止写数据
- min-slaves-max-lag x，主从数据复制和同步延迟不能超过x秒，否则禁止写数据
即使原主库加固在，也会被限制写入，只有新主库上线时，新主库才能接受数据和处理请求，新数据会直接写入新主库中，从主库会被哨兵降级为从库
# Redis过期删除和内存淘汰
### 过期删除策略
对key设置过期时间时，redis会把该key带上过期时间存到一个**过期字典**中，当查询一个key是，首先检测是否存在过期字典中，不在则正常读取；存在则判定过期时间并对比
redis采用的过期删除策略是**惰性删除+定期删除**搭配使用
##### 惰性删除
不主动删除过期键，每次从数据库访问key时，检测是否过期，过期则删除key
- 优点：每次访问时才检测key是否过期，只会占用很少系统资源，对CPU时间最友好
- 缺点：key已经过期而又存在数据库中，只要这个过期key一直不被访问，占用的内存就不会释放，造成内存空间浪费，对内存不友好
##### 定期删除
每隔一段时间*随机*从数据库中取出一定的key检查并删除过期key
- 从过期字典中选择20个key
- 检查是否过期并删除
- 如果本轮检查已过期数量超过25%则重复检查，如果小于25%则停止检查等待下一轮检查时间到
- 优点：通过限制删除操作执行的时长和频率，减少操作对CPU的影响，也能减少一部分空间无效占用
- 缺点：难以确定删除操作执行时长和频率。太平凡则对CPU不友好，太少又对内存不友好
### 持久化对过期键处理
**RDB**：
- 生成阶段：过期间不会被保存到新RDB文件中
- 加载阶段：
	- 主服务器：载入RDB文件时，会对文件中保存的key进行检查，过期键不会被载入数据库中
	- 从服务器：载入时无论是否过期都会被载入数据库，但主从同步时，从服务器数据会被删除，所以不会造成影响
**AOF**：
- 写入阶段：如果某个过期key没被删除，AOF会保留该key，当过期键被删除后，会追加一条DEL命令显式删除该键
- 重写阶段：重写时会检查redis中键值，已过期的键不会被保存到重写后AOF文件中
### 主从模式对过期键处理
从库不会进行过期扫描，对过期的处理是**被动的**；主库再key到期时，会在AOF文件中增加一条del指令，同步到所有的从库，从库再执行命令删除
### redis内存满了会怎么样
触发内存淘汰机制，配置项maxmemory
### redis过期淘汰策略
##### 不进行数据淘汰的策略
- noeviction（3.0后默认）：当运行内存超过最大设置内存时，不淘汰数据，而是不再提供服务直接返回错误
##### 进行数据淘汰的策略
在设置了过期时间的数据中淘汰
- volatile-random：随机淘汰设置了过期时间的任意键值
- volatile-ttl：优先淘汰更早过期的键值
- volatile-lru：淘汰所有设置了过期时间键值中最久未使用的键值
- volatile-lfu：最少被使用的键值
所有数据范围内进行淘汰
- allkeys-random：随机淘汰任意键值
- allkeys-lru：最久未使用
- allkeys-lfu：最少被使用
### LRU LFU
传统LRU基于链表实现，淘汰最近最少使用数据，存在额外空间开销和链表移动操作带来的耗时
redis使用**近似LRU**算法，实现方式时在redis对象结构体中添加一个额外字段，记录此数据最后一次访问时间，使用随机采样方式淘汰数据，但是无法解决缓存污染问题，通过了**LFU**解决
redis的lru算法多记录了数据访问频次信息，redis对象头中的lru字段，在LRU和LFU算法下使用方式不同
**LRU**算法中，lru字段用来记录key的访问时间戳，在lru模式下redis可根据字段的值比较最后一次key的访问时间
**LFU**算法中，24bit的lru字段分为两段来储存，高16bit存储key访问时间戳，低8bit储存访问频次
# Redis缓存设计
### 缓存雪崩
当大量缓存数据在同一时期过期，如果又有大量用户请求，都无法在redis处理，于是请求直接访问数据库导致压力骤增，严重时导致数据库宕机，形成连锁反应造成系统奔溃，这就是缓存雪崩
可以通过两种方式解决
- 打乱缓存失效时间：在原有失效时间上增加一个随机值，降低集体失效概率
- 设置缓存不过期：设置后台服务更新缓存数据，避免缓存雪崩
### 缓存击穿
缓存中某个**热点数据过期**，大量请求访问了这个热点数据，就无法从缓存中读取，直接访问数据库，导致数据库被高并发请求冲垮，这就是缓存击穿问题
- 互斥锁方案，保证同一时间只有一个业务线程请求缓存；未能获取锁的请求要么等待释放后重新获取缓存，要么返回空值
- 不给热点数据设置过期时间，后台异步更新缓存，或在要过期前，通知后台线程更新缓存和重新设置时间
### 缓存穿透
访问的数据**既不在缓存中，也不再数据库中**，导致请求访问缓存时，发现缓存缺失，而数据库中也没数据，服务后续请求，这样大量请求到来时，数据库压力骤增，这就是缓存穿透
发生缓存穿透两种情况
- 业务误操作，删除了缓存和数据库中数据
- 黑客攻击，恶意访问大量不存在数据的业务
三种解决方案
- 限制非法请求，在API入口处就判断参数是否合理
- 设置空值或默认值，后续请求读取时就读到空值或默认值，不会查询数据库
- 使用布隆过滤器判断数据是否存在，避免通过查询判断数据是否存在：业务线程确认缓存失效后，通过查询布隆过滤器判断数据是否存在，即使发生缓存穿透，请求也只会查询redis和过滤器
### 设计一个缓存策略缓存热点数据
总体思路：通过数据最新访问时间做排名，过滤掉不常访问的数据，只留下经常访问的数据
### 常见缓存更新策略
- Cache Aside旁路缓存
- Read/Write Through 读/写穿透策略
- Write Back写回策略
最常用的是**旁路缓存**策略，程序直接和数据库、缓存交互，负责对缓存的维护，又课细分为*读策略*和*写策略*
**写策略步骤**：
- 先更新数据库中数据，再删除缓存数据
**读策略步骤**：
- 如果读取数据命中缓存，则直接返回数据
- 没有命中缓存，则从数据库中读取数据并写入内存，返回给用户
为什么*先更新数据库再删除缓存*不会导致数据不一致：概率不高，缓存写入远快于数据库写入，很难出现一边更新了数据库/删除缓存后，另一边才更新完缓存
旁路缓存适合读多写少场景，写入频繁时缓存会被频繁清理，对命中率有影响，如果对命中率有要求，有两种解决方案
- 更新数据时也更新缓存，在更新缓存前先加一个分布式锁，避免并发，对写入性能有影响
- 给缓存加一个较短过期时间，即使出现缓存不一致，缓存的数据也很快会过期
**读穿/写穿策略**
应用程序只和缓存交互，不和数据库交互，由缓存和数据库交互
**Read Through**策略：
- 先查询缓存中是否存在数据，存在则直接返回，不存在则由缓存数据负责从数据库中查询数据并将结果写入缓存组件，最后由缓存组件返回数据
**Write Through**：
- 如果缓存数据已存在，则更新数据并由缓存组件同步更新到数据库中，然后缓存组件告诉程序更新完成
- 不存在则直接更新数据库，然后返回
**WriteBack写回策略**
只更新缓存，将缓存数据设置为脏，然后立刻返回，对于数据库采用批量异步更新方式
写回策略不能用到常用数据库和缓存中，redis不支持异步更新，是CPU缓存、OS文件系统常用策略
特别适合写多场景，但数据不是强一致的，且有丢失风险
# Redis实战
### 延迟队列
把当前做的事情，延迟一定时间再做，比如下单超时、取消订单等
通过Zset有序集合实现，有一个Score属性存放延迟执行时间，使用zadd生产消息，再利用zrangebyscore查询符合条件的待处理任务
### Redis大key处理
指key对应value很大，一般两种情况
- String值大于10KB
- Hash、List、Set、Zset元素个数超过5000
会带来四个影响
- 客户端超时阻塞：redis单线程操作大key费时，从客户端看就是没有响应
- 引发网络阻塞：每次获取大key产生流量较大
- 阻塞工作线程：del删除大key时会阻塞工作线程
- 内存分布不均：集群在slot分片均匀情况下会出现数据和查询倾斜情况，部分大key占用节点多，qps大
通过redis -cli --bigkeys/SCAN/RdbTools查找大key
通过分批次删除/异步删除来删除大key
### Redis管道
一次处理多个redis命令，可以解决多个命令执行时网络等待，要注意避免发送命令过大或数据太多造成管道阻塞
### redis事务支持回滚吗
没有提供回滚机制，DISCARD命令只支持放弃事务，清空暂存命令队列，无法回滚
### 使用redis实现分布式锁
SETNX，如果key存在则插入成功（加锁成功），不存在则插入失败（加锁失败）
对于加锁操作，要满足三个条件
- 加锁包括读取锁变量、检查、设置三个操作，但需要原子操作，所以使用SET+NX实现
- 锁变量需要设置过期时间，以免无法释放锁
- 锁变量值需要区分不同客户端加锁操作，避免误释放，通过SET设置变量时，每个客户端都是唯一值
redis实现分布式锁的优点
- 性能高
- 实现方便
- 避免单点故障
	缺点
- 超时时间不好设置。可通过设置守护线程判断锁状态续约
- 主从复制模式数据异步复制，导致分布式锁不可靠性
#### 如何解决分布式锁可靠性
让客户端和多个独立Redis节点依次请求申请加锁，如果客户端能和半数以上节点成功加锁，就认为成功获得分布式锁
加锁成功后，重新计算有效时间，避免锁失效；加锁失败则发起释放锁操作
# Redis常见数据类型
### String
基本k-v结构，不仅是字符串，还可以是整数或浮点数，最大数据长度是512M
#### 内部实现
int和SDS(简单动态字符串)
- SDS可以保存二进制数据（图片、音频等）
- SDS获取字符长度O(1)
- SDS API安全，拼接字符串不会缓冲区溢出
内部编码有三种：int、raw、embstr
字符串保存**整数值**，且可以用long表示时，会将整数值保存在字符串对象结构的ptr中，编码设置为int
字符串保存的是**字符串，且长度≤32字节**，会使用SDS保存，并设置编码为embstr；如果大于32字节，会使用SDS保存，且设置编码为raw
embstr&raw在不同版本边界不同，2+为32、3-4为39、5.0为40字节
embstr使用一次内存分配函数分配**连续内存空间**保存redisObject和SDS，而raw使用两次内存分配**两块内存空间**保存redisObject和SDS
embstr创建分配内存、释放内存的操作只要一次，且因为连续内存使得embstr可以更好利用CPU缓存；但缺点是字符串长度增加时需要重新分配内存，所以embstr编码是只读的，使用append增加时会先转为raw再修改
#### 应用场景
**缓存对象**：缓存整个对象JSON；将key分离为对象属性，采用MSET保存
**常规计数**：计算访问次数、点赞、转发、库存等情况
**分布式锁**：SETNX
**共享session信息**：分布式系统服务器获取用户session
### List
字符串链表，按照插入顺序排序。最大长度2^32 - 1
#### 内部实现
**双向链表**或**压缩列表**
- 元素个数小于512，且值小于64字节，使用压缩列表
- 否则使用双向链表
3.2之后使用quicklist代替双向链表和压缩链表
#### 应用场景
**消息队列**：必须满足**消息保序、处理重复消息和保证消息可靠性**，redis的List和Stream就可以满足这三个需求
##### 消息保序
通过LPUSH+RPOP实现消息队列
- 生产者通过LPUSH插入队列头部
- 消费者通过RPOP读取队伍消息
但是存在性能风险，即消费者不知道生产者是否写入新消息，需要重复调用RPOP读取队列，影响性能，通过BRPOP阻塞式读取解决，客户端没有读到数据时会阻塞，直到有新数据写入
##### 重复消息处理
List不会为每个消息生成ID号，需要自信为每个消息生产唯一全局ID
##### 消息可靠性
提供了BRPOPLPUSH命令留存消息，让消费者程序从一个LIST中读取消息，同时Redis会把这个消息再插入另一个List留存
#### 作消息队列缺陷
不支持多个消费者消费同一个消息，一个消费者拉取一条消息后，这条消息就从List中删除了，List并不支持消费组的实现
### Hash
#### 内部实现
由哈索列表或哈希表实现
- 如果哈希类型元素小于512个，所有值小于64，使用压缩列表
- 否则使用哈希表
7.0中压缩列表被listpack实现
#### 应用场景
**缓存对象**：将哈希的key、field、value和对象的id、属性、值对应。一般对象用String+Json储存，其中频繁变化的属性可以考虑用Hash储存
**购物车**
### Set
set是无需且唯一的键值集合，存储顺序不会按照插入先后顺序进行储存
Set和List区别
- List可以存重复元素，Set只能存非重复元素
- List有序，Set无序
#### 内部实现
- 元素都是整数且个数小于512，使用整数集合
- 否则哈希表i
#### 应用场景
适合存储的数据是无序且需要去重
**点赞**：Set可以保证用户只能点一个赞
**共同关注**、**抽奖活动**（去重，保证只有一个人中奖）
### Zset
有序集合，相比Set多了一个score排序属性，对于Zset每个元素由两个值组成，一个是有序集合的元素值，一个是排序值
#### 内部实现
压缩列表或跳表
- 集合元素个数小于128且元素值小于64字节，使用压缩列表
- 否则使用跳表
7.0中压缩列表被listpack代替
#### 应用场景
**排行榜**、**电话/姓名排序**
### BitMap
适合数据量大且使用**二值统计**
#### 内部实现
基于String，Redis将字节数组每个bit位表示元素的二值状态，可以把BitMap看作bit数组
#### 应用场景
**签到统计**：使用0 1标记签到情况，通过命令可以获取首次打卡日期
**判断用户登录态**
**连续签到用户总数**：把每天日期作为key，userid作为offset，若打卡则将offset的bit设置为1；共有N个Bitmap，对这N个Bitmap作与运算，当一个userid在N个Bitmap对应位置的bit = 1则说明该用户连续N天签到了
### HyperLogLog
提供不精确的去重计数，标准误差率是0.81%
#### 内部实现
？
#### 应用场景
百万级网页UV计数
### GEO
地理信息
#### 内部实现
使用了Sorted Set，对GeoHash编码实现了从经纬度到SortedSet元素权重分数的转换
#### 应用场景
嘀嘀打车
### Stream
专门为消息队列设计的数据场景，支持消息持久化、生成全局唯一ID、ack确认消息模式、消费组模式等
#### 应用场景
**消息队列**
##### 故障处理
使用内部队列保证消费者故障/宕机后处理未完成消息。内部队列存留消费组中每个消费者读取的消息，直到消费者使用XACK通知Stream消息已经处理完成，消费者可以使用XPENDING查看已读取但未完成消息
##### Stream对比专业的消息队列
***Stream消息会丢失吗***：
- 生产者会不会丢消息，取决于生产者对异常情况处理。消息被生产出来，交给MQ过程中，只要能收到ACK就表示发送成功，返回异常则消息重发，那么是不会出错的
- 消费者不会丢消息，因为Stream会自动使用内部队列留存消费组中每个读取的消息，未被读取的消息重启后也可以重新读取
- Redis消息中间件会不会丢消息？**会**
	- AOF持久化写盘异步操作时，Redis宕机会导致数据丢失
	- 主从复制异步，主从切换时也可能丢失数据
RabbitMQ Kafka这种专业消息队列中间件，使用集群部署，即使一个节点挂了，集群也能保证数据不丢失
***Stream消息可堆积吗***：
Stream通过指定队列最大长度，避免消息积压在内存中导致OOM
如果堆积消息长度超过最大值，还是可能丢失消息
但Kafka RabbitMQ这种专业消息队列都是存储在硬盘上，不会OOM KILL掉
所以Redis当MQ使用存在两个问题
- Redis本身可能丢数据
- 面对消息挤压，内存资源会紧张
如果业务简单、数据丢失不敏感、消息挤压概率小，那么Redis当MQ完全可以；其他还是用MQ吧
##### Redis的订阅/发布机制为什么不能当MQ使用
- 发布/订阅机制没有基于任何数据类型实现，所以不具备持久化功能，不会被写入RDB和AOF中，Redis宕机重启后，发布/订阅的数据也会全部丢失
- 发后即忘，如果有订阅者重连后不能消费之前的历史消息
- 消费端有一定消息挤压，消费者消费不过来时，如果超过32M或60s内持续保持在8M以上时，消费端会被强行断开
发布订阅机制只适合即时通讯场景，比如构建哨兵集群
# Redis数据结构
### 键值对数据库是怎么实现的
Redis使用哈希表保存所有键值对，哈希表就是一个数组，数组中的元素叫哈希桶；哈希桶存放指向键值对数据的指针，通过指针就能找到键值对数据，键值对的值可以存放字符串对象和集合数据类型的对象
- redisDb结构表示redis数据库的结构，结构体存放了指向dict的只在
- dict，存放两个哈希表，一般情况下用哈希表1，哈希表2只有在rehash时才用
- ditctht结构，存放了哈希表数组，每个元素都是指向一个哈希表节点结构（dictEntry）的指针
- dictEntry表示哈希表节点的结构，存放了 * void key 和void * value指针
### SDS
基于c语言封装了SDS，简单动态字符串，redis的String的底层数据结构是SDS
#### C字符串的缺陷
C采用`\0`字符作结尾标记，获取字符串长度的时间复杂是O(N)，如果字符串中存在`\0`操作这个字符串时就会提早结束，导致不能保存图片、视频、音频等二进制数据
同时操作字符串的函数是很不安全的，容易缓冲区溢出，操作效率不高
#### SDS结构设计
- len记录字符串长度，获取长度时返回这个变量值，保证二进制安全
- alloc分配给字符数组的空间长度，修改字符串时，通过alloc - len计算出剩余空间大小，不满足时则会自动将SDS空间拓展至所需大小，避免出现缓冲区溢出问题
- flags表示不同类型SDS，一共有五种类型，sdshdr5/8/16/32/64，区别在于数据结构中的len和alloc的数据类型不同，灵活保存不同大小字符串，有效节省内存空间
- buf[]字符数组，保存实际数据
redis除了设计不同结构体，还是用专门编译优化节省内存空间：告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐
### 链表
#### 链表节点结构设计
前置节点+后置节点+节点值，是一个双向链表
#### 链表结构设计
在listNode结构体基础上又封装了list这个数据结构，增加了头指针head、尾节点tail、节点数量len、以及可以自定义实现的dup、free、match函数
#### 链表的优势与缺陷
**优点**
- listNode结构里带有prev和next指针，获取某个节点前后节点只需要O(1)，这两个节点都可以指向NULL，是无环链表
- 提供了head和tail，所以获取链表的表头节点和表尾节点的时间复杂度只要O(1)
- list保存了len，获取节点数量只需要O(1)
- 可以保存类型不同的值
**缺点**
- 每个节点之间内存都是不连续的，无法很好利用CPU缓存
- 保存一个链表节点的值都需要一个链表节点结构头的分配，内存开销大
### 压缩列表
是一种内存紧凑型的数据结构，占用一块连续的内存空间，可以利用CPU缓存且会针对不同长度的数据进行相应编码，有效节省内存开销
但是也存在缺陷：
- 不能保存过多数据，否则查询效率变低
- 新增或修改元素时，压缩列表占用的内存空间需要重新分配，可能引发连锁更新的问题
#### 压缩列表结构设计
压缩列表在表头有三个字段
- zlbytes，记录整个压缩列表占用的字节内存数
- zltail，压缩列表尾部距离起始地址多少字节
- zllen，压缩列表包含节点数量
- zlend，压缩列表的结束点，固定值0xFF
压缩列表查找第一个/最后一个元素时为O(1)，其他都是O(N)，所以压缩列表不适合保存过多元素
压缩列表节点包含三部分
- prevlen，记录前一个节点长度，实现从后向前遍历
- encoding，几里路当前实际数据的类型和长度
- data，记录实际数据，类型和长度由encoding记录
prevlen和encoding根据数据的大小和类型进行不同的空间大小分配
- 前一个节点长度小于254字节，prevlen用1字节空间保存这个长度值
- 大于254字节，使用5字节空间保存这个长度值
encoding空间大小和数据是字符串还是整数，以及数据长度有关
- 当前节点是整数，encoding使用1字节空间进行编码
- 如果是字符串，根据字符串长度，使用1字节/2字节/5字节空间进行编码
#### 连锁更新
压缩链表新增或修改某个元素时，如果空间不够，占用的内存空间就需要重新分配，而新插入的元素较大时，可能会导致后续元素的prevlen占用空间发生变化，引起连锁更新问题，导致每个元素的空间都需要重新分配，造成访问压缩列表性能的下降
#### 压缩列表的缺陷
连锁更新一旦发生，就会导致压缩列表占用的内存空间需要多次重新分配，会影响压缩列表的访问性能
压缩列表只会用于保存节点数量不多的场景
### 哈希表
#### 结构设计
哈希表是一个数组（dictEntry ** table），每个元素是一个指向哈希表节点的指针（dictEntry）。dictEntry不仅包含指向键和值的指针，还包含指向下一个哈希表节点的指针，将多个哈希值相同的kv对连接起来，解决哈希冲突的问题，这就是链式哈希
dictEntry键值对中的值是一个*联合体v*定义的，可以是一个指向实际值的指针，或是一个无符号的64位整数等。这样好处是节约内存空间，把值的数据内嵌在dictEntry结构里，无需再用一个指针指向实际的值
#### 哈希冲突
哈希表实际上是一个数组，数组里每多一个元素就是一个哈希桶，kv对的键经过hash函数计算后得到哈希值，再将哈希值取模得到kv对应元素位置
哈希冲突就是两个*取模相同的不同值的key*放进一个哈希桶，就造成key的哈希冲突
#### 链式哈希
每个哈希表节点都有一个next指针，指向下一个哈希表节点，多个哈希表节点可以用next指针构成一个单项链表，被分配到一个哈希桶中的key通过单项链表连接起来，解决了哈希冲突
随着单项链表长度的增加，查询这一位置的耗时也会增加，通过rehash对哈希表大小进行拓展来解决这个问题
#### rehash
实际使用哈希表时，redis定义了一个dict结构体，其中有两个哈希表ht(2)，进行rehash的时候，需要用上两个哈希表了
正常服务阶段，数据都被插入哈希表1，数据增多则触发rehash
- 将哈希表2分配空间，一般比哈希表1大一倍
- 将哈希表1数据迁移到哈希表2中
- 释放哈希表1空间，把哈希表2设置为表1，在哈希表2新建一个空哈希表，为下次rehash做准备
如果表1数据量非常大，在迁移到表2时会涉及大量拷贝导致redis阻塞，无法服务其他请求
#### 渐进式rehash
- 给哈希表2分配空间
- rehash期间，每次哈希表元素增删改更新操作时，redis除了执行对应操作，还会顺序将表1索引位置上的所有kv迁移到哈希表2上
- 随着客户端发起哈希标请求增多，某个时间点会把哈希表1所有kv迁移到哈希表2上
渐进式rehash过程中，哈希表元素的删除、查找、更新等操作会在两个哈希表进行；在渐进式rehash过程中，新增一个kv时，会被保存到表2中，表1不再进行任何添加工作
#### rehash触发条件
和**负载因子**有关，负载因子 = 哈希表已保存节点数量/哈希表大小
- 当负载因子大于等于1，且redis没有进行bgsave或bgrewriteaof，也就是RDB快照和AOF重写时，会进行rehash操作
- 负载因子大于等于5，就是哈希冲突非常严重了，不管有没有在执行RDB快照或AOF重写，都会强制执行rehash操作
### 整数集合
是Set底层实现之一
#### 结构设计
本质上是一块连续内存空间，保存元素的容器是一个contents数组，被声明为int8类型，实际类型取决于intset中encoding的值
- ending值为INTSET_ENC_INT16，则就是一个int16_t类型数组
- 以此类推，INTSET_ENC_INT32就是int32_t
不同类型contents数组，意味着数组大小也会不同
#### 整数集合的升级操作
如果加入的新元素比集合中所有元素类型都长，整数集合先要进行升级，按新元素类型扩展contents数组空间大小，将原有元素的类型转换为新元素类型（int16->int32）并插入升级的集合中，再将新元素加入整数集合中，升级过程中也要维持整数集合的有序性
升级集合过程中不会分配新类型数组，而是在原本数组上扩展空间，再将每个元素按间隔类型大小分割，如果encoding属性值为int16，则每个元素间隔就是16位
- **使用整数集合升级的好处**
同时保存int16_t、int32_t、int64_t三种类型数据时，如果保存的数据都是int16_t而直接使用int64_t进行保存时，会造成内存浪费；而使用集合升级，集合底层一直都是int16_t进行保存，只有要添加int32_t或int64_t新元素时，才会对数组进行升级操作，节省内存资源
- **支持降级操作吗**
不支持
### 跳表
Zset底层实现用到了跳表，优势是支持O(logN)复杂度的节点查找
Zset中一个是跳表，一个是哈希表，好处是可以高效的范围查找，也可以高效的单点查询
Zset执行插入或更新时，会依次在跳表和哈希表中插入更新相应数据，保证数据一致；Zset通过跳表进行范围查询，通过哈希表实现常数复杂度获取元素权重
Zset使用哈希表+跳表组成struct zset，在讨论时候会说跳表是Zset底层结构，因为大部分操作是跳表实现的，哈希表只用于以O(N)获取元素权重
#### 跳表结构设计
在链表基础上改进，实现了**多层的有序链表**，好处是可以快速定位数据
Zset对象要同时保存元素和元素权重，对应到跳表结构就是sds类型的ele变量和double的score变量，每个跳表节点都有一个后向指针，指向前一个节点，便于倒序查找
跳表是一个带有层级关系的链表，每一层级包含多个节点，每个节点通过指针连接起来，通过zskiplistlevel的level数组；数组的每个元素代表跳表的一层，zskiplistlevel结构体定义了*指向下一个跳表节点的指针*和*跨度*，跨度用来记录两个节点间距离，实际上**计算这个节点在跳表中的排位**；计算某个节点排位时，从头结点到该节点查询路径上，将沿途访问过的所有层跨度累加起来得到目标节点在条表中的排位
跳表结构体zskiplist
- 跳表头尾节点，便于在O(1)访问头尾节点
- 跳表长度，便于O(1)获取跳表节点的数量
- 跳表最大层数，便于O(1)获取条表中层高最高节点的层数量
#### 跳表节点查询过程
从头节点最高层开始，逐一遍历每一层，遍历某一层节点时会用跳表节点中SDS类型的元素和元素权重进行判断
- 当前节点权重小于要查找权重时，跳表会访问该层上下一个节点
- 当前权重等于要查找权重，且当前节点SDS类型数据小于要查找数据时，跳表就会访问该层上下一个节点
两个条件都不满足，或下一个节点为空时，跳表就会使用目前遍历到节点的level数组的下一层指针，然后沿着下一层继续查找
#### 跳表节点层数设置
跳表相邻两层节点数量最理想比例是2：1，查找复杂度降低到O(logN)
*如何维持两层节点数量比例为2：1*
跳表创建节点时，随机生成每个节点的层数，没有严格维持相邻两层节点数为2：1；具体做法是，跳表在创建节点时生成范围 0-1的随机数，如果这个数小于0.25则层数增加一层，然后继续生成下一个随机数，直到随机数大小大于0.25结束，最终确定该节点层数。层高最大为64，**头节点直接创建为64层高**
#### 为什么用跳表不用平衡树
- 从内存占用上比较，跳表比平衡树更灵活
- Zset经常需要执行ZRANGE或ZREVRANGE，作为链表遍历跳表，缓存局部性至少和其他类型平衡树一样好，比平衡树操作简单
- 更易于实现、调试等，算法实现上更简单
### quicklist
时双向链表+压缩列表组合，一个quicklist就是一个双向链表，链表中的每个元素就是一个压缩列表
压缩列表有连锁更新风险，quicklist通过控制每个链表节点中的压缩列表大小或元素个数来规避连锁更新的问题（压缩列表元素越少/越小），连锁更新带来的影响就越小，从而提供了更好的访问性能
#### quicklist结构设计
和链表结构体类似，区别在于节点是quicklistnode
quicklistnode包含了前一个结点和下一个节点指针，每个quicklistnode形成双向链表，节点元素不再是单纯保存元素值，而是保存了压缩列表
### listpack
代替压缩列表，每个节点不再包含前一个节点的长度，避免连锁更新的隐患
#### listpack结构设计
采用了压缩列表很多设计，用连续内存紧凑保存数据，listpack采用不同编码方式保存不同大小的数据
listpack entry就是listpack节点，每个listpack entry主要保存
- encoding，该元素编码类型，会对不同长度的整数和字符串进行编码
- data，实际存放数据
- len，encoding+data实际长度
# AOF持久化的实现
### AOF日志
每执行一条操作，就会把该命令以追加的方式写入到文件中，这就是AOF操作。AOF操作只保存写命令，不保存读命令
redis先执行写命令，再写入AOF日志中，**避免额外检查开销、不会阻塞当前写命令执行**；但是也存在问题，当AOF还未写入时服务器宕机，数据就有丢失的风险，同时有可能阻塞下一个写命令
### 三种写回策略
redis在执行完写操作后，将命令追加到`server.aof_buf`缓冲区，通过write()将缓冲区数据写入AOF文件中，拷贝到内核缓冲区中，等待内核决定写入硬盘实际；存在三种写回的策略
- Always，每次写操作执行完后同步AOF日志写回硬盘
- Eversec，每隔一秒将缓冲区内容写回硬盘
- No，不由redis控制写回硬盘时间，由内核决定何时写回硬盘
三种策略无法完美解决问题
- Always最大程度保证数据不丢失，但是会影响主进程性能
- No性能好，但是操作系统写回硬盘的时机是位置的，可能会导致数据丢失
- Eversec是折中策略
### AOF重写
redis为了避免AOF越写越大，当超过阈值时，就会启用AOF重写压缩AOF文件
重写是在重写时，读取当前数据库中所有键值对，将每个键值对用一条新命令写入新AOF中，全写完后将新AOF文件替代现有的AOF文件
重写机制只用根据键值对的最新状态，用一条命令记录键值对
如果AOF重写过程中失败了，现有的AOF文件就会造成污染
### AOF后台重写
触发AOF重写时，过于耗时会阻塞主进程，是由后台子进程bgrewriteaof完成
- 子进程AOF重写时，主进程继续处理命令请求，避免阻塞主进程
- 子进程带有主进程的数据副本，主进程通过fork创建子进程时，会把页表复制给子进程，同时对应只读，当子进程发起修改时，会触发写时复制，才会去复制并修改物理内存
redis通过AOF重写缓冲区，避免主进程修改键值对导致子进程数据不一致的问题，在重写AOF期间，redis会同时把写命令写入AOF缓冲区和AOF重写缓冲器区；当子进程完成AOF重写工作后，向主进程发送一条信号，让主进程发送并覆盖AOF文件
# RDB快照实现
AOF保存操作，RDB保存某一时刻实际内存数据
### 快照使用
redis提供了两个命令生成RDB文件，`save`和`bgsave`
- save在主线程生成RDB文件，如果写入RDB文件时间过长会阻塞主线程
- bgsave创建子进程生成RDB文件，避免主线程的阻塞
RDB文件加载工作是在服务器启动时自动实现的，redis没有专门用来加载RDB文件的命令
redis的快照是**全量快照**，每次执行快照把内存中所有数据记录到内存中，频率太频繁则会对redis性能产生影响
RDB在服务器故障时，丢失的数据比AOF多，因为RDB是全量快照模式，操作不能太频繁，而AOF以秒级记录命令，丢失数据更少
### 执行快照时数据可以修改吗
执行bgsave时，redis可以继续处理操作命令，在于**写时复制技术**
执行bgsave时，通过`fork()`创建子进程，子进程和父进程共享一片内存（子进程页表指向相同物理内存），发生修改时物理内存才会被复制，这样的目的是降低创建子进程时的性能损耗，加快子进程创建速度
创建bgsave子进程后，共享父进程所有内存数据，可以直接读取父进程数据并写入RDB，父进程对共享内存数据也进行只读操作；当父进程修改数据时，这块物理内存就会被复制一份，父进程再对这个副本操作，子进程继续把原来数据写入RDB文件中
发生写时复制后，RDB保存的仍是原来的内存数据，主线程修改的数据在下一次RDB快照时才能被写入
极端情况下，即`fork()`创建的子进程的共享内存全部被修改，此时内存占用是原来两倍
### RDB和AOF合体
将AOF和RDB混合，混合使用AOF快照，即混合持久化
开启混合持久化后，AOF重写日志时，`fork()`创建的子进程会先将共享内存数据以RDB写入AOF文件中，然后主线程处理的操作命令会被写在重写缓冲区中，以增量方式写入AOF文件中，写入完成后通知主进程将含有RDB和AOF格式的AOF文件替换旧的AOF文件
使用混合持久化后，**AOF文件前半部分是RDB全量数据，后半部分是AOF增量数据**
加载速度快，数据丢失少
# Redis大key影响
### 大key对AOF日志的影响
使用Always时，如果写入的是一个大key，主线程执行fsync()函数时，阻塞的时间会比较久，数据同步到硬盘的过程很耗时
使用EveySec时，由于是异步执行fsync()，所有大key持久化的过程不会阻塞主线程
No时，由于永不执行fsync()，所以大key持久化过程不会影响主线程
*fsync由内核发起的写操作，将内核缓冲区数据写入硬盘*
### 大key对AOF重写和RDB的影响
如果AOF写入了很多大key，那么AOF文件大小会很大，触发AOF重写机制
AOF重写和RDB bgsave都会调用fork()创建子进程，如果主进程存在很多大key，则**fork()复制页表时**会很耗时导致阻塞，且fork()由主线程处理，则此时会阻塞主线程，无法处理后续客户端请求
如果**创建完子进程后**，父进程对共享内存中的大key进行修改，内核就会发生写时复制把内存复制一份，由于大key占用物理内存比较大，则复制内存过程会耗时导致阻塞
如果Linux开启内存大页，也会影响redis性能（4KB内存页->2MB内存页），复制时复制内存放大了512倍，导致redis性能变慢
# redis过期删除和内存淘汰有什么区别
### 过期删除策略
#### 如何设置过期时间
- `expire <key> <n>`设置key在n秒后过期
- `pexpire <key> <n>`设置key在n毫秒后过期
- `expireat <key> <n>`设置key在某个时间戳（精确到秒）过期
- `pexpireat <key> <n>`精确到毫秒后过期
设置字符串时同时对key设置过期时间
- `set <key> <value> ex <b>`设置键值对时，同时指定过期时间（精确到秒）
- `set <key> <value> px <n>`设置键值对时，同时指定过期时间（精确到毫秒）
- `set <key> <n> <value>`设置键值对时，同时指定过期时间（精确到秒）
通过 `TTL <key>`查看某个key剩余存活时间
#### 如何判定key已经过期了
对key设置过期时间时，会把该key带上过期时间存储到**过期字典**中，过期字典保存在redisDB结构中
- key是指针，指向某个键对象
- value是一个long long类型整数，保存了key的过期时间
查询一个key时，首先查询是否存在过期字典中，不在则正常读取键值；存在则判断过期时间、是否过期
#### 过期删除策略有哪些
- **定时删除**：设置key过期时间时，同时创建定时事件，时间到达时由事件处理器自动执行key的删除操作。**优点**保证过期key尽快被删除，内存尽快被释放，对内存最友好。**缺点**key较多情况时，删除过期key会占用CPU时间，影响服务器吞吐量
- **惰性删除**：不主动删除过期键，每次从数据库访问key时检测是否过期，过期则删除该key。**优点**每次访问时才检查key是否过期，对CPU时间最友好。**缺点**如 果一个key已经过期，且长时间不被访问则会一直占用内存资源，对资源不友好
- **定期删除**：每隔一段时间从数据库中选出一定量key并删除其中过期key。**优点**通过限制删除操作的时长和频率，减少对CPU占用和内存占用。**缺点**内存清理不如定时删除，系统占用不如惰性删除，同时难以确定删除时长和频率
#### Redis过期删除策略是什么
redis使用**惰性删除+定期删除**两种策略
惰性删除由`expireIfNeeded`实现
- 如果过期，则删除key，由`lazyfree_lazy_expire`参数决定异步删除还是同步删除
定期删除
- 通过redis的redis.conf进行配置，默认每秒10次对数据库进行过期检查，每次随机抽取一定数量的key进行过期检查
- 通过expire.c的`activeExpireCycle`控制，由代码中定义的数量决定，数值是20，每轮抽查时会随机选择20个key判断是否过期
  1. 过期字典中随机选择20个key
  2. 判断是否过期并删除过期key
  3. 如果已过期key超过25%，则重复步骤1直到过期key数量少于25%
### 内存淘汰策略
#### 如何设置redis最大运行内存
配置文件redis.conf中，通过`maxmemory <bytes>`设定最大运行内存，不同位数操作系统默认值不同
#### redis内存淘汰策略有哪些
1. 不进行数据淘汰noeviction：运行内存超过最大设置内存时，不淘汰任何数据，如果有新数据写入则会报错禁止写入，但是可以进行单纯的查询和删除操作
2. 细分为 在设置了过期时间的数据中进行淘汰
   - volatile-random：随机淘汰设置了过期时间的任意键值
   - volatile-ttl：优先淘汰更早过期的键值
   - volatile-lru：淘汰所有设置了过期时间键值中，最久未被使用的键值
   - volatile-lfu：~最少使用的键值
   在所有数据范围内进行淘汰
   - allkeys-random：随机淘汰任意键值
   - allkeys-lru：淘汰整个键值中最久未使用的
   - allkeys-lfu：~最少被使用的
#### lru和lfu算法区别
**LRU**最近最少使用，淘汰最近最少使用的算法
redis没有使用传统lru算法，因为存在两个问题
- 需要用链表所有的缓存数据，会带来额外的空间开销
- 大量数据被访问需要很多链表移动，降低redis性能
redis通过近似LRU算法，即在redis对象结构中添加一个额外的字段，记录该数据最后一次使用的时间。当redis内存淘汰时，随机采访的方式进行数据淘汰：随机取五个值，淘汰最久未被使用的
- 不用维护大链表，节省了内存空间
- 不用每次都移动链表元素，提升了缓存性能
但是无法解决缓存污染问题
**LFU**最近不常用
对于LRU，在数据的结构中添加了*数据访问频次*信息

在LRU算法中，redis对象头24bits的lru字段记录key访问时间戳，通过时间戳比较最后一次key访问时间，淘汰最久未被使用key
在LFU算法中，投24bits字段被分为两端，高16bits储存ldt访问时间戳，低8bits记录访问频次；每次key被访问时，会对logc做一个衰减操作，和最后访问时间有关，如果和上次访问时间相差较大，则衰减值就越大
# 主从复制是怎么实现的
redis提供了主从复制，采用了主从读写分离方式，解决了服务器之间的数据一致性问题
主服务器可以进行读写操作，发生写操作时自动将操作同步给从服务器；从服务器一般是只读，接收主服务器同步过来写操作命令，然后执行
### 第一次同步
通过`replicaof`(5.0前使用`salveof`)形成主从服务器之间的关系
主从服务器第一次同步分为三阶段
- 第一阶段建立连接、协商同步
- 第二阶段主服务器同步数据给从服务器
- 第三阶段主服务器发送新写操作命令给从服务器
*第一阶段*：
从服务器给主服务器发送`psync`命令，表示要进行数据同步
`psync`包含两个参数，**主服务器的runID**&**复制进度offset**
- runID，每个redis服务器启动时随机产生一个ID标识自己，主从第一次同步时，因为不知道主服务器的runID所以设置为“？”、
- offset，标识复制进度，第一次同步时值设置为-1
主服务器收到`psync`后通过`FULLRESYNC`响应给对方，且会带上runID和当前offset，从服务器收到后会记录这两个值
`FULLRESYNC`响应意图是**全量复制**方式
*第二阶段*：
主服务器执行bgsave生成RDB文件，发送给从服务器，从服务器收到RDB文件后，清空当前数据并载入RDB文件
（主线程通过bgsave子进程生成RDB文件的过程不会阻塞主线程，异步工作）
这期间的写操作没有记录到RDB文件中，为了保证数据一致性，主服务器将三个时间间隔中收到的写操作命令写入replication buffer缓冲区中
- 主服务器生成RDB文件期间
- 将RDB文件发送给从服务器期间
- 从服务器加载RDB文件期间
*第三阶段*：
从服务器完成RDB载入后，发送一个确认消息给主服务器；主服务器将replication buffer缓冲区中的写操作命令发送给从服务器，从服务器读取并执行
### 命令传播
主从服务器完成第一次同步后，双方之间就会维护一个TCP链接，后续服务器通过这个链接将写操作命令传播给从服务器，保证主从服务器数据一致；且这个连接是长连接的
### 分摊主服务器的压力
主服务器可以有多个从服务器，如果从服务器数量非常多且都进行全量同步的话会有两个问题
- 通过bgsave生成RDB文件，则主服务器会忙于fork()，如果主服务器内存数据非常大，则fork()时将会阻塞主线程，使redis无法正常处理请求
- 传输RDB文件会占用主服务器的网络宽带，影响主服务器响应请求
redis从服务器可以有自己的从服务器，此时不仅可以接受主服务器的同步数据，还可以作为主服务器向从服务器同步数据
从服务器通过`replicaof <目标服务器IP> 6379`建立自己的从服务器
### 增量复制
如果主从服务器间网络连接断开了，就无法进行命令传播了，主从服务器数据就无法保持一致，客户端就可能从从服务器读到旧数据
从2.8起，网络断开又连接后，主从服务器会采用**增量复制**继续同步，只会把网络断开期间主服务器收到的写命令同步给从服务器
- 从服务器在恢复网络后，发送`psync`给主服务器，此时offset参数不是-1
- 主服务器收到命令后，用`CONTINUE`响应告诉从服务器采用增量复制同步数据
- 主服务器发送断线期间的写命令给从服务器执行
通过两个参数得知发送的增量数据
- repl_backlog_buffer：环形缓冲区，主从服务器断链后从中找到差异的数据
- replication offset：标记上面缓冲区的同步进度，主从服务器有各自的偏移量。主服务器通过`master_repl_offset`记录自己*写*的位置，从服务器通过`salve_repl_offset`记录自己读的位置
**repl_backlog_buffer写入时机**：
主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入repl_backlog_buffer缓冲区中；网络断开重连后，从服务器通过`psync`将自己的`salve_repl_offset`发送给主服务器，主服务器通过计算和`master_repl_offset`之间的差距决定同步操作
- 如果计算出从服务器要读取的数据还在缓冲区中，则进行**增量复制**
- 不在缓冲区中则进行**全量同步**
主服务器在repl_backlog_buffer中找到增量数据后，写入replication buffer缓冲区中；repl_backlog_buffer默认大小是1M，且由于是环形缓冲区，之前的数据会被新写入的数据覆盖，因此主服务器写入数据远超从服务器读取速度时，缓冲区数据一下就会被覆盖，此时就会使用全量复制
**为了避免频繁全量同步，应调整repl_backlog_buffer缓冲区大小，尽可能避免出现数据被覆盖而不是用增量同步方式**
repl_backlog_buffer最小大小可以用`second * write_size_per_second`公式估算
### 面试题
#### redis主从连接时是长连接还是短连接
长连接
#### 怎么判断redis节点是否正常工作
redis通过相互的ping-pong心态检测机制，如果一半以上节点去ping一个节点时候没有pong回应，集群会认为节点挂掉，断开与其的链接
redis主从节点发送给的心跳间隔是不同的
- 主节点默认每隔十秒对从节点发送ping命令，判断存活性和链接状态，通过repl_ping_salve_period控制发送频率
- 从节点每隔一秒发送replconf ack{offset}命令，给主节点上报自身当前的复制偏移量，为了
  - 监测主从节点网络状态
  - 上报自身偏移量，检查复制数据是否丢失，如果从节点数据丢失，再从主节点复制缓冲区中拉取丢失数据
#### 主从复制结构中过期key如何处理
主节点处理了一个key或通过淘汰算法淘汰了一个key，这个时间主节点模拟一个del命令发送给从节点，从节点收到该命令后进行淘汰key的操作
#### Redis是同步复制还是异步复制
主节点每次收到写命令后，先写入内部缓冲区，然后异步发送给从节点
#### 主从复制中两个Buffer有什么区别
- 出现阶段不一样
  - repl_backlog_buffer在增量复制阶段出现，**一个主节点只分配一个repl_backlog_buffer**
  - replication buffer在全量复制和增量复制阶段都会出现，**主节点会给每个新连接的从节点分配一个replication buffer**
- 两个buffer都有大小限制，满了之后发生事情不一样
  - repl_backlog_buffer直接覆盖起始位置的数据
  - replication_buffer满了，会导致连接断开、删除缓存、从节点重新链接重新开始增量复制
#### 如何应对主从数据不一致
**为什么会出现主从数据不一致**
主从节点之间命令复制时异步进行的，无法保证强一致
主节点在传播命令阶段，收到新写命令后，发送给从节点，但是主节点不会等待从节点执行完命令后再返回客户端数据，而是主节点本地执行完命令后直接向客户端返回数据
**如何应对主从数据不一致**
- 尽量保证主从节点间的网络连接状况良好
- 开发外部程序监控主从节点间复制进度
  - redis的INFO replication命令可以查看主节点接受写命令的进度信息和从节点复制写命令的进度信息，可以开发一个监控程序从INFO replication查询主从复制进度和复制进度差值
  - 如果从节点进度差值大于预设的阈值，可以让客户端不再和这个从节点连接进行数据读取
#### 主从切换如何减少数据丢失
主从切换中有两种情况导致数据丢失
- 异步复制同步丢失
- 集群脑裂数据丢失
**异步复制同步丢失**
主从节点之间数据复制是异步复制；当客户端发送写请求给主节点时，客户端就会返回ok，主节点将写请求异步同步给各从节点，如果此时主节点还没来得及同步给从节点时出现了异常，主节点中内存数据就会丢失
通过配置min-salve-max-log表示一旦所有从节点数据复制和同步延迟都超过了定义值，主节点就会拒绝接受任何请求；假设设置为10s，如果主从复制需要时间超过10s，就会认为master宕机后损失数据会很多，master就会拒绝写入新请求，这样就控制数据差异在10s内；对于客户端，发现master不可写后，采取降级措施将数据写入本地缓存和磁盘中，等master恢复后重新写入，或写入kafka等待master消费
**集群脑裂数据丢失**
redis主从节点中，一般是一主多从，如果主节点与从节点失联，但主节点和客户端正常链接，客户端还在向主节点写入数据，此时这些数据都被主节点写入了缓冲区，但是无法同步给从节点；而哨兵发现主节点失联，就会在slave中选举一个leader作为主节点，此时导致脑裂
如果原主节点恢复链接，但此时已有新主节点，哨兵就会把旧主节点降级为从节点，这个节点会向新主节点请求数据进行全量同步，会清空客户端写入的本地缓存，此时客户端写入的数据就会丢失
通过设置参数，当主节点发现**从节点下线数量太多**或**网络延迟太大**时，主节点就会禁止写操作
- min-salve-to-write x，主节点必须要有x个从节点链接，小于这个数则会禁止写数据
- min-slave-max-log x，主从数据复制和同步延迟不能超过x秒，如果延迟超过x秒主节点会禁止写数据
即使原主节点假故障，假故障期间无法响应哨兵心跳，也不能和从节点进行同步，无法和从节点进行ACK确认，原主节点会被限制接收接收新客户端请求，等新主节点上线时，只有新主节点能接受和请求客户端数据，新写的数据会被直接写入新主节点，原主节点会被降级为从节点，即使数据被清空也不会丢失新数据
#### 主从如何做到故障自动切换
主节点挂了从节点无法自动升级为主节点，这个过程需要人工处理
此时哨兵机制就登场了，哨兵发现主节点出现故障时，由哨兵自动完成故障发现和故障转移通知给应用方
# 哨兵
### 为什么要有哨兵
主从节点是读写分离的，如果主节点挂了则无法进行写操作，哨兵机制实现了**主从节点故障转移**
### 哨兵机制工作
哨兵是一个运行在特殊模式下的redis进程，是一个*观察者节点*，观察主从对象，主要负责三件事情：**监控、选主、通知**
### 如何判断主节点故障
每隔1s对主从节点发送PING，主从节点收到PING后响应哨兵，判断是否正常运行
如果主从节点没有在规定时间内响应哨兵的PING，会被标记为**主观下线**；而**客观下线**只适用于主节点
对主节点设计主观下线和客观下线，是因为主节点**可能并没有下线**，只是发生了网络拥塞，导致没有及时响应；为了减少误判，哨兵部署时会多个节点部署成**哨兵集群（至少三台）**，通过多个哨兵节点一起判断避免误判主节点下线
当一个哨兵判断主节点**主观下线**后，会向其他哨兵发起命令，其他哨兵收到后会根据自身和主节点网路状况，投票赞成或拒绝；当赞同票超过设定值后会被标记为客观下线（一般设置为哨兵个数1/2 + 1），当判断完主节点客观下线后，在多个从节点中选出一个新从节点做新主节点
### 哪个哨兵进行主从故障转移
哨兵节点中投票选出leader，leader进行主从切换，哪个哨兵判断主节点客观下线则称为候选者
候选者会向其他哨兵发送命令，希望成为leader进行主从切换并要求投票，每个哨兵只有一次机会，可以投给别人或自己（只有候选者可以），投票过程中需要满足两个条件
1. 拿到一半以上赞成票
2. 票数大于等于哨兵配置文件中的quorum值
### 主从故障转移的过程
#### 选出主节点
在已下线主节点的所有从节点中，选择一个状态良好、数据完整的从节点，向其发送`SLAVEOF no one`命令，将其转换为主节点
要把失联、网络不好的从节点排除，通过`down-after-milliseconds * 10`配置项，判断时间间隔内从节点是否一直断链/锻炼超过10次（网络不好），排除作为新主节点可能性
再进行三轮考察：**优先级、复制进度、ID号**，哪个从节点先胜出，作为新主节点
- 第一轮考察从节点优先级，优先级越小排名越靠前
- 第二轮考察，优先级相同则查看复制下标，哪个从*主节点*收到复制进度最多（repl_backlog_buffer的slave_repl_offset记录的进度）哪个靠前
- 第三轮考察，如果优先级和下标都相同，就选择从节点ID小的
在发送`SLAVEOF no one`后，以每秒一次频率向被升级节点发送`INFO`命令并观察回复的角色信息，当被升级节点中角色信息从slave升级到master后，哨兵leader就知道被选中从节点已经顺利升级为主节点
#### 将从节点指向新主节点
向其他所有从节点发送`SLAVEOF`，使称为新主节点从节点
#### 通知客户主节点已更换
通过Redis的订阅发布机制实现，每个节点提供机制，客户端从哨兵订阅消息
客户端和哨兵建立连接后，客户端订阅哨兵提供的频道；主从切换完成后，哨兵就会像`+switch-master`发布新主节点IP和端口消息，客户端向里进行通信
#### 将旧主节点变为从节点
哨兵继续监视旧主节点，旧主节点重新上线时，哨兵集群就会发送`SLAVEOF`命令，成为新主节点的从节点
### 哨兵集群是如何组成的
哨兵节点之间通过redis的发布订阅机制实现的
主从集群中，主节点有一个`__sentinel_:hello`频道，不同哨兵通过这个频道相互发现地址实现通信
主节点知道所有从节点信息，哨兵以每10s一次发送INFO获取所有从节点信息，与从节点建立链接
# 什么是缓存雪崩、击穿、穿透
### 缓存雪崩
**大量缓存数据在同一时间过期失效或Redis故障宕机**时，如果此时有大量的用户请求，都无法在redis中处理，于是全部请求直接访问数据库，导致数据库压力骤增，严重时导致数据库宕机系统奔溃
#### 大量数据同时过期
常见应对方法
- 均匀设置过期时间：避免将大量数据设置成同一个过期时间，在对缓存设计过期时间时，给数据过期时间加上一个随机数，避免同一时间过期
- 互斥锁：业务线程处理请求时，如果发现访问数据不在redis中，就加个互斥锁，保证同一时间只有一个请求构建缓存，缓存构建完后再释放锁。未能获取锁的请求等待锁释放获取缓存或返回空值
- 后台更新缓存：让缓存“永久有效”，由后台线程定时更新缓存
  - 后台线程不仅定时更新缓存，也频繁检测缓存是否有效，检测到失效后就重新读取数据库更新缓存
  - 业务线程发现失效后，通过消息队列发送消息通知后台线程更新缓存，后台线程收到消息后，更新缓存前判断缓存是否存在，不存在则更新缓存
#### Redis故障宕机
- 服务熔断或请求限流：服务熔断暂停业务对缓存的访问，直接返回错误；或启用限流，少部分请求发进数据库处理，其他请求直接在入口处就拒绝服务
- 构建redis缓存高可靠集群：主从节点方式构建redis缓存高可用集群，缓存的主节点宕机了就切换到从节点，继续提供服务
### 缓存击穿
数据中某个热点数据过期了，大量请求访问该数据，但是无法获取缓存就会直接冲击数据库，导致数据库被高斌发请求冲垮
- 互斥锁：保证同一时间只有一个业务线程可以更新缓存数据，未能获取互斥锁的请求，等待锁释放后重新获取或直接返回空值或默认值
- 不给热点数据设置过期时间，由后台内存异步更新缓存；或在数据要过期前，提前通知后台线程更新缓存和设置过期时间
### 缓存穿透
用户访问的数据既不在缓存中，也不在数据库中，导致请求访问缓存时发现缓存缺失，再去访问数据库也没发现数据，无法构建缓存服务后续请求，导致大量请求访问数据库，导致缓存穿透
缓存穿透一般有两种情况
- 业务误操作，缓存和数据库中数据都被误删除了
- 黑客攻击，故意大量访问不存在的数据
有三种常见方案
- 限制非法请求：大量恶意请求访问不存在的数据时，在API入口处判断参数是否合理，判断出如果是恶意请求就直接返回错误
- 缓存空值或默认值：业务发现缓存穿透时，针对查询的数据在缓存中设置一个空值或默认值，后续请求就可以直接读取缓存中的空值或默认值
- 布隆过滤器快速判断数据是否存在：在写入数据库时用布隆过滤器做标记，用户请求到来时业务线程确认缓存失效后，通过布隆过滤器判断数据是否存在，即使发生缓存穿透，请求也只会查询redis和布隆过滤器，不会直接打到数据库上
#### 布隆过滤器
由*初始值都为0的位图数组*和*N个哈希函数*两部分构成，写入数据库时，在布隆过滤器中做个标记，下次查询数据是否在数据库时，只需要查询布隆过滤器
布隆过滤器会通过三个操作完成标记
1. 将N个哈希函数分别对数据进行哈希计算，得到N个哈希值
2. 将哈希值对位图数组长度取模，得到每个哈希值在位图数组对应的位置
3. 将每个哈希值在位图数组对应位置的值设定为1
**不同的字符串可能哈希出来的位置相同，这种情况我们可以适当增加位数组大小或者调整我们的哈希函数。布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在**
# 数据库和缓存如何保证一致性
### 先更新数据库还是先更新缓存
无论是先更新数据库还是先更新缓存，都存在并发问题，当两个请求并发修改数据的时候，都会出现数据库和缓存数据不一致的问题
### 先更新数据库还是先删除缓存
Cache Aside不更新缓存而是删除缓存中数据，等读取数据发现缓存为空时，从数据库中更新数据到缓存中
**先删除缓存，再更新数据库**
读+写并发时（请求A删除缓存更新数据库晚于请求B更新缓存），还是会出现缓存数据库不一致问题
可以通过**延迟双删**解决
**先更新数据库，再删除缓存**
读+写并发时理论存在数据不一致问题，但是实际**出现概率不高**，缓存写入速度远快于数据库写入速度
可以保证数据一致性（再通过加上缓存过期时间兜底）
但是存在删除缓存操作失败问题，导致缓存存在旧数据问题
#### 更新数据库+更新缓存
由于更新数据库和更新缓存两个操作是独立的，两个更新请求并发执行时会出现缓存不一致问题
- 更新缓存前加**分布式锁**，同一时间只有一个请求更新缓存，但是会导致性能下降
- 更新完缓存后，给缓存**加上较短过期时间**，出现缓存不一致问题时也会很快过期
### 如何保证两个操作执行成功
#### 重试机制
将删除缓存操作加入**消息队列**，由消费者操作数据
- 如果应用删除缓存失败，从消息队列中重新读取数据，再次删除缓存，如果重试删除失败超过一定次数，则向业务层发送报错信息
- 如果缓存删除成功，就把消息从消息队列中移出，避免重复操作
或**订阅MysqlBinlog**；先更新数据库再删缓存第一步是更新数据库，更新成功则会产生变更日志再binlog中，订阅Binlog日志得到具体要操作的数据，再执行缓存操删除，阿里Canal中间件基于这个实现
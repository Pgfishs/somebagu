# Redis
### 什么是redis
基于内存的数据库，对数据的读写都是在内存中完成的，读写速度非常快，用于缓存、消息队列、分布式锁登场景
redis提供了多种数据类型，String、Hash、List、Set、Zset、Bitmaps、HyperLogLog、GEO、Stream，对数据类型的操作都是原子性的，因为**执行命令由单线程负责**，不存在并发竞争的问题
redis还支持事务、持久化、lua脚本、多种集群方案、发布/订阅模式、内存淘汰机制、过期删除机制等
### 和memcached异同
1. 都是基于内存的数据库，当做缓存使用
2. 都有过期策略
3. 高性能
区别
- redis数据更丰富，memcached只支持k-v数据结构
- redis支持持久化，保存在磁盘中，memcached挂掉后数据就没了
- redis原生支持集群模式，memcached需要依赖客户端实现往集群中分片写入数据
- redis支持订阅发布模型、lua脚本、事务等功能
### 为什么用redis作为mysql缓存
1. redis具备高性能。将访问数据缓存在redis中，下次访问时直接从缓存中读取，mysql数据改变后同步改变redis中数据即可，会有双写一致性问题
2. redis具备高并发。redis的qps可以破10w，而mysql很难破1w
# Redis数据结构
- String：缓存对象、常规计数、分布式锁、共享session等
- List：消息队列（生产者需要自行实现全局唯一ID，不能以消费组形式消费数据）
- Hash：缓存对象、购物车等
- Set：聚合计算（并集、交集等），比如点赞、共同关注等
- Zset：排序场景，比如排行榜、电话和姓名排序
以上是五种常见数据类型
----------
- BitMap：二值状态统计，比如签到、判断登陆状态、签到用户数等
- HyperLogLog：海量数据基数统计场景，比如百万级网页UV计数
- GEO：储存地理位置信息，比如嘀嘀打车
- Stream：消息队列（实现List没有的两个特性）
### 五种常见数据类型的实现
#### String
基于SDS简单动态字符串
- SDS可以保存二进制数据。使用len而非空字符判断是否结束，SDS所有API会处理二进制方式处理SDS存放在buf数组的数据，所以SDS还可以保存图片、音频、视频这样二进制数据
- SDS获取字符串长度的时间复杂度是O(1)
- SDS API是安全的，拼接字符串不会导致缓冲区溢出
#### List
双向链表或压缩列表
- 列表元素小于512个且每个元素值小于64，使用压缩列表
- 不满足上面使用双向链表
在3.2版本后，只用quicklist实现，代替了双向链表和压缩列表
#### Hash
压缩列表或哈希表
- 列表元素小于512个且每个元素值小于64，使用压缩列表
- 不满足上面使用哈希表
在7.0中压缩列表被listpack实现
#### Set
哈希表或整数集合
- 元素都是整数且个数小于512，使用整数集合
- 否则使用哈希表
#### Zset
压缩列表或跳表
- 元素小于128个且值小于64字节，使用压缩列表
- 否则使用跳表
7.0中由listpack实现压缩列表
# Redis线程模型
### Redis是单线程吗
redis单线程是指**接受请求->解析请求->读写操作->发送数据**这个过程是由主线程完成的，redis程序并不是单线程的，会**启动后台线程**BIO
- 2.6版本会启动两个后台线程，分别处理关闭文件、AOF刷盘
- 4.0以后新增线程，异步释放Redis内存，即lazyfree线程。删除线程会交给后台线程执行，不会造成主线程卡顿，删除大key时用unlink异步删除大key
redis创建单独线程处理耗时任务，避免造成主线程卡顿，后台线程相当于消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）轮询队列
关闭文件、AOF刷盘、释放内存三个任务有各自任务队列
### Redis单线程模式
redis首先初始化，创建socket并监听、注册连接事件处理函数，初始化结束后进入**事件循环函数**：
- 调用**处理发送队列函数**，发送队列中存在的任务，即通过write将客户端发送缓存区中数据发送，没发送完则注册写事件处理函数，等待epoll_wait发现可写后在处理
- 调用epoll_wait函数
	- 链接事件则调用**连接事件处理函数**，调用accept获取已连接socket->调用epoll_ctl将socket加入epoll->注册读事件处理函数
	- 读事件则调用读事件处理函数，调用read获取发送的数据->解析->处理->添加客户端对象至发送队列->写入执行结果到发送等待区等待发送
	- 写事件调用写事件处理函数，通过write发送客户端发送缓存区数据，没发送完则注册写事件处理函数，等待epoll_wait发现可写后在处理
### Redis单线程高QPS原因
- 大部分操作在内存中完成，采用了高效数据结构，瓶颈可能是内存或网络带宽
- 单线程避免了多线程竞争，省去了多线程切换带来的开销也避免了死锁
- 采用I/O多路复用机制处理客户端Socket请求
### redis6.0之前为什么使用单线程
CPU不是制约redis性能的瓶颈，多线程模型会带来并发读写的问题，增加系统复杂度，存在线程切换，甚至加锁解锁，死锁造成的性能损耗
### 6.0之后为什么引入了多线程
采用了多个IO线程处理网络请求，对于命令的执行仍然使用单线程
6.0以后启动redis时会创建额外6个线程，三个后台线程和三个IO线程
# Redis持久化
### redis如何实现数据不丢失
- AOF快照：每执行一条写操作命令，就把该命令以追加形式写入一个文件
- RDB快照：将某一时刻内存数据以二进制写入磁盘
- 混合持久化方式：集成AOF和RBD
### AOF日志的实现
执行完写操作后，将命令以追加方式写入文件，当Redis重启时会读取该文件记录的命令，逐一执行命令进行数据恢复
#### 为什么先执行命令再写入日志
- 避免额外检查开销。如果先写入日志，则需要进行语法检查造成额外开销，避免读取时出错
- 不会阻塞当前写操作命令的执行，当写成功后，才会记录到AOF日志
- **数据可能会丢失**。这两个操作不是一个原子操作，当没来得及将命令写入硬盘时服务器宕机，则会丢失数据
- **可能阻塞其他操作**。写成功后才记录到AOF日志，不会阻塞当前命令执行，但写入AOF的操作也是在主线程中执行，可能会阻塞后续操作
#### AOF写回策略
redis执行完写操作后将命令追加server.aof_buf缓冲区->write()系统调用，将缓冲区数据写入AOF文件，拷贝内核缓冲区pagecache等待内核写入硬盘->*内核决定何时写入硬盘*
redis三种写回策略，控制第三步过程
- Always：每次写命令执行完后同步AOF写回硬盘，可靠性高，但是性能开销大
- Everysec：写命令执行完后写入AOF文件内核缓冲区，每隔一秒写回硬盘，性能始终，宕机时会丢失1s内数据
- No：写命令执行完后写入AOF缓冲区，由操作系统决定何时写入硬盘
#### AOF日志过大触发机制
AOF重写机制，当文件大小超过阈值后触发，压缩AOF文件
再重写时，读取当前数据库中所有键值对，对每个键值对用命令写入到新AOF文件中，写完全部记录后用新AOF文件代替现有AOF文件
#### 重写AOF日志过程
后台子进程bgwriteaof完成
- 子进程重写AOF，避免阻塞主进程
- 子进程带有主进程数据副本，不使用线程避免修改共享内存，若使用线程需要加锁导致性能降低；而进程共享内存数据且只读，保证数据安全
重写过程中，主进程依然可以正常处理命令，redis设置AOF重写缓冲区避免主进程修改k-v导致和子进程数据不一致，缓冲区在创建后台子进程后建立。在重写AOF期间，redis主线程执行完命令后会写入AOF缓冲区和AOF重写缓冲区
子进程完成重写后，异步发送信号给主线程，主线程调用函数：
- 将AOF重写缓冲区中内容追加到新AOF文件中，使新旧AOF文件保存数据库状态一致
- 新AOF进行改名，覆盖现有AOF文件
### RDB快照实现
RDB快照记录某个瞬间内存数据，是实际数据，AOF保存命令操作日志。RDB恢复数据效率比AOF高
#### RDB快照会阻塞线程吗
通过save和bgsave生成RDB文件，区别在于是否在主线程中执行
- save在主线程中生成RDB文件，写入RDB时间太长会阻塞主线程
- bgsave创建子进程生成RDB文件，可以避免主线程阻塞，可通过配置文件实现自动执行bgsave
redis快照是**全量快照**，保存内存中所有数据到磁盘中，过于频繁的快照会对性能产生影响
#### RDB执行快照时可以修改数据吗
写时复制计数COW，可以继续处理操作命令
fork创建子进程，复制父进程页表，指向物理内存是同一个，如果主线程读操作，则主线程和bgsave进程互不影响；如果是写操作，修改的数据会创建副本，bgsave进程写入RDB文件，这个过程中主线程仍可以修改原来数据
#### 混合持久化
使用了混合持久化，AOF文件的前半部分是RDB格式的全量数据，后半部分是AOF格式增量数据，加载时速度会快
- 结合RDB和AOF优点，加快启动速度，降低大量数据丢失风险
- AOF文件添加了RDB格式内容，可读性变差
- 兼容性差，不能用在4.0之前版本
# Redis集群
### redis服务高可用
#### 主从复制
一主多从模式，主从服务器之间采用读写分离方式。主服务器进行读写操作，写操作时主服务器同步给从服务器，从服务器一般是只读，接收主服务器命令并执行
所有数据修改只在主服务器进行，然后将新数据同步给从服务器，主从之间命令复制是异步进行的
主服务器不会等待从服务器执行完写命令再返回服务器，而是本地执行完后就返回结果，从服务器如果没有及时执行命令就会导致主从之间数据不一致
#### 哨兵模式
哨兵模式可以监控主从服务器，提供主从节点故障转移的功能
#### 切片集群模式
Redis Cluster采用哈希槽处理数据和节点之间的关系，一个集群有16384个哈希槽，哈希槽类似数据分区，每个k-v值根据key映射到哈希槽中
- 根据键值对的key按照CRC16计算一个16bit值
- 值对16384取模，模数对应相应编号哈希槽
哈希槽有两种分配模式
- 平均分配：redis自动把哈希槽平均到节点上
- 手动分配：cluster meet命令手动建立节点，再addslots指定哈希槽个数
### 集群脑裂
#### 脑裂
redis主从架构中，一般都是一主多从，主节点提供写操作，从节点提供读操作，如果主节点与从节点失联，但主节点和客户端链接正常，客户端并不知道redis内部发生问题，还在写数据，都被缓存到旧主节点缓冲区中，无法同步给从节点
从节点也发现主节点失联，于是重新选举主节点，此时集群两个主节点就产生了**脑裂**；网络好了后，旧主节点会被降级成从节点，然后回向新主节点全量同步（清楚本地数据），导致先前写入的客户端数据丢失
**解决方案**
当主节点发现从节点下线或通信超时总数量小于阈值时，禁止主节点写操作，返回客户端错误；通过redis参数调节
- min-slaves-to-write x，主节点必须有x从节点链接，否则禁止写数据
- min-slaves-max-lag x，主从数据复制和同步延迟不能超过x秒，否则禁止写数据
即使原主库加固在，也会被限制写入，只有新主库上线时，新主库才能接受数据和处理请求，新数据会直接写入新主库中，从主库会被哨兵降级为从库
# Redis过期删除和内存淘汰
### 过期删除策略
对key设置过期时间时，redis会把该key带上过期时间存到一个**过期字典**中，当查询一个key是，首先检测是否存在过期字典中，不在则正常读取；存在则判定过期时间并对比
redis采用的过期删除策略是**惰性删除+定期删除**搭配使用
##### 惰性删除
不主动删除过期键，每次从数据库访问key时，检测是否过期，过期则删除key
- 优点：每次访问时才检测key是否过期，只会占用很少系统资源，对CPU时间最友好
- 缺点：key已经过期而又存在数据库中，只要这个过期key一直不被访问，占用的内存就不会释放，造成内存空间浪费，对内存不友好
##### 定期删除
每隔一段时间*随机*从数据库中取出一定的key检查并删除过期key
- 从过期字典中选择20个key
- 检查是否过期并删除
- 如果本轮检查已过期数量超过25%则重复检查，如果小于25%则停止检查等待下一轮检查时间到
- 优点：通过限制删除操作执行的时长和频率，减少操作对CPU的影响，也能减少一部分空间无效占用
- 缺点：难以确定删除操作执行时长和频率。太平凡则对CPU不友好，太少又对内存不友好
### 持久化对过期键处理
**RDB**：
- 生成阶段：过期间不会被保存到新RDB文件中
- 加载阶段：
	- 主服务器：载入RDB文件时，会对文件中保存的key进行检查，过期键不会被载入数据库中
	- 从服务器：载入时无论是否过期都会被载入数据库，但主从同步时，从服务器数据会被删除，所以不会造成影响
**AOF**：
- 写入阶段：如果某个过期key没被删除，AOF会保留该key，当过期键被删除后，会追加一条DEL命令显式删除该键
- 重写阶段：重写时会检查redis中键值，已过期的键不会被保存到重写后AOF文件中
### 主从模式对过期键处理
从库不会进行过期扫描，对过期的处理是**被动的**；主库再key到期时，会在AOF文件中增加一条del指令，同步到所有的从库，从库再执行命令删除
### redis内存满了会怎么样
触发内存淘汰机制，配置项maxmemory
### redis过期淘汰策略
##### 不进行数据淘汰的策略
- noeviction（3.0后默认）：当运行内存超过最大设置内存时，不淘汰数据，而是不再提供服务直接返回错误
##### 进行数据淘汰的策略
在设置了过期时间的数据中淘汰
- volatile-random：随机淘汰设置了过期时间的任意键值
- volatile-ttl：优先淘汰更早过期的键值
- volatile-lru：淘汰所有设置了过期时间键值中最久未使用的键值
- volatile-lfu：最少被使用的键值
所有数据范围内进行淘汰
- allkeys-random：随机淘汰任意键值
- allkeys-lru：最久未使用
- allkeys-lfu：最少被使用
### LRU LFU
传统LRU基于链表实现，淘汰最近最少使用数据，存在额外空间开销和链表移动操作带来的耗时
redis使用**近似LRU**算法，实现方式时在redis对象结构体中添加一个额外字段，记录此数据最后一次访问时间，使用随机采样方式淘汰数据，但是无法解决缓存污染问题，通过了**LFU**解决
redis的lru算法多记录了数据访问频次信息，redis对象头中的lru字段，在LRU和LFU算法下使用方式不同
**LRU**算法中，lru字段用来记录key的访问时间戳，在lru模式下redis可根据字段的值比较最后一次key的访问时间
**LFU**算法中，24bit的lru字段分为两段来储存，高16bit存储key访问时间戳，低8bit储存访问频次
# Redis缓存设计
### 缓存雪崩
当大量缓存数据在同一时期过期，如果又有大量用户请求，都无法在redis处理，于是请求直接访问数据库导致压力骤增，严重时导致数据库宕机，形成连锁反应造成系统奔溃，这就是缓存雪崩
可以通过两种方式解决
- 打乱缓存失效时间：在原有失效时间上增加一个随机值，降低集体失效概率
- 设置缓存不过期：设置后台服务更新缓存数据，避免缓存雪崩
### 缓存击穿
缓存中某个**热点数据过期**，大量请求访问了这个热点数据，就无法从缓存中读取，直接访问数据库，导致数据库被高并发请求冲垮，这就是缓存击穿问题
- 互斥锁方案，保证同一时间只有一个业务线程请求缓存；未能获取锁的请求要么等待释放后重新获取缓存，要么返回空值
- 不给热点数据设置过期时间，后台异步更新缓存，或在要过期前，通知后台线程更新缓存和重新设置时间
### 缓存穿透
访问的数据**既不在缓存中，也不再数据库中**，导致请求访问缓存时，发现缓存缺失，而数据库中也没数据，服务后续请求，这样大量请求到来时，数据库压力骤增，这就是缓存穿透
发生缓存穿透两种情况
- 业务误操作，删除了缓存和数据库中数据
- 黑客攻击，恶意访问大量不存在数据的业务
三种解决方案
- 限制非法请求，在API入口处就判断参数是否合理
- 设置空值或默认值，后续请求读取时就读到空值或默认值，不会查询数据库
- 使用布隆过滤器判断数据是否存在，避免通过查询判断数据是否存在：业务线程确认缓存失效后，通过查询布隆过滤器判断数据是否存在，即使发生缓存穿透，请求也只会查询redis和过滤器
### 设计一个缓存策略缓存热点数据
总体思路：通过数据最新访问时间做排名，过滤掉不常访问的数据，只留下经常访问的数据
### 常见缓存更新策略
- Cache Aside旁路缓存
- Read/Write Through 读/写穿透策略
- Write Back写回策略
最常用的是**旁路缓存**策略，程序直接和数据库、缓存交互，负责对缓存的维护，又课细分为*读策略*和*写策略*
**写策略步骤**：
- 先更新数据库中数据，再删除缓存数据
**读策略步骤**：
- 如果读取数据命中缓存，则直接返回数据
- 没有命中缓存，则从数据库中读取数据并写入内存，返回给用户
为什么*先更新数据库再删除缓存*不会导致数据不一致：概率不高，缓存写入远快于数据库写入，很难出现一边更新了数据库/删除缓存后，另一边才更新完缓存
旁路缓存适合读多写少场景，写入频繁时缓存会被频繁清理，对命中率有影响，如果对命中率有要求，有两种解决方案
- 更新数据时也更新缓存，在更新缓存前先加一个分布式锁，避免并发，对写入性能有影响
- 给缓存加一个较短过期时间，即使出现缓存不一致，缓存的数据也很快会过期
**读穿/写穿策略**
应用程序只和缓存交互，不和数据库交互，由缓存和数据库交互
**Read Through**策略：
- 先查询缓存中是否存在数据，存在则直接返回，不存在则由缓存数据负责从数据库中查询数据并将结果写入缓存组件，最后由缓存组件返回数据
**Write Through**：
- 如果缓存数据已存在，则更新数据并由缓存组件同步更新到数据库中，然后缓存组件告诉程序更新完成
- 不存在则直接更新数据库，然后返回
**WriteBack写回策略**
只更新缓存，将缓存数据设置为脏，然后立刻返回，对于数据库采用批量异步更新方式
写回策略不能用到常用数据库和缓存中，redis不支持异步更新，是CPU缓存、OS文件系统常用策略
特别适合写多场景，但数据不是强一致的，且有丢失风险
# Redis实战
### 延迟队列
把当前做的事情，延迟一定时间再做，比如下单超时、取消订单等
通过Zset有序集合实现，有一个Score属性存放延迟执行时间，使用zadd生产消息，再利用zrangebyscore查询符合条件的待处理任务
### Redis大key处理
指key对应value很大，一般两种情况
- String值大于10KB
- Hash、List、Set、Zset元素个数超过5000
会带来四个影响
- 客户端超时阻塞：redis单线程操作大key费时，从客户端看就是没有响应
- 引发网络阻塞：每次获取大key产生流量较大
- 阻塞工作线程：del删除大key时会阻塞工作线程
- 内存分布不均：集群在slot分片均匀情况下会出现数据和查询倾斜情况，部分大key占用节点多，qps大
通过redis -cli --bigkeys/SCAN/RdbTools查找大key
通过分批次删除/异步删除来删除大key
### Redis管道
一次处理多个redis命令，可以解决多个命令执行时网络等待，要注意避免发送命令过大或数据太多造成管道阻塞
### redis事务支持回滚吗
没有提供回滚机制，DISCARD命令只支持放弃事务，清空暂存命令队列，无法回滚
### 使用redis实现分布式锁
SETNX，如果key存在则插入成功（加锁成功），不存在则插入失败（加锁失败）
对于加锁操作，要满足三个条件
- 加锁包括读取锁变量、检查、设置三个操作，但需要原子操作，所以使用SET+NX实现
- 锁变量需要设置过期时间，以免无法释放锁
- 锁变量值需要区分不同客户端加锁操作，避免误释放，通过SET设置变量时，每个客户端都是唯一值
redis实现分布式锁的优点
- 性能高
- 实现方便
- 避免单点故障
	缺点
- 超时时间不好设置。可通过设置守护线程判断锁状态续约
- 主从复制模式数据异步复制，导致分布式锁不可靠性
#### 如何解决分布式锁可靠性
让客户端和多个独立Redis节点依次请求申请加锁，如果客户端能和半数以上节点成功加锁，就认为成功获得分布式锁
加锁成功后，重新计算有效时间，避免锁失效；加锁失败则发起释放锁操作
# Redis常见数据结构
### String
基本k-v结构，不仅是字符串，还可以是整数或浮点数，最大数据长度是512M
#### 内部实现
int和SDS(简单动态字符串)
- SDS可以保存二进制数据（图片、音频等）
- SDS获取字符长度O(1)
- SDS API安全，拼接字符串不会缓冲区溢出
内部编码有三种：int、raw、embstr
字符串保存**整数值**，且可以用long表示时，会将整数值保存在字符串对象结构的ptr中，编码设置为int
字符串保存的是**字符串，且长度≤32字节**，会使用SDS保存，并设置编码为embstr；如果大于32字节，会使用SDS保存，且设置编码为raw
embstr&raw在不同版本边界不同，2+为32、3-4为39、5.0为40字节
embstr使用一次内存分配函数分配**连续内存空间**保存redisObject和SDS，而raw使用两次内存分配**两块内存空间**保存redisObject和SDS
embstr创建分配内存、释放内存的操作只要一次，且因为连续内存使得embstr可以更好利用CPU缓存；但缺点是字符串长度增加时需要重新分配内存，所以embstr编码是只读的，使用append增加时会先转为raw再修改
#### 应用场景
**缓存对象**：缓存整个对象JSON；将key分离为对象属性，采用MSET保存
**常规计数**：计算访问次数、点赞、转发、库存等情况
**分布式锁**：SETNX
**共享session信息**：分布式系统服务器获取用户session
### List
字符串链表，按照插入顺序排序。最大长度2^32 - 1
#### 内部实现
**双向链表**或**压缩列表**
- 元素个数小于512，且值小于64字节，使用压缩列表
- 否则使用双向链表
3.2之后使用quicklist代替双向链表和压缩链表
#### 应用场景
**消息队列**：必须满足**消息保序、处理重复消息和保证消息可靠性**，redis的List和Stream就可以满足这三个需求
##### 消息保序
通过LPUSH+RPOP实现消息队列
- 生产者通过LPUSH插入队列头部
- 消费者通过RPOP读取队伍消息
但是存在性能风险，即消费者不知道生产者是否写入新消息，需要重复调用RPOP读取队列，影响性能，通过BRPOP阻塞式读取解决，客户端没有读到数据时会阻塞，直到有新数据写入
##### 重复消息处理
List不会为每个消息生成ID号，需要自信为每个消息生产唯一全局ID
##### 消息可靠性
提供了BRPOPLPUSH命令留存消息，让消费者程序从一个LIST中读取消息，同时Redis会把这个消息再插入另一个List留存
#### 作消息队列缺陷
不支持多个消费者消费同一个消息，一个消费者拉取一条消息后，这条消息就从List中删除了，List并不支持消费组的实现
### Hash
#### 内部实现
由哈索列表或哈希表实现
- 如果哈希类型元素小于512个，所有值小于64，使用压缩列表
- 否则使用哈希表
7.0中压缩列表被listpack实现
#### 应用场景
**缓存对象**：将哈希的key、field、value和对象的id、属性、值对应。一般对象用String+Json储存，其中频繁变化的属性可以考虑用Hash储存
**购物车**
### Set
set是无需且唯一的键值集合，存储顺序不会按照插入先后顺序进行储存
Set和List区别
- List可以存重复元素，Set只能存非重复元素
- List有序，Set无序
#### 内部实现
- 元素都是整数且个数小于512，使用整数集合
- 否则哈希表i
#### 应用场景
适合存储的数据是无序且需要去重
**点赞**：Set可以保证用户只能点一个赞
**共同关注**、**抽奖活动**（去重，保证只有一个人中奖）
### Zset
有序集合，相比Set多了一个score排序属性，对于Zset每个元素由两个值组成，一个是有序集合的元素值，一个是排序值
#### 内部实现
压缩列表或跳表
- 集合元素个数小于128且元素值小于64字节，使用压缩列表
- 否则使用跳表
7.0中压缩列表被listpack代替
#### 应用场景
**排行榜**、**电话/姓名排序**
### BitMap
适合数据量大且使用**二值统计**
#### 内部实现
基于String，Redis将字节数组每个bit位表示元素的二值状态，可以把BitMap看作bit数组
#### 应用场景
**签到统计**：使用0 1标记签到情况，通过命令可以获取首次打卡日期
**判断用户登录态**
**连续签到用户总数**：把每天日期作为key，userid作为offset，若打卡则将offset的bit设置为1；共有N个Bitmap，对这N个Bitmap作与运算，当一个userid在N个Bitmap对应位置的bit = 1则说明该用户连续N天签到了
### HyperLogLog
提供不精确的去重计数，标准误差率是0.81%
#### 内部实现
？
#### 应用场景
百万级网页UV计数
### GEO
地理信息
#### 内部实现
使用了Sorted Set，对GeoHash编码实现了从经纬度到SortedSet元素权重分数的转换
#### 应用场景
嘀嘀打车
### Stream
专门为消息队列设计的数据场景，支持消息持久化、生成全局唯一ID、ack确认消息模式、消费组模式等
#### 应用场景
**消息队列**
##### 故障处理
使用内部队列保证消费者故障/宕机后处理未完成消息。内部队列存留消费组中每个消费者读取的消息，直到消费者使用XACK通知Stream消息已经处理完成，消费者可以使用XPENDING查看已读取但未完成消息
##### Stream对比专业的消息队列
***Stream消息会丢失吗***：
- 生产者会不会丢消息，取决于生产者对异常情况处理。消息被生产出来，交给MQ过程中，只要能收到ACK就表示发送成功，返回异常则消息重发，那么是不会出错的
- 消费者不会丢消息，因为Stream会自动使用内部队列留存消费组中每个读取的消息，未被读取的消息重启后也可以重新读取
- Redis消息中间件会不会丢消息？**会**
	- AOF持久化写盘异步操作时，Redis宕机会导致数据丢失
	- 主从复制异步，主从切换时也可能丢失数据
RabbitMQ Kafka这种专业消息队列中间件，使用集群部署，即使一个节点挂了，集群也能保证数据不丢失
***Stream消息可堆积吗***：
Stream通过指定队列最大长度，避免消息积压在内存中导致OOM
如果堆积消息长度超过最大值，还是可能丢失消息
但Kafka RabbitMQ这种专业消息队列都是存储在硬盘上，不会OOM KILL掉
所以Redis当MQ使用存在两个问题
- Redis本身可能丢数据
- 面对消息挤压，内存资源会紧张
如果业务简单、数据丢失不敏感、消息挤压概率小，那么Redis当MQ完全可以；其他还是用MQ吧
##### Redis的订阅/发布机制为什么不能当MQ使用
- 发布/订阅机制没有基于任何数据类型实现，所以不具备持久化功能，不会被写入RDB和AOF中，Redis宕机重启后，发布/订阅的数据也会全部丢失
- 发后即忘，如果有订阅者重连后不能消费之前的历史消息
- 消费端有一定消息挤压，消费者消费不过来时，如果超过32M或60s内持续保持在8M以上时，消费端会被强行断开
发布订阅机制只适合即时通讯场景，比如构建哨兵集群
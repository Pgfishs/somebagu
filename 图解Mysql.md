# 执行select期间发生了什么
### 第一步：连接器
通过连接器链接Mysql，Mysql都是通过TCP协议进行传输的。当空连接超过`wait_timeout`参数时将会自动断开；Mysql默认最大连接数是151个，和HTTP一样都有长短连接概念，可以通过**定期断开长连接**和**客户端主动重置链接**来解决长连接占用内存的问题
### 第二步：查询缓存
服务端解析SQL语句，先去查询缓存中是否有这个语句（以k-v缓存），被命中则直接返回value，*在8.0以后Mysql将查询缓存删除了*
### 第三步：解析SQL 解析器
#### 第一步：词法分析
根据输入字符串识别关键词，得到TOKEN
#### 第二步：语法分析
根据词法分析结果，语法解析器根据语法规则判断语法，构建SQL语法树，方便后续模块获取SQL类型、表名等
### 第四步：执行SQL
每条SELECT经过三个阶段
- prepare预处理
- optimize优化阶段
- execute执行阶段
#### 预处理器
- 检查SQL语句中表或字段是否存在
- 将`select *`中`*`扩展为表上所有列
#### 优化器
负责将SQL查询语句执行方案确定下来，比如多个引索时确定引索，确定覆盖引索/普通引索等
#### 执行器
- 主键索引查询
- 全表扫描
- 索引下推
**主键索引下推**
- 执行器第一次查询，调用read_first_record指针，这个指针被指向InnoDB索引查询的接口，吧id = 1交给储存引擎，让储存引擎定位符合条件的第一个记录
- 返回记录，不存在则报错
- 执行器判断记录是否符合查询条件，返回记录或跳过该记录
- 执行器查询是while循环，再查一次调用read_record指向的函数，被定位为永远返回-1的函数，退出循环
**全表扫描**
- 第一次查询调用read_first_record，指向InnoDB全扫描接口，让存储引擎读取表中的第一条记录
- 执行器判断条件是否符合，发给客户或跳过
- 执行器while循环查询，存储引擎调用read_record根据条件查询完全表，直到读完整个表，返回读取完毕
- 执行器收到读取完毕，退出
**索引下推**
能减少二级索引在查询时的回表操作，提高查询效率，因为他将Server层事情交给存储引擎去处理了
不适用索引下推时，存储引擎根据二级索引B+树定位到记录后获取主键值，进行徽标操作返回给Server层判断联合索引的条件；使用索引下推时，不回表，先判断索引中的条件是否成立，不成立直接跳过，成立再执行回表操作
# Mysql一行记录的储存
### Mysql数据的存放
/var/lib/mysql/dbname目录下，db.opt储存当前数据库默认字符集和校验规则；xxx.frm储存表结构，保存每个表的元数据信息；xxx.ibd保存表数据，每个表默认存放一个独立的.ibd文件
#### 表空间文件的结构
表结构由**段（segment）、区（extent）、页（page）、行（row）** 组成
##### 行
表中结构都是按行存放，每行记录根据不同的行格式有不同的存储结构
##### 页
InnoDB按**页**为单位读取数据，每个页默认大小为16KB
页的类型有很多，常见有数据页、undo日志页、溢出页等。数据表中行记录是用数据页来管理的
##### 区
表中数据量大时，按照区为单位为索引分配空间。每个区大小为1MB，64个16KB的连续的页会被划为一个区，使相邻页中物理位置也相同，就能顺序I/O
##### 段
一般分为数据段、索引段、回滚段
- 索引段：存放B+树非叶子节点的区的集合
- 数据段：存放B+树叶子节点的区的集合
- 回滚段：存放回滚数据的区的集合
### InnoDB行格式
提供四种行格式
- Redundant，5.0以前用的行格式
- Compact，紧凑行格式存放更多行记录，5.1后默认行格式
- Dynamic&Compressed紧凑行格式，和Compact差不多，从5.7后默认使用Dynamic
### Compact行格式长什么样
#### 记录的额外信息
##### 变长字段长度列表
varchar和char区别->变长字段实际存储的数据长度时不固定的，把数据占用的大小存进**变长字段长度列表**中，读取数据时根据这个去读对应长度的数据。变长字段真实占用的字节数会按照列的顺序**逆序存放**（使靠前记录的真实数据和队友长度信息同时在一个cacheline中提高命中率）；NULL不会存在真实数据中，当数据表没有变长字段时，就没有这个列表了
##### NULL值列表
每个列对应一个二进制位，位为1时代表为NULL（逆序存放），同理无NULL时就没列表
##### 记录头信息
- delete_mask：标识数据是否被删除
- next_record：下一条记录位置
- record_type：当前记录类型，0普通记录，1B+树非叶子节点记录，2最小记录，3最大记录
#### 记录的真实数据
定义的字段+三个隐藏字段
- row_id：InnoDB会添加这个隐藏字段，当指定了主键或唯一约束列，就没有这个字段了，占用6个字节
- trx_id：事务id，表示由哪个事务生成；必需的，6个字符
- roll_pointer：这个记录上个版本的指针；必需的，7个字符
### varchar最大取值
Mysql中规定除TEXT、BLOBs其他所有列占用字节长度加起来不超过65535字节
#### 单字段情况
一行数据的最大字节数是65535，其中包含了storage overhead，即**变长字段长度列表**&**NULL值列表**占用字节数，在算varchar(n)的n最大值时需要减去上面占的字节数；实际上varchar被分为三个部分来储存
- 真实数据
- 真实数据占用的字节数
- NULL标识
UTF-8下，最大n取值时21844（一个字符需要三个字节）
#### 多字段情况
保证所有字段长度+变长字段字节数列表占用字节数+NULL值列表占用字节数<=65535
### 行溢出后Mysql是怎么处理的
一个页一般是16KB，当存大对象时一个页可能存不了一个记录，就会发生**行溢出**，多的数据就会存到另外的溢出页中，在记录的真实数据处只会保存该列一部分数据，用20字节指向存储溢出页的地址；Dynamic和Compressed使用完全的行溢出方式，真实地址处只储存20个字节指针指向溢出页
# 索引
数据的目录，Mysql存储引擎有MyISA、InnoDB、Memory，InnoDB在5.5后称为默认存储引擎
### 索引分类
- 数据结构分类：B+树索引、Hash索引、Full-text索引
- 物理存储分类：聚簇索引（主键索引）、二级索引（辅助索引）
- 字段特性分类：主键索引、唯一索引、普通索引、前缀索引
- 字段个数分类：单列索引、联合索引

|  类型  |InnoDB|MyISAM|Memory|
| ----- |------|------|------|
|B+|Y|Y|Y|
|HASH|N|N|Y|
|FullText|Y|Y|N|
InnoDB在5.5后成为默认存储引擎，会根据不同场景使用不同列做索引
- 有主键默认使用主键作为聚簇索引的key
- 没有主键则使用第一个不包含NULL的唯一列作key
- 都没有则生成隐式自增id作为key
创建的主键索引和二级索引默认使用B+索引
B+树是多叉树，叶子节点存放数据，非叶子节点存放所有，每个节点的数据都是按主键顺序存放的，每一层夫索引值都出现在下层子节点的索引值中，所以叶子节点中包括所有的索引值信息，每个叶子节点之间都有双向链表。B+树查找千万级数据只要3~4次IO
#### 唯一索引 
一张表可以有多个唯一索引，索引列的值必须唯一，允许空值
#### 前缀索引
对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段为char类的列上
#### 联合索引 
存在最左匹配原则，按照最左优先方式进行索引匹配，不遵循则联合索引会失效
联合索引存在特殊情况，在范围查询的字段可以用到联合索引，在范围查询字段后的字段无法用到联合索引
#### 索引下推 
在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数
#### 索引区分度
建立联合索引时，要把区分度大的字段排在前面，区分度大的字段越有可能被更多sql使用到
### 什么时候需要创建索引
索引也存在缺点
- 占用物理空间，数量越大占用空间越大
- 创建索引和维护索引需要耗费时间
- 降低表的增删改效率，每次增删改索引，B+树都需要动态维护
##### 什么时候适用索引
- 字段有唯一性限制的
- 常用WHERE查询条件的
- 常用GROUP BY和ORDER BY的
##### 什么时候不需要创建索引
- WHERE、GROUP BY、ORDER BY用不到的字段
- 字段中存在大量重复数据
- 表数据太少
- 经常维护的字段
### 索引优化办法
#### 前缀索引优化
减少索引字段大小，增加一个索引页中存储的索引值，提高查询效率，减小索引项大小；但也存在局限性
- order by无法使用前缀索引
- 无法把前缀索引用作覆盖索引
#### 覆盖索引优化
指SQL中query的所有字段，在索引B+树叶子节点上都能找到的索引，从二级索引中查询到的记录，而不需要通过聚簇索引查询获得，避免回表
#### 主键索引最好自增
InnoDB创建主键索引默认为聚簇索引，存在B+树叶子节点上，按主键顺序存放的。使用自增主键，每次插入叶子节点都是追加操作，不需要移动数据；而使用非自增主键，可能会移动数据造成页分裂，产生内存碎片
主键字段越小，二级索引叶子节点越小，占用空间越小
#### 索引最好设置为NOTNULL
- 存在NULL使优化器选择索引时复杂，难以优化
- 无意义但是会占用物理空间
#### 防止索引失效
- 左、右模糊匹配时，都会造成索引失效
- 查询时对索引列作了计算、函数、类型转换会造成失效
- 联合索引没能匹配最左匹配原则会造成失效
- WHERE语句中OR前条件列是索引列，而OR后条件列不是索引列，会造成索引失效
尽量让SQL使用range以上级别type访问方式，type字段扫描效率
- 全表扫描
- 全索引扫描
- 索引范围扫描
- 非唯一索引扫描
- 唯一索引扫描
- 结果只有一条的主键或索引扫描
# 数据页看B+树
### InnoDB储存数据
按**数据页**为单位读写，默认大小是16KB，即一次IO最少16KB
*InnoDB格式：*

|名称|说明|
|---|---|
|文件头(38字节)|表示页信息|
|页头(56字节)|表示页状态信息|
|最大、最小记录(26字节)|虚拟伪记录，表示页中最大最小记录|
|用户记录(不确定)|储存行记录内容|
|空闲空间(不确定)|页中未被使用空间|
|页目录(不确定)|储存用户记录相对位置，起索引作用|
|文件尾(8字节)|校验页是否完整|
文件头中有两个指针，指向上/下一个人页，连起来形成双向链表，构成逻辑上的联系
数据页中的记录按照**主键**顺序组成单向链表，数据页中有**页目录**，起到记录索引作用
页目录创建过程：
- 将记录分为多个组，包括最大最小记录，但不包括“已删除”记录
- 将每个记录组最后一条记录（组内最大记录），且最后一条记录头信息会存有该组共多少条记录，作为n_owned字段
- 页目录存储每组最后一条记录地址偏移量，这些偏移量会按照先后顺序存储，且这些地址也被称之为**槽**，每个槽相当于指针指向了不同组的最后一个记录
页目录就是由多个槽组成的，槽相当于分组记录的索引。槽是按照主键值大小从小到大排序，通过槽查找记录时，使用二分法定位需要查询的槽，定位到槽后遍历所有记录，找到对应记录
InnoDB对分组中记录有规定
- 第一个分组中记录只有一个记录
- 最后一个分组中记录条数在1-8条之间
- 剩下分组记录条数范围再4-8条之间
### B+树如何查询
InnoDB使用B+树作为索引，每个节点都是一个数据页
- 只有叶子节点存放数据，其他节点仅存放目录项作索引
- 非叶子节点分不同层次，通过分层降低每一层搜索量
- 所有节点按照索引键大小快速排序，构成双向链表
### 聚簇索引和二级索引
- 聚簇索引叶子节点存放实际数据，所有完整用户数据都存放在聚簇索引叶子节点
- 二级索引叶子节点存放主键值，而非实际数据
InnoDB一定会为表创建一个聚簇索引，有且仅有一个，会根据不同场景选择不同列作为索引
- 主键
- 无主键则选择第一个不包含NULL的唯一列
- 都没有则自动生成隐式自增id
如果某个查询语句用了二级索引，但查询的数据不是主键值，那么找到二级索引后需要去聚簇索引中获得数据行，这个过程就叫回标，就是需要查两个B+树才能得到数据。查询的是主键时，通过二级索引就能查到，不再用聚簇索引，这时候叫索引覆盖
# 为什么使用B+树作索引
### 二分查找树
一个节点左子树所有节点都小于这个节点，右子树都大于这个节点
当每次插入元素都是最大元素时，就会退化成链表
树的高度就是查询时磁盘IO次数
### 自平衡二叉树
AVL树，左右子树高度不超过1，还有红黑树通过约束达到自平衡
不管是AVL树还是红黑树，都会随着插入元素变多导致树高度增加，磁盘IO次数多，影响查询效率（二叉树限制）
### B树
B树每个节点最多可以包含M个子节点，称为B树的阶，多叉树可以降低树的高度。每个节点最多有M-1个数据和M个子节点，超过要求则会分裂节点
B树每个节点都包含索引+记录，记录数据的大小可能远超索引大小，就需要更多磁盘IO读到有用数据；如果读最底层节点时，回加载不要的数据，占用内存数据，且范围查找时需要中序遍历，设置到磁盘IO问题
### B+树
- 叶子节点存放数据，非叶子节点存放索引
- 所有所有都会在叶子节点出现，叶子节点间构成有序链表
- 非叶子节点的所有也会同时存在子节点中，且是子节点中所有索引最大（最小）
- 非叶子节点中有多少子节点，就有多少索引
#### 单点查询
B树最快O(1)就能查到数据，但查询波动大
数据量相同时，B+树非叶子节点可以存放更多索引，因此B+树比B树更矮胖，查询底层节点磁盘IO次数更少
#### 插入和删除效率
B树没有冗余节点，删除时可能发生复杂的树的变形，插入也同理，B+树只涉及树的一条路径；且B+树会自动平衡，不需要更多复杂算法，比如红黑树的旋转
#### 范围查询
B+树所有叶子节点之间用链表链接，而B树只能通过遍历完成范围查找
#### Mysql中B+树
见上一篇
# Mysql单表最大值
单表数据达到2000w时，查询时长急剧上升
### 单表数量限制
主键大小可以限制表的上限
- 主键int声明，最大支持2^32~21亿
- bigint则是2^62-1
建表时自增字段选择无符号bigint，则自增最大值是18446744074709551615

### 单表建议值
索引B+树的非叶子节点存放索引，叶子节点存放数据，一个16K的页非叶子节点每个每条数据都指向新的页，新的页有两种可能
- 叶子节点则是数据
- 非叶子节点则继续指向新页
设非叶子节点指向其他页数量为x，叶子节点内数据行数为y，B+树层数为z，则**Total = x^(z-1) * y，总数等于x的z-1次方与y乘积**
#### X=?
索引和页一样存在页结构，+页目录大小为1k，整个数据页剩余15K存放数据，主键假设为bigint(8byte)，页号也固定(4byte)，索引中每个数据为12byte，则x=15 * 1024/12 = 1280行
#### Y=?
叶子节点和非叶子节点相同，都可以存放15k数据，假设一行数据为1k，一页最多存下15条，则Y=15 * 1024/1000 = 15
#### Total
根据公式Total = x ^ (z-1) * y，假设B+树是**2层(z=2)** 则total = 19200，**z=3**则total=2450w 即最大行数建议值2kw

在保持相同层级的情况下，行数据大小不同会导致最大建议值也不同，其他因素也会影响查询性能
Mysql为了提高性能，会将表索引加载进内存，InnoDB buffer size足够情况下能完全加载进内存，当单表数据库达到上线时，会导致内存无法储存其索引，使之后的SQL产生磁盘IO导致性能下降
# 索引失效有哪些
### 索引储存结构
InnoDB默认创建一个主键索引，也就是聚簇索引，其他索引都属于二级索引
MyISAM支持多种索引数据结构，B+树、R树、FULLTEXT索引等，创建表时默认是B+树索引
- InnoDB B+树索引的叶子节点保存数据本身（二级索引只保存主键值）
- MyISAM B+叶子节点保存数据的物理地址
### 对索引使用左或右模糊匹配
like关键字`like %xx`或`like %xx%会造成索引失效
**B+树按照索引值有序排列存储，只能根据前缀进行比较**，模糊匹配时不知道如何查询只能作全表查询
### 对索引使用函数
索引保存的是原始数据，经过函数计算后的值无法走索引
8.0后索引特性增加了函数索引，可针对函数计算后的值建立一个索引，该索引的值是经过函数计算后的值，可以通过扫描索引进行查找
### 对索引进行表达式计算
和对索引使用函数差不多，索引保存的是原始数据的值
### 对索引隐式数据转换
条件查询时使用和索引字段不同类型的参数，查询时就会走全表扫描
**Mysql遇到字符串和数字比较时，自动将字符串转为数字**，用整形查找字符串索引时会失效，反之则不会
### 联合索引非最左匹配
多个普通字段组合在一起叫联合索引，使用时需要满足最左匹配原则，否则会导致索引失效
在联合索引情况下，数据按第一列排序，第一列数据相同时才会按照第二列排序
### Where中的OR
OR前条件是索引，而OR后不是，则会导致索引失效
OR的含义是两个满足一个就行，只有一个条件列是索引是没有意义的，只要有条件列不是索引列，就会进行全表扫描
# Mysql使用like "%x"索引一定会失效吗
表中存在非索引列时，使用`select * like %x`会导致索引失效；而当表中没有非索引列时，`select *`就相当于查找的数据都在二级索引的B+树中，因为二级索引的B+树包含索引+主键值，这就是覆盖索引
扫描二级索引树效率高，聚簇索引树包含主键值、事务id、MVCC回滚指针的内容。同时select * 不用执行回表操作，所以优化器直接全扫描二级索引树
加了非索引字段后，执行相同查询语句走了全表扫描，因为这时查询数据需要进行回表操作，再加上是左模糊匹配无法根据树的有序性快速定位，所以直接遍历二级索引树获取主键值后，再到聚簇索引树中检索对应数据行
# count(\*)和count(1)区别
### count性能哪个最好
count(\*)=count(1)>count(主键)>count(字段)
### count是什么
统计符合查询条件的记录中，指定参数不为NULL的记录有多少
### count(主键)执行过程
count统计记录时，Mysql的server层会维护一个count变量，server会循环向InnoDB读取记录，如果count函数指定的参数不为NULL则会将变量count+1，直到读完全部记录再退出循环，将count变量值发送给客户端
如果表中只有主键索引，没有二级索引时那么InnoDB遍历聚簇索引，将读到的记录返回给server层，然后读取记录中的id值，判断是否为NULL，并将count+1
如果由二级索引，则InnoDB遍历的就是二级索引，因为相同数量二级索引记录比聚簇索引树小，遍历二级索引的IO成本就比遍历聚簇索引IO成本小
### count(1)执行过程
如果表中**只有主键索引**，则循环遍历聚簇索引，又count(1)参数不是字段，则无需读取记录中字段值，每读取到一个记录，就会将count变量+1
count(1)比count(主键)少一个读取记录字段的步骤，执行效率高
如果有**二级索引**时，InnoDB遍历二级索引
### count(\*)执行过程
count(\*) = count(0)，所以执行过程和count(1)基本一致
mysql会对count(\*)和count(1)优化，有多个二级索引时会使用key_len最小的二级索引扫描
### count(字段)执行过程
这个查询会采用全表扫描技术，执行效率较差
### 为什么采用遍历方式计数
InnoDB中都采取遍历方式，而MyISAM中查询速度更快，只需O(1)，因为MyISAM数据表都有**meta信息**存储了row_count值，由表级锁保证一致性，所以直接读取row_count值就是count结果
而InnoDB支持事务，同一个时刻的多个查询，由于版本并发控制(MVCC)原因，InnoDB“应该返回多少行”也是不确定的，无法像MyISAM一样维护一个row_count变量
### 如何优化count(\*)
1. 返回近似值
2. 额外表保存计数值，但是有额外维护开销
# 事务隔离级别的实现
### 事务特性
- 原子性：一个事务中所有操作，要么全部完成，要么全部失败，不会结束在中间状态
- 一致性：事务操作前操作后，数据满足完整性约束，数据库保持一致性状态
- 隔离性：数据库允许多个并发事务同时对于数据进行读写和修改能力，隔离性可以防止多个事务并发而导致数据不一致
- 持久性：事务结束后，对数据的修改就是永久的，系统故障也不会丢失
InnoDB通过以下计数保证四个特性
- 持久性通过redo log（重做日志）
- 原子性通过undo log（回滚日志）
- 隔离性通过MVCC（多版本并发控制）或锁机制保证
- 一致性通过持久性+原子性+隔离性保证
### 并发事务会引发什么问题
#### 脏读
一个事务**读到**另一个**未提交事务修改过的数据**就会发生脏读
#### 不可重复读
一个事务内**多次读取一个数据**，前后两次读到的数据前后不一致，就发生了不可重复读
#### 幻读
一个事务内多次查询某个符合查询条件的记录数量，出现前后两次查询到的记录数量不一致
### 事务隔离级别
事务问题严重性 脏读＞不可重复读＞幻读
SQL有四种隔离级别规避这些问题，隔离级别越高性能越低
- 读未提交：一个事务还没被提交时，作的更改就能被其他事务看到
- 读提交：一个事务提交之后，做的变更才能被其他事务看到
- 可重复读：一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**InnoDB默认隔离级别**
- 串行化：对记录加上读写锁，多个事务对这条记录进行读写操作时，如果发生了读写冲突，后访问数据必须等前一个事务执行完成才能操作
隔离级别 串行化＞可重复读＞读已提交＞读未提交
- 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；
- 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
- 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；
- 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生
InnoDB默认隔离级别是可重复读，但是很大程度上避免了幻读现象，通过两种方案解决
- 针对快照读（普通select）通过**MVCC**解决幻读，可重复读隔离级别下，事务执行过程中看到的数据一直和这个事务启动时看到的数据是一致的，即使中途插入了其他数据也是查询不出来的
- 针对当前读（select...for update)通过**next-key lock（记录锁+间隙锁**解决了幻读，当执行select...for update时会加上next-key lock，其他事务在锁范围内插入语句时会被阻塞
四种隔离级别的实现
- 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了
- 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问
- 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过**Read View**来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。**「读提交」** 隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个Read View，然后整个事务期间都在用这个**Read View**
### ReadView在MVCC中如何工作的
ReadView有四个重要的字段
- m_ids：在创建ReadView时，当前数据库中**活跃事务**中的事务id列表（启动了还未提交的食物）
- min_trx_id：创建ReadView时当前数据库**活跃事务**中事务id**最小**的事务
- max_trx_id：创建ReadView时当前数据库中应该给下一个事务的id值，全局食物中最大的事务id+1
- creator_trx_id：创建该ReadView的事务的事务id
对于使用InnoDB的数据库表，聚簇索引记录中都包含下面两个隐藏列：
- trx_id：当一个事务对某个聚簇索引记录进行改动时，**会把该事务id记录在trx_id隐藏列里**
- roll_pointer：对某条聚簇索引记录进行改动时，会把旧版本记录写入undo log中，**这个隐藏列是个指针，指向每一个旧版本记录**
一个事务去访问记录的时候，除了自己的更新记录总是可见的外，还有几种情况
- 记录的trx_id小于ReadView中`min_trx_id`，表示这个版本的记录是在创建ReadView前已经提交的事务生成的，所以该版本的记录对当前事务可见
- 记录的trx_id大于`max_trx_id`，表示这个版本的记录是在创建ReadView后才启动的事务生成的，对当前事务不可见
- 如果trx_id在min和max之间
  - 如果记录的trx_id在`m_ids`列表中，表示生成该版本记录的事务仍然活跃着，该版本记录对当前事务不可见
  - 如果记录的trx_id不在`m_ids`列表中，则当前事务不可见
通过版本链控制并发事务访问同一个记录的行为就叫MVCC
### 可重复读是如何工作的
可重复读隔离级别是启动事务时生成一个ReadView，整个事务期间都在用这个ReadView，通过事务的trx_id进行版本控制
### 读提交是如何工作的
读提交是在每次读取数据时都会生成一个新的ReadView
# Mysql可重复读级别完全解决幻读了吗
### 幻读
同一个查询在不同时间返回了不同的结果集，事务就出现了幻读
### 快照读是怎么避免幻读的
可重复读通过MVCC实现，MVCC在事务开始后创建一个ReadView，后续事务利用这个ReadView在undolog中找到事务开始时候的数据，所以每次查询数据是一致的
### 当前读是如何避免幻读的
Mysql中除了普通查询是快照读，其他都是**当前读**，例如update、insert、delete等，`select ... for update`这种查询语句也是当前读
InnoDB通过间隙锁解决了可重复读级别使用当前读造成的幻读问题
通过`next-key lock间隙锁+记录锁`阻塞指定位置中记录被插入，解决幻读
### 幻读被完全解决了吗
在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作。这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读
因为这种特殊现象的存在，所以我们认为 **MySQL Innodb 中的 MVCC 并不能完全避免幻读现象**

除了上面这一种场景会发生幻读现象之外，还有下面这个场景也会发生幻读现象。
- T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。
- T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；
- T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。

**要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句**，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录
# Mysql有哪些锁
### 全局锁
`flush tables with read lock`执行后整个数据库就处于只读状态，对数据增删改查/更改表结构都会阻塞
`unlock tables`释放全局锁
全局锁应用于**全库逻辑备份**，在备份数据期间，不会因为数据或表结构的更新出现备份数据和预期不一致；**缺点**是整个数据库都是只读状态，如果有很多数据则备份就会花费很多时间，造成业务停滞
如果数据库引擎支持**可重复读**级别，在备份数据库之前先开启事务，会创建ReadView，事务执行期间都用这个ReadView，且由于MVCC支持，备份期间依然可以对数据进行更新
### 表级锁
#### 表锁
对表加表锁
`lock tables name read`表级别共享锁，读锁
`lock tables name write`表级别独占锁，写锁
表锁除了会限制别的线程读写外，也会限制本线程接下来的读写操作
尽量避免使用InnoDB表锁，因为颗粒度太大会影响并发性能
#### 元数据锁
不需要显式使用MDL，因为当对数据库表进行操作时，会自动给表加上MDL
- 对表进行CRUD时，加的是MDL读锁
- 进行结构更改时，加的是MDL写锁
MDL是为了保证用户对表执行CRUD操作时，防止其他线程对这个表结构做了变更，有线程在执行select时，其他线程要更改表结构将会被阻塞，反之有线程更改表结构时，其他线程要CRUD也会被阻塞
MDL在事务提交后会被释放，事务执行期间MDL是一直被持有的
申请MDL的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现MDL写锁等待，会阻塞后续所有的CRUD操作
#### 意向锁
- 使用InnoDB引擎的表里对某些记录加上共享锁之前，需要在表级别加上一个意向共享锁
- 加上独占锁之前，需要先加上一个意向独占锁
也就是当执行插入、更新、删除操作，需要先对表加上意向独占锁，然后对该记录加独占锁，而普通的select是不会加行级锁的，普通select语句是利用MVCC实现一致性读，是无锁的
**意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，意向锁之间也不会发生冲突，只会和共享表锁和独占表锁发生冲突**
表锁和行锁是满足读读共享、读写互斥、写写互斥的
意向锁的目的是为了快速判断表里是否有记录被加锁
#### AUTOINC锁
表中组件通常都是自增的，这是通过对主键字段声明`AUTO_INCREMENT`实现，之后在插入数据时不指定主键的值，数据库自动给主键赋值递增的值，通过**AUTO-INC锁**实现的
AUTOINC锁是特殊表锁机制，锁**不再是事务提交后再释放，而是在执行完插入语句后就立刻释放**
插入数据时，会加一个表级别的AUTO-INC锁，然后为设置自增的字段赋递增的值，插入语句执行完后才会把AUTOINC释放掉；一个事务持有AUTOINC锁过程中，其他食物向该表插入语句都会被阻塞，保证AUTOINC值是递增的，**大量数据插入时会阻塞其他事务**
5.1.22开始Mysql提供了轻量级锁实现自增，在插入数据时为字段加上轻量级锁，**然后给该字段赋一个自增的值然后就释放掉这个轻量级锁，而不需要等待整个插入语句执行完后才释放锁**
InnoDB还提供innodb_autoinc_lock_mode系统变量控制使用AUTOINC锁还是轻量级锁
- =0时使用AUTOINC锁
- =2时使用轻量级锁
- =1时
  - 类似insert语句，自增锁申请后就马上释放
  - 类似insert...select批量插入语句，等待语句结束后才释放
当mode=2性能最高，但搭配binlog日志格式时statement一起使用时，在*主从复制*情况下可能出现数据不一致问题，**当innodb_autoinc_lock_mode=2时，设置binlog_format=row既能提高并发性，又不会出现数据不一致问题**
### 行级锁
InnoDB支持行级锁，MyISAM不支持行级锁
普通的select不会对记录加锁，属于快照读。如果查询时对记录加行锁，这种加锁方式称为**锁定读**
```
select ... lock in share mode //对读取记录加共享锁
select ... for update //对读取记录加独占锁
```
两个语句必须在一个事务中，**因为当事务提交了，锁就会被释放**
#### RecordLock
记录所，锁住一个记录，有S锁和X锁之分
- 当一个事务对记录加了S锁，其他事务可以继续对该事务加S锁，但是不可以加X锁
- 一个事务对记录加了X锁，其他事物无论S锁还是X锁都不能加
#### GapLock
间隙锁，只存在于可重复读隔离级别，为了解决可重复读隔离级别下幻读现象
间隙锁存在X锁和S锁区别，并没有什么区别，**间隙锁之间是兼容的，两个事务可以同时持有包含共同间隙范围的间隙锁，不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出**
#### NextKeyLock
临键锁，是RecordLock+GapLock组合，锁定范围和记录本身
nextkeylock是包含间隙锁+记录锁，一个事务获取了X型的nextkeylock，则其他事物获取相同范围的X锁时会被阻塞
#### 插入意向锁
一个事务在插入一条记录时，需要判断插入位置是否已经被其他事物加了间隙锁，如果有的话则会**阻塞**，直到事务提交，在此期间会生成一个**插入意向锁**，表示有食物等待插入（Mysql加锁先生成锁结构，再设置锁状态，如果是等待状态则不代表事务成功获取锁，只有正常时才代表成功获取了锁）
插入意向锁**不是意向锁，是特殊的间隙锁，属于行级锁**
# Mysql是如何加锁的
### 什么SQL语句会加行级锁
InnoDB支持行级锁，而MyISAM不支持行级锁，普通的select不会对记录加锁（除了串行化隔离级别）属于快照读，通过MVCC实现的；如果查询时要对记录加锁，可以通过两个方式
```
select ... lock in share mode 对记录加s锁共享锁
select ... for update 对记录加x锁独占锁
```
除了这两个锁定语句，**update和delete操作都会加行级锁，且类型都是x锁独占锁**
### 行级锁类型
[[图解Mysql#Mysql有哪些锁#行级锁]]
### Mysql是如何加行级锁的
加锁的对象是索引，基本单位是next-key lock，由记录锁和间隙锁组合而成，next-key lock是前开后闭区间，而间隙锁是前开后开区间
但是next-ley lock在一定场景下会退化成记录锁或间隙锁：**在能使用记录锁或间隙锁就能避免幻读的情况下就会退化**
#### 唯一索引等值查询
当使用唯一索引进行等值查询的时候，查询的记录不存在，加锁的规则也会不同
- 查询的记录是存在的，在索引树上定位到记录后，将该记录索引的next-key lock**退化成记录锁**
- 查询记录不存在，索引树查找到第一条大于该查询记录的记录后，将该记录中索引的next-key lock退化成**间隙锁**
在唯一索引等值查询并查询记录存在的情况下，仅靠记录锁也能避免幻读问题
- 主键具有唯一性，其他事物插入id=1时，会因为主键冲突导致无法插入新id=1的记录，这样事务在多次查询id=1记录时，不会出现前后查询结果不同的问题
- 对id=1加了记录锁，其他事物无法删除该记录，也不会出现前后查询结果不同的问题
#### 唯一索引范围查询
当唯一索引进行范围查询时，**会对每一个扫描到的索引加next-key lock锁，遇到如下清空会退化成记录锁或间隙锁**
- 大于等于情况下，如果等值查询记录存在于表中，则该索引的next-key会退化成记录锁
- 小于或小于等于情况下，还要看条件值记录是否存在表中
  - 不存在表中，不管是小于还是小于等于，扫描到终止范围的查询记录时，该记录索引next-key会退化成间隙锁，其他扫描到的记录，都是加上next-key锁
  - 存在表中，如果是*小于*条件，扫描到终止范围查询的记录时，该记录索引的next-key会退化成间隙锁，其他记录都在索引上加next-key锁；如果是*小于等于*，扫描到终止范围查询的记录时，该记录不会退化成间隙锁，其他记录都加上next-key lock
#### 非唯一索引等值查询
用非唯一索引进行等值查询时，**因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁**
针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：
- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是**非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁**
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**
#### 非唯一索引范围查询
非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于**非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况**，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁
#### 没有加索引的查询
**如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞**
不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表
**在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了**
# update没加索引会锁全表
InnoDB 存储引擎的默认事务隔离级别是「可重复读」，但是在这个隔离级别下，在多个事务并发的时候，会出现幻读的问题，因此 InnoDB 存储引擎自己实现了行锁，通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录
当我们执行 update 语句时，会对记录加独占锁（X 锁）的，如果其他事务对持有独占锁的记录进行修改时会被阻塞。另外，这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放
在 InnoDB 事务中，对记录加锁带基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。加锁的位置准确的说，锁是加在索引上的而非行上
**在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了**。update 语句的 where 带上索引不能避免全表记录加锁了，还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁
### 如何避免这种事故的发生？
我们可以将 MySQL 里的 `sql_safe_updates` 参数设置为 1，开启安全更新模式。
当 sql_safe_updates 设置为 1 时，update 语句必须满足如下条件之一才能执行成功：
- 使用 where，并且 where 条件中必须有索引列；
- 使用 limit；
- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；
delete 语句必须满足以下条件能执行成功：
- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；
如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 `force index([index_name])` 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患
# MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗
- 针对快照读（普通select）通过MVCC解决幻读，可重复读隔离级别下，事务执行过程中看到的数据和事务启动时是一致的，即使插入了其他数据，事务中也查询不到
- 针对当前读（select for update）通过next-key lock（记录锁+间隙锁）方式解决了幻读，当执行select for update时候，会加上next-key lock，如果有其他事物在next-key lock范围内插入记录则会被阻塞
通过`select * from performance_schema.data_locks\G`查看加锁类型
LOCKTYPE中RECORD代表行级锁
- 如果LOCK_MODE是`X`，说明是next-key锁
- 如果LOCK_MODE是`X REC_NOT_GAP`说明是记录锁
- 如果LOCK_MODE是`X GAP`说明是间隙锁
执行全表扫描时，锁在遍历索引时候加上的，并不是针对输出结果加锁。因此在线上执行update、delete、select...for update等加锁性质语句，要检查是否走了索引，如果是全表扫描的话会对每个索引加next-key lock，把整个表锁住
# Mysql死锁了怎么办
### 死锁发生
两个事务select for update先后锁住记录，互相等待对方释放锁导致死锁
或两个查询同id的select进入查询，导致两条重复的记录产生幻读
### 为什么产生死锁
可重复读级别存在幻读问题，InnoDB使用next-key lock锁住
普通select使用MVCC快照读，不会对记录加锁
如果update的where没有用到索引，就会进行全表扫描，会给行加上行锁和空隙加上间隙锁，锁住整个表，直到事务结束才会解锁
插入意向锁和间隙锁是冲突的，当其他食物持有该间隙的间隙锁时，需要等待其他事物释放间隙锁后，才能获取到插入意向锁；而间隙锁和间隙锁之间是兼容的，两个事务的`select for update`不会相互影响
### 为什么间隙锁之间是兼容的
间隙锁的意义在于阻止区间被插入，是可以共存的，一个事务获取的间隙锁是不会阻止另一个事物的获取同一个间隙范围的间隙锁，共享和排他的间隙锁是没有区别的，相互不冲突，且功能相同，两个事务可以同时持有包含共同间隙的间隙锁，有两种场景
- 两个间隙锁区间完全相同
- 一个间隙区间是另一个的子集
next-key lock是包含间隙锁+记录锁，如果一个事务获取了X锁会导致另一个事务在获取相同范围的X锁会被阻塞
插入意向锁是一种特殊的间隙锁，**锁住一个点**，会在查询意向插入的记录是否被加了间隙锁，加了锁则生成意向插入锁
### Insert是如何加行级锁的
Insert正常执行时不会生成锁结构，考聚簇索引自带的trx_id隐藏列作为隐式锁来保护记录的
隐式锁式在Insert过程不加锁，特殊情况下才将隐式锁转换为显锁
- 如果记录间有间隙锁，为了避免幻读此时不能插入记录
- 如果insert记录和已有记录存在唯一键冲突，也不能插入记录
### 如何避免死锁
死锁四个必要条件：互斥、占有且等待、不可强占用、循环等待
数据库层面有两种策略通过*打断循环等待条件*来解锁死锁状态
- 设置事务等待锁的超时时间
- 主动开启死锁检测
# Mysql日志
- undolog：InnoDB层生成的日志，实现事务的**原子性**，用于**事务回滚和MVCC**
- redolog：InnoDB生成的日志，实现事务的**持久性**，用于**掉电故障恢复**
- binlog：Server层生成日志，用于**数据备份和主从复制**
### Undolog 
每次事务执行过程中，都记录下回滚时需要的信息到日志中，则事务执行中途Mysql奔溃后，可以通过这个日志回滚到事物之前的数据，这就是undo log，保证了事务的原子性
undo log是一种用于撤销回滚的日志，在事务未提交之前Mysql会先记录更新前的数据到undolog中，回滚时可以利用undolog进行回滚
- **插入**记录时，记录主键值，回滚时只需要把这个主键值对应的记录删除
- **删除**记录时，要将对应记录所有内容都记下来，回滚时将这些内容组成的记录插入表中
- **更新**记录时，将被更新的旧值记录下来，回滚时将记录变为旧值
一条记录每次操作产生的undolog格式都有roll_pointer指针和trx_id事务id
- 通过trx_id得知记录被哪个事务修改的
- 通过roll_pointer将undo log串成链表，这个链表就是版本链
undo log还可通过ReadView+undo log实现MVCC多版本并发控制，对于*读提交*和*可重复读*级别，快照读（select）都是通过ReadView+undo log实现；通过判断ReadView字段并顺undo log版本链找到可见性记录
- *读提交*在每个select都会生成一个新的ReadView，意味着事务期间多次读取同一数据，前后可能会出现不一致，因为另一个事务可能修改了数据
- *可重复读*在创建事务时创建一个ReadView，后续整个事务都使用这个ReadView
则undo log两大作用
- 实现事务回滚，保证事务原子性
- 实现MVCC关键因素之一
### Buffer Pool
InnoDB设计了BufferPool缓冲池，要更新记录时，从硬盘读取在内存中修改这个记录，再写入BufferPool中提高数据库读写性能
- 读取数据时，如果数据存在于BufferPool中，客户端会直接读取BufferPool中数据，否则再去磁盘中读取
- 修改数据时，如果数据存在BufferPool中，则直接修改BufferPool中数据所在页，再将其设置为脏页，为了减少磁盘IO，不会立即将脏页写入磁盘，后续由后台线程选择合适时机写入磁盘
#### BufferPool缓存什么
Buffer Pool按*页*划分；Mysql启动时，InnoDB为BufferPool申请连续内存空间，然后按照默认16KB分页，BufferPool中页就叫缓存页，随着程序运行会有磁盘上的页缓存到BufferPool中
BufferPool除了缓存*索引页*和*数据页*，还包括了*Undo页、插入缓存、自适应哈希索引、锁信息等*
**Undo页记录什么**
开启事务后，InnoDB更新记录前，先记录相应Undolog，会写入BufferPool的Undo页面中
**查询记录一次缓存一条记录吗**
查询一条记录时，InnoDB会把整个页数据加载到BufferPool中，再通过页里页目录区定位到具体某条记录
### Redo log
为了防止断电导致数据丢失，有记录需要更新时InnoDB会先更新内存并标记为脏页，再将本次对这个页的修改以redo log记录，后续由后台线程将缓存在BufferPool的脏页刷新到磁盘里，这就是WAL（写操作不是立刻写在磁盘上，而是先写日志等待合适时机再写入磁盘）
#### 什么是Redo log
是物理日志，记录了某个数据页做了什么修改，每当执行一个事务就会产生这样的一条或多条物理日志
在事务提交时，只要先将redo log持久化到磁盘，不需要等到缓存在Buffer Pool的脏页数据持久化到磁盘。系统奔溃时，redo log已经持久化，等待Mysql重启后根据Redolog内容恢复到最新状态
开启事务后，InnoDB更新前首先要记录对应Undo log，会写入BufferPool的Undo页面，在内存修改该Undo页面后，需要记录对应Redo log
- redo log记录了此次事务*完成后*的状态，记录更新后的值
- undo log记录此次事务*开始前*的状态，记录更新前的值
事务提交前发生奔溃，根据undo log回滚；事务提交后奔溃，重启后通过redo log恢复事务，redo log保证了**持久性**
写入redo log使用了追加操作，磁盘操作是**顺序写**，而写入数据需要先找到写入位置，然后再写入磁盘，操作是**随机写**，磁盘的顺序写性能比随机写高效，redo log写入磁盘开销小；这也是WAL优点，将磁盘随机写变为了顺序写
redo log产生后也不是直接写入磁盘，而是存进redo log buffer，每当产生一条redo log先写入buffer，后续持久化进磁盘中
#### Redo log什么时候刷盘
- Mysql正常关闭时
- redo log buffer记录的写入量大于redo log buffer内存的一半时，会触发落盘
- InnoDB后台线程每隔一秒，将redo log buffer持久化到磁盘
- 每次事物提交时都将缓存在redo log buffer的redo log持久化到磁盘，通过innodb_flush_log_at_trx_commit控制
**innodb_flush_log_at_trx_commit**
- 参数为**0**时，代表每次事物提交时，还是将**redo log留在buffer中**，该模式下事物提交时不会主动触发写入磁盘的操作
- 参数为**1**时，表示每次事物提交时，都将**buffer中的redo log直接持久化到磁盘**，保证Mysql重启后数据不会丢失
- 参数为**2**时，表示每次事物提交时，都只是缓存在buffer中的redo log写道redo log文件，缓存到对应Page Cache
InnoDB后台线程每隔一秒
- 参数为0：会把缓存在redo log buffer中的redo log通过`write()`写进操作系统Page Cache，然后调用`fsync()`持久化进磁盘。参数为0的策略，Mysql奔溃会导致上一秒所有事务数据的丢失
- 参数为2：调用`fsync()`，将缓存在操作系统Page Cache的redo log持久化进磁盘。参数为0更安全，Mysql进程奔溃不会丢失数据，只有系统奔溃或断电情况下，上一秒事务数据才会丢失
#### Redo log文件写满了怎么办
默认InnoDB有一个重做日志文件组，由两个redo log文件组成：`ib_logfile0`&`ib_logfile1`。在重做日志中，每个redo log file大小是一致的，且设置上限为1GB，总共可以记录2GB操作
重做日志文件是**循环写**，所以InnoDB会先写0文件，写满后切换至1文件，再被写满后会写换回0文件
InnoDB用write pos表示redo log当前记录写到的位置，checkpoint表示当前要擦除的位置
- write pos和checkpoint都是顺时针移动
- write pos ~ checkpoint之间记录新操作记录
- checkpoint ~ write pos记录待落盘脏页
如果write pos追上checkpoint，代表**redo log文件写满了，Mysql将不能再执行新更新操作，Mysql将会被阻塞，会停下先将Buffer Pool脏页刷新进磁盘，然后标记哪些redo log可以被删除，等删除后checkpoint会向后移动**，Mysql恢复正常
